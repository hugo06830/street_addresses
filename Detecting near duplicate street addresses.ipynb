{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVZZrnY0WpRK"
      },
      "source": [
        "\n",
        "## Config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4ZJwmQjaqYG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfc74912-faba-4da4-ca20-288a3a6a4a25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUcKDlguvbI_",
        "outputId": "3d794b28-fe36-49cb-aa04-6ad475bb4f99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nlpaug\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.23.5)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.31.0)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.12.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.66.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.11.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2023.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2023.7.22)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.4.1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n",
            "Installing collected packages: nlpaug\n",
            "Successfully installed nlpaug-1.1.11\n"
          ]
        }
      ],
      "source": [
        "!pip install nlpaug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Aicr_-HriuP",
        "outputId": "f0aac5e1-2009-497f-a911-ac967d94e3b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flair\n",
            "  Downloading flair-0.12.2-py3-none-any.whl (373 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.1/373.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.10/dist-packages (from flair) (2.8.2)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from flair) (2.0.1+cu118)\n",
            "Requirement already satisfied: gensim>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.3.1)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.66.0)\n",
            "Collecting segtok>=1.5.7 (from flair)\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from flair) (3.7.1)\n",
            "Collecting mpld3==0.3 (from flair)\n",
            "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.5/788.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from flair) (1.2.2)\n",
            "Collecting sqlitedict>=1.6.0 (from flair)\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting deprecated>=1.2.4 (from flair)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: hyperopt>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from flair) (0.2.7)\n",
            "Collecting boto3 (from flair)\n",
            "  Downloading boto3-1.28.26-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers[sentencepiece]>=4.18.0 (from flair)\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bpemb>=0.3.2 (from flair)\n",
            "  Downloading bpemb-0.3.4-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from flair) (2023.6.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from flair) (0.9.0)\n",
            "Collecting langdetect (from flair)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from flair) (4.9.3)\n",
            "Collecting ftfy (from flair)\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting janome (from flair)\n",
            "  Downloading Janome-0.5.0-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gdown==4.4.0 (from flair)\n",
            "  Downloading gdown-4.4.0.tar.gz (14 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting huggingface-hub>=0.10.0 (from flair)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting conllu>=4.0 (from flair)\n",
            "  Downloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from flair) (10.1.0)\n",
            "Collecting wikipedia-api (from flair)\n",
            "  Downloading Wikipedia_API-0.6.0-py3-none-any.whl (14 kB)\n",
            "Collecting pptree (from flair)\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytorch-revgrad (from flair)\n",
            "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
            "Collecting transformer-smaller-training-vocab>=0.2.1 (from flair)\n",
            "  Downloading transformer_smaller_training_vocab-0.2.4-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown==4.4.0->flair) (3.12.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown==4.4.0->flair) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown==4.4.0->flair) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown==4.4.0->flair) (4.11.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bpemb>=0.3.2->flair) (1.23.5)\n",
            "Collecting sentencepiece (from bpemb>=0.3.2->flair)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.4->flair) (1.14.1)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim>=3.8.0->flair) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=3.8.0->flair) (6.3.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (2023.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (4.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (23.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair) (3.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair) (0.18.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair) (0.10.9.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (3.1.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->flair) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->flair) (3.2.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.8,>=1.5.0->flair) (3.27.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.8,>=1.5.0->flair) (16.0.6)\n",
            "Collecting datasets<3.0.0,>=2.0.0 (from transformer-smaller-training-vocab>=0.2.1->flair)\n",
            "  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers[sentencepiece]>=4.18.0->flair)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers[sentencepiece]>=4.18.0->flair)\n",
            "  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]>=4.18.0->flair) (3.20.3)\n",
            "Collecting botocore<1.32.0,>=1.31.26 (from boto3->flair)\n",
            "  Downloading botocore-1.31.26-py3-none-any.whl (11.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->flair)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3->flair)\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->flair) (0.2.6)\n",
            "Collecting urllib3<1.27,>=1.25.4 (from botocore<1.32.0,>=1.31.26->boto3->flair)\n",
            "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (1.5.3)\n",
            "Collecting xxhash (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.4.0->flair) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.4.0->flair) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.4.0->flair) (2023.7.22)\n",
            "Collecting accelerate>=0.20.3 (from transformers[sentencepiece]>=4.18.0->flair)\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown==4.4.0->flair) (2.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.8,>=1.5.0->flair) (2.1.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.4.0->flair) (1.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.8,>=1.5.0->flair) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[sentencepiece]>=4.18.0->flair) (5.9.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (1.3.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (2023.3)\n",
            "Building wheels for collected packages: gdown, mpld3, sqlitedict, langdetect, pptree\n",
            "  Building wheel for gdown (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-4.4.0-py3-none-any.whl size=14759 sha256=881305e5e7c2565c51cf412b7bbfb922da9345881b5c4500638fc557925971f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/0b/3f/6ddf67a417a5b400b213b0bb772a50276c199a386b12c06bfc\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116686 sha256=8428d27ae99f086ec6d5008de3ff8d88969874cf2a7234c011e56f5d2d031a36\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/92/f7/45d9aac5dcfb1c2a1761a272365599cc7ba1050ce211a3fd9a\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16863 sha256=b7daee278eef9d1c92be4e9dcabf961046f84b19cbd3276afe792545e77ffbcf\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=e81338a266ea1e80bd40ee6a3b2bd2d322bd7a4c45364f2880360e36592bacd4\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4608 sha256=33f284846f0a6b92899f1f9e62ce998cbf4473e55b5718a67dc26dde859a1ff0\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/b6/0e/6f26eb9e6eb53ff2107a7888d72b5a6a597593956113037828\n",
            "Successfully built gdown mpld3 sqlitedict langdetect pptree\n",
            "Installing collected packages: tokenizers, sqlitedict, sentencepiece, safetensors, pptree, mpld3, janome, xxhash, urllib3, segtok, langdetect, jmespath, ftfy, dill, deprecated, conllu, multiprocess, botocore, wikipedia-api, s3transfer, huggingface-hub, bpemb, transformers, gdown, datasets, boto3, accelerate, transformer-smaller-training-vocab, pytorch-revgrad, flair\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.4\n",
            "    Uninstalling urllib3-2.0.4:\n",
            "      Successfully uninstalled urllib3-2.0.4\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.6.6\n",
            "    Uninstalling gdown-4.6.6:\n",
            "      Successfully uninstalled gdown-4.6.6\n",
            "Successfully installed accelerate-0.21.0 boto3-1.28.26 botocore-1.31.26 bpemb-0.3.4 conllu-4.5.3 datasets-2.14.4 deprecated-1.2.14 dill-0.3.7 flair-0.12.2 ftfy-6.1.1 gdown-4.4.0 huggingface-hub-0.16.4 janome-0.5.0 jmespath-1.0.1 langdetect-1.0.9 mpld3-0.3 multiprocess-0.70.15 pptree-3.1 pytorch-revgrad-0.2.0 s3transfer-0.6.1 safetensors-0.3.2 segtok-1.5.11 sentencepiece-0.1.99 sqlitedict-2.1.0 tokenizers-0.13.3 transformer-smaller-training-vocab-0.2.4 transformers-4.31.0 urllib3-1.26.16 wikipedia-api-0.6.0 xxhash-3.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install flair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUe6zQQLWpRR"
      },
      "outputs": [],
      "source": [
        "\n",
        "EMBEDDING_DIM = 300\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 10\n",
        "VALIDATION_SPLIT = 0.1\n",
        "\n",
        "\n",
        "RATE_DROP_LSTM = 0.17\n",
        "RATE_DROP_DENSE = 0.25\n",
        "NUMBER_LSTM = 50\n",
        "NUMBER_DENSE_UNITS = 50\n",
        "ACTIVATION_FUNCTION = 'relu'\n",
        "\n",
        "\n",
        "siamese_config = {\n",
        "\t'EMBEDDING_DIM': EMBEDDING_DIM,\n",
        "\t'MAX_SEQUENCE_LENGTH' : MAX_SEQUENCE_LENGTH,\n",
        "\t'VALIDATION_SPLIT': VALIDATION_SPLIT,\n",
        "\t'RATE_DROP_LSTM': RATE_DROP_LSTM,\n",
        "\t'RATE_DROP_DENSE': RATE_DROP_DENSE,\n",
        "\t'NUMBER_LSTM': NUMBER_LSTM,\n",
        "\t'NUMBER_DENSE_UNITS': NUMBER_DENSE_UNITS,\n",
        "\t'ACTIVATION_FUNCTION': ACTIVATION_FUNCTION\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8cnCsYjWpRW"
      },
      "source": [
        "## Inputhandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Bn7OsFgWpRX"
      },
      "outputs": [],
      "source": [
        "from keras.utils import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import FastText\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from flair.data import Sentence\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings\n",
        "import numpy as np\n",
        "import gc\n",
        "\n",
        "def flair_embed_meta_data(documents):\n",
        "\n",
        "    \"\"\"\n",
        "    Load FLAIR embeddings for the given documents.\n",
        "    Args:\n",
        "        documents (list): List of documents.\n",
        "    Returns:\n",
        "        word_embeddings (flair.embeddings.StackedEmbeddings): StackedEmbeddings object containing word embeddings.\n",
        "        embedding_dim (int): Embedding dimension.\n",
        "    \"\"\"\n",
        "    # Create a Sentence object for each document\n",
        "    sentences = [Sentence(doc) for doc in documents]\n",
        "\n",
        "    # Initialize WordEmbeddings\n",
        "    word_embeddings = WordEmbeddings('glove', fine-tune == True)\n",
        "\n",
        "    # Initialize FlairEmbeddings\n",
        "    flair_embeddings = FlairEmbeddings('news-forward', chars_per_chunk=128)\n",
        "\n",
        "    # Stack the embeddings\n",
        "    embeddings = StackedEmbeddings([word_embeddings, flair_embeddings])\n",
        "\n",
        "    # Embed the sentences\n",
        "    embeddings.embed(sentences)\n",
        "\n",
        "    # Retrieve the embedding dimension\n",
        "    embedding_dim = embeddings.embedding_length\n",
        "\n",
        "    # Create an embedding matrix\n",
        "    embedding_matrix = np.zeros((len(sentences), embedding_dim))\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        embedding_matrix[i] = sentence.embedding.numpy()\n",
        "\n",
        "    return embedding_matrix\n",
        "\n",
        "def create_train_dev_set_with_flair(embedding_matrix, sentences_pair, is_similar, max_sequence_length, validation_split_ratio):\n",
        "    \"\"\"\n",
        "    Create training and validation dataset with FLAIR embeddings.\n",
        "    Args:\n",
        "        embedding_matrix (np.ndarray): Array containing FLAIR embeddings for the sentences.\n",
        "        sentences_pair (list): List of tuples of sentence pairs.\n",
        "        is_similar (list): List containing labels indicating whether respective sentences in sentence1 and sentence2\n",
        "                           are the same or not (1 if same else 0).\n",
        "        max_sequence_length (int): Maximum sequence length of sentences to apply padding.\n",
        "        validation_split_ratio (float): Ratio to split training data into validation data.\n",
        "    Returns:\n",
        "        train_data (np.array): Array of input features for the training set.\n",
        "        labels_train (np.array): Array containing similarity scores for the training data.\n",
        "        val_data (np.array): Array of input features for the validation set.\n",
        "        labels_val (np.array): Array containing similarity scores for the validation data.\n",
        "    \"\"\"\n",
        "    sentences1 = [x[0].lower() for x in sentences_pair]\n",
        "    sentences2 = [x[1].lower() for x in sentences_pair]\n",
        "\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(sentences1 + sentences2)\n",
        "\n",
        "    train_sequences_1 = tokenizer.texts_to_sequences(sentences1)\n",
        "    train_sequences_2 = tokenizer.texts_to_sequences(sentences2)\n",
        "\n",
        "    train_padded_data_1 = pad_sequences(train_sequences_1, maxlen=max_sequence_length)\n",
        "    train_padded_data_2 = pad_sequences(train_sequences_2, maxlen=max_sequence_length)\n",
        "    train_labels = np.array(is_similar)\n",
        "\n",
        "    # Add an extra dimension to the input data\n",
        "    train_data_1 = embedding_matrix[train_padded_data_1]\n",
        "    train_data_2 = embedding_matrix[train_padded_data_2]\n",
        "\n",
        "    shuffle_indices = np.random.permutation(np.arange(len(train_labels)))\n",
        "    train_data_1_shuffled = train_data_1[shuffle_indices]\n",
        "    train_data_2_shuffled = train_data_2[shuffle_indices]\n",
        "    train_labels_shuffled = train_labels[shuffle_indices]\n",
        "\n",
        "    dev_idx = max(1, int(len(train_labels_shuffled) * validation_split_ratio))\n",
        "\n",
        "    train_data = train_data_1_shuffled[:-dev_idx], train_data_2_shuffled[:-dev_idx]\n",
        "    labels_train = train_labels_shuffled[:-dev_idx]\n",
        "    val_data = train_data_1_shuffled[-dev_idx:], train_data_2_shuffled[-dev_idx:]\n",
        "    labels_val = train_labels_shuffled[-dev_idx:]\n",
        "\n",
        "    return train_data, labels_train, val_data, labels_val\n",
        "\n",
        "\n",
        "def train_word2vec(documents, embedding_dim):\n",
        "    \"\"\"\n",
        "    train word2vector over traning documents\n",
        "    Args:\n",
        "        documents (list): list of document\n",
        "        embedding_dim (int): output wordvector size\n",
        "    Returns:\n",
        "        word_vectors(dict): dict containing words and their respective vectors\n",
        "    \"\"\"\n",
        "    model = Word2Vec(documents, min_count=1, vector_size=embedding_dim)\n",
        "    word_vectors = model.wv\n",
        "    del model\n",
        "    return word_vectors\n",
        "\n",
        "\n",
        "def train_char2vec(documents, embedding_dim):\n",
        "    \"\"\"\n",
        "    Train character-level embedding using FastText over training documents.\n",
        "    Args:\n",
        "        documents (list): List of documents\n",
        "        embedding_dim (int): Output character vector size\n",
        "    Returns:\n",
        "        char_vectors (dict): Dictionary containing characters and their respective vectors\n",
        "    \"\"\"\n",
        "    model = FastText(vector_size=embedding_dim, min_count=1)\n",
        "    model.build_vocab(corpus_file=None, corpus_iterable=documents)\n",
        "    model.train(corpus_file=None, corpus_iterable=documents, total_examples=len(documents), epochs=100)  # Adjust epochs as needed\n",
        "\n",
        "    char_vectors = model.wv\n",
        "    del model\n",
        "    return char_vectors\n",
        "\n",
        "\n",
        "def create_char_embedding_matrix(tokenizer, vectors, embedding_dim):\n",
        "    \"\"\"\n",
        "    Create embedding matrix from the tokenizer and pre-trained vectors.\n",
        "    Args:\n",
        "        tokenizer (keras.preprocessing.text.Tokenizer): Keras tokenizer object\n",
        "        vectors (dict): Dictionary with character vectors\n",
        "        embedding_dim (int): Embedding dimension\n",
        "    Returns:\n",
        "        embedding_matrix (np.ndarray): Character embedding matrix\n",
        "    \"\"\"\n",
        "    embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\n",
        "    for char, i in tokenizer.word_index.items():\n",
        "        if char in vectors:\n",
        "            embedding_matrix[i] = vectors[char]\n",
        "\n",
        "    return embedding_matrix\n",
        "\n",
        "\n",
        "\n",
        "def create_embedding_matrix(tokenizer, word_vectors, embedding_dim):\n",
        "    \"\"\"\n",
        "    Create embedding matrix containing word indexes and respective vectors from word vectors\n",
        "    Args:\n",
        "        tokenizer (keras.preprocessing.text.Tokenizer): keras tokenizer object containing word indexes\n",
        "        word_vectors (dict): dict containing word and their respective vectors\n",
        "        embedding_dim (int): dimention of word vector\n",
        "    Returns:\n",
        "    \"\"\"\n",
        "    nb_words = len(tokenizer.word_index) + 1\n",
        "    word_index = tokenizer.word_index\n",
        "    embedding_matrix = np.zeros((nb_words, embedding_dim))\n",
        "    print(\"Embedding matrix shape: %s\" % str(embedding_matrix.shape))\n",
        "    for word, i in word_index.items():\n",
        "        try:\n",
        "            embedding_vector = word_vectors[word]\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "        except KeyError:\n",
        "            print(\"vector not found for word - %s\" % word)\n",
        "    print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))\n",
        "    return embedding_matrix\n",
        "\n",
        "\n",
        "\n",
        "def char_embed_meta_data(documents, embedding_dim):\n",
        "    \"\"\"\n",
        "    Load tokenizer object for given documents list and create character-level embedding matrix.\n",
        "    Args:\n",
        "        documents (list): List of documents\n",
        "        embedding_dim (int): Embedding dimension\n",
        "    Returns:\n",
        "        tokenizer (keras.preprocessing.text.Tokenizer): Keras tokenizer object\n",
        "        embedding_matrix (np.ndarray): Character embedding matrix\n",
        "    \"\"\"\n",
        "    documents = [list(x.lower()) for x in documents]\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(documents)\n",
        "\n",
        "    char_vectors = train_char2vec(documents, embedding_dim)\n",
        "    embedding_matrix = create_char_embedding_matrix(tokenizer, char_vectors, embedding_dim)\n",
        "    del char_vectors\n",
        "\n",
        "    return tokenizer, embedding_matrix\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def word_embed_meta_data(documents, embedding_dim):\n",
        "    \"\"\"\n",
        "    Load tokenizer object for given vocabs list\n",
        "    Args:\n",
        "        documents (list): list of document\n",
        "        embedding_dim (int): embedding dimension\n",
        "    Returns:\n",
        "        tokenizer (keras.preprocessing.text.Tokenizer): keras tokenizer object\n",
        "        embedding_matrix (dict): dict with word_index and vector mapping\n",
        "    \"\"\"\n",
        "    documents = [x.lower().split() for x in documents]\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(documents)\n",
        "    word_vector = train_word2vec(documents, embedding_dim)\n",
        "    embedding_matrix = create_embedding_matrix(tokenizer, word_vector, embedding_dim)\n",
        "    del word_vector\n",
        "    gc.collect()\n",
        "    return tokenizer, embedding_matrix\n",
        "\n",
        "def create_train_dev_set_no_embedding(sentences_pair, is_similar, max_sequence_length, validation_split_ratio):\n",
        "    \"\"\"\n",
        "    Create training and validation dataset without any embedding.\n",
        "    Args:\n",
        "        sentences_pair (list): List of tuples of sentence pairs.\n",
        "        is_similar (list): List containing labels indicating whether respective sentences in sentence1 and sentence2\n",
        "                           are the same or not (1 if same else 0).\n",
        "        max_sequence_length (int): Maximum sequence length of sentences to apply padding.\n",
        "        validation_split_ratio (float): Ratio to split training data into validation data.\n",
        "    Returns:\n",
        "        train_data_1 (np.array): Array of input features for the training set from sentences1.\n",
        "        train_data_2 (np.array): Array of input features for the training set from sentences2.\n",
        "        labels_train (np.array): Array containing similarity scores for the training data.\n",
        "        val_data_1 (np.array): Array of input features for the validation set from sentences1.\n",
        "        val_data_2 (np.array): Array of input features for the validation set from sentences2.\n",
        "        labels_val (np.array): Array containing similarity scores for the validation data.\n",
        "    \"\"\"\n",
        "    sentences1 = [x[0].lower() for x in sentences_pair]\n",
        "    sentences2 = [x[1].lower() for x in sentences_pair]\n",
        "\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(sentences1 + sentences2)\n",
        "\n",
        "    train_sequences_1 = tokenizer.texts_to_sequences(sentences1)\n",
        "    train_sequences_2 = tokenizer.texts_to_sequences(sentences2)\n",
        "\n",
        "    train_padded_data_1 = pad_sequences(train_sequences_1, maxlen=max_sequence_length)\n",
        "    train_padded_data_2 = pad_sequences(train_sequences_2, maxlen=max_sequence_length)\n",
        "    train_labels = np.array(is_similar)\n",
        "\n",
        "    # Add an extra dimension to the input data\n",
        "    train_data_1 = np.expand_dims(train_padded_data_1, axis=-1)\n",
        "    train_data_2 = np.expand_dims(train_padded_data_2, axis=-1)\n",
        "\n",
        "    shuffle_indices = np.random.permutation(np.arange(len(train_labels)))\n",
        "    train_data_1_shuffled = train_data_1[shuffle_indices]\n",
        "    train_data_2_shuffled = train_data_2[shuffle_indices]\n",
        "    train_labels_shuffled = train_labels[shuffle_indices]\n",
        "\n",
        "    dev_idx = max(1, int(len(train_labels_shuffled) * validation_split_ratio))\n",
        "\n",
        "    train_data_1, val_data_1 = train_data_1_shuffled[:-dev_idx], train_data_1_shuffled[-dev_idx:]\n",
        "    train_data_2, val_data_2 = train_data_2_shuffled[:-dev_idx], train_data_2_shuffled[-dev_idx:]\n",
        "    labels_train, labels_val = train_labels_shuffled[:-dev_idx], train_labels_shuffled[-dev_idx:]\n",
        "\n",
        "    return train_data_1, train_data_2, labels_train, val_data_1, val_data_2, labels_val\n",
        "\n",
        "\n",
        "def create_train_dev_set(tokenizer, sentences_pair, is_similar, max_sequence_length, validation_split_ratio):\n",
        "    \"\"\"\n",
        "    Create training and validation dataset.\n",
        "    Args:\n",
        "        tokenizer (keras.preprocessing.text.Tokenizer): Keras tokenizer object.\n",
        "        sentences_pair (list): List of tuples of sentence pairs.\n",
        "        is_similar (list): List containing labels indicating whether respective sentences in sentence1 and sentence2\n",
        "                           are the same or not (1 if same else 0).\n",
        "        max_sequence_length (int): Maximum sequence length of sentences to apply padding.\n",
        "        validation_split_ratio (float): Ratio to split training data into validation data.\n",
        "    Returns:\n",
        "        train_data_1 (list): List of input features for the training set from sentences1.\n",
        "        train_data_2 (list): List of input features for the training set from sentences2.\n",
        "        labels_train (np.array): Array containing similarity scores for the training data.\n",
        "        val_data_1 (list): List of input features for the validation set from sentences1.\n",
        "        val_data_2 (list): List of input features for the validation set from sentences2.\n",
        "        labels_val (np.array): Array containing similarity scores for the validation data.\n",
        "    \"\"\"\n",
        "    sentences1 = [x[0].lower() for x in sentences_pair]\n",
        "    sentences2 = [x[1].lower() for x in sentences_pair]\n",
        "    train_sequences_1 = tokenizer.texts_to_sequences(sentences1)\n",
        "    train_sequences_2 = tokenizer.texts_to_sequences(sentences2)\n",
        "\n",
        "    train_padded_data_1 = pad_sequences(train_sequences_1, maxlen=max_sequence_length)\n",
        "    train_padded_data_2 = pad_sequences(train_sequences_2, maxlen=max_sequence_length)\n",
        "\n",
        "    train_labels = np.array(is_similar)\n",
        "\n",
        "    shuffle_indices = np.random.permutation(np.arange(len(train_labels)))\n",
        "    train_data_1_shuffled = train_padded_data_1[shuffle_indices]\n",
        "    train_data_2_shuffled = train_padded_data_2[shuffle_indices]\n",
        "    train_labels_shuffled = train_labels[shuffle_indices]\n",
        "\n",
        "    dev_idx = max(1, int(len(train_labels_shuffled) * validation_split_ratio))\n",
        "\n",
        "    del train_padded_data_1\n",
        "    del train_padded_data_2\n",
        "\n",
        "    train_data_1, val_data_1 = train_data_1_shuffled[:-dev_idx], train_data_1_shuffled[-dev_idx:]\n",
        "    train_data_2, val_data_2 = train_data_2_shuffled[:-dev_idx], train_data_2_shuffled[-dev_idx:]\n",
        "    labels_train, labels_val = train_labels_shuffled[:-dev_idx], train_labels_shuffled[-dev_idx:]\n",
        "\n",
        "    return train_data_1, train_data_2, labels_train, val_data_1, val_data_2, labels_val\n",
        "\n",
        "def create_train_dev_set_for_folds(tokenizer, sentences_pair, is_similar, max_sequence_length, validation_split_ratio):\n",
        "    \"\"\"\n",
        "    Create training and validation dataset\n",
        "    Args:\n",
        "        tokenizer (keras.preprocessing.text.Tokenizer): keras tokenizer object\n",
        "        sentences_pair (list): list of tuple of sentences pairs\n",
        "        is_similar (list): list containing labels if respective sentences in sentence1 and sentence2\n",
        "                           are same or not (1 if same else 0)\n",
        "        max_sequence_length (int): max sequence length of sentences to apply padding\n",
        "        validation_split_ratio (float): contain ratio to split training data into validation data\n",
        "    Returns:\n",
        "        train_data_1 (list): list of input features for training set from sentences1\n",
        "        train_data_2 (list): list of input features for training set from sentences2\n",
        "        labels_train (np.array): array containing similarity score for training data\n",
        "        leaks_train(np.array): array of training leaks features\n",
        "        val_data_1 (list): list of input features for validation set from sentences1\n",
        "        val_data_2 (list): list of input features for validation set from sentences2\n",
        "        labels_val (np.array): array containing similarity score for validation data\n",
        "        leaks_val (np.array): array of validation leaks features\n",
        "    \"\"\"\n",
        "    sentences1 = [x[0].lower() for x in sentences_pair]\n",
        "    sentences2 = [x[1].lower() for x in sentences_pair]\n",
        "    train_sequences_1 = tokenizer.texts_to_sequences(sentences1)\n",
        "    train_sequences_2 = tokenizer.texts_to_sequences(sentences2)\n",
        "    leaks = [[len(set(x1)), len(set(x2)), len(set(x1).intersection(x2))]\n",
        "             for x1, x2 in zip(train_sequences_1, train_sequences_2)]\n",
        "\n",
        "    train_padded_data_1 = pad_sequences(train_sequences_1, maxlen=max_sequence_length)\n",
        "    train_padded_data_2 = pad_sequences(train_sequences_2, maxlen=max_sequence_length)\n",
        "    train_labels = np.array(is_similar)\n",
        "    leaks = np.array(leaks)\n",
        "\n",
        "    shuffle_indices = np.random.permutation(np.arange(len(train_labels)))\n",
        "    train_data_1_shuffled = train_padded_data_1[shuffle_indices]\n",
        "    train_data_2_shuffled = train_padded_data_2[shuffle_indices]\n",
        "    train_labels_shuffled = train_labels[shuffle_indices]\n",
        "    leaks_shuffled = leaks[shuffle_indices]\n",
        "\n",
        "    dev_idx = max(1, int(len(train_labels_shuffled) * validation_split_ratio))\n",
        "\n",
        "    del train_padded_data_1\n",
        "    del train_padded_data_2\n",
        "    gc.collect()\n",
        "\n",
        "    train_data_1 = train_data_1_shuffled\n",
        "    train_data_2 = train_data_2_shuffled\n",
        "    labels =  train_labels_shuffled\n",
        "    leaks = leaks_shuffled\n",
        "\n",
        "\n",
        "    return train_data_1, train_data_2, labels, leaks\n",
        "\n",
        "def create_test_data(tokenizer, test_sentences_pair, max_sequence_length):\n",
        "    \"\"\"\n",
        "    Create training and validation dataset\n",
        "    Args:\n",
        "        tokenizer (keras.preprocessing.text.Tokenizer): keras tokenizer object\n",
        "        test_sentences_pair (list): list of tuple of sentences pairs\n",
        "        max_sequence_length (int): max sequence length of sentences to apply padding\n",
        "    Returns:\n",
        "        test_data_1 (list): list of input features for training set from sentences1\n",
        "        test_data_2 (list): list of input features for training set from sentences2\n",
        "    \"\"\"\n",
        "    test_sentences1 = [x[0].lower() for x in test_sentences_pair]\n",
        "    test_sentences2 = [x[1].lower() for x in test_sentences_pair]\n",
        "\n",
        "    test_sequences_1 = tokenizer.texts_to_sequences(test_sentences1)\n",
        "    test_sequences_2 = tokenizer.texts_to_sequences(test_sentences2)\n",
        "\n",
        "    test_data_1 = pad_sequences(test_sequences_1, maxlen=max_sequence_length)\n",
        "    test_data_2 = pad_sequences(test_sequences_2, maxlen=max_sequence_length)\n",
        "\n",
        "    return test_data_1, test_data_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wz7djaC8rhBU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyBhZp6VXnML",
        "outputId": "5bf9291f-c7a7-4a0e-b0ad-1d7932a25745"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.3.0)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.22.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGZDh6-yWpRZ"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OT1YH7HTWpRa"
      },
      "outputs": [],
      "source": [
        "# keras imports\n",
        "from keras.layers import Dense, Input, LSTM, Dropout, Bidirectional\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers import BatchNormalization, Embedding, concatenate, Bidirectional\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.models import load_model\n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# std imports\n",
        "import time\n",
        "import gc\n",
        "import os\n",
        "\n",
        "class SiameseBiLSTM:\n",
        "    def __init__(self, embedding_dim, max_sequence_length, number_lstm, number_dense, rate_drop_lstm,\n",
        "                 rate_drop_dense, hidden_activation, validation_split_ratio):\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.number_lstm_units = number_lstm\n",
        "        self.rate_drop_lstm = rate_drop_lstm\n",
        "        self.number_dense_units = number_dense\n",
        "        self.activation_function = hidden_activation\n",
        "        self.rate_drop_dense = rate_drop_dense\n",
        "        self.validation_split_ratio = validation_split_ratio\n",
        "\n",
        "    def train_model_word(self, sentences_pair, is_similar, embedding_meta_data, model_save_directory='./', fold = 1):\n",
        "        \"\"\"\n",
        "        Train Siamese network to find similarity between sentences in `sentences_pair`\n",
        "            Steps Involved:\n",
        "                1. Pass the each from sentences_pairs  to bidirectional LSTM encoder.\n",
        "                2. Merge the vectors from LSTM encodes and passed to dense layer.\n",
        "                3. Pass the  dense layer vectors to sigmoid output layer.\n",
        "                4. Use cross entropy loss to train weights\n",
        "        Args:\n",
        "            sentences_pair (list): list of tuple of sentence pairs\n",
        "            is_similar (list): target value 1 if same sentences pair are similar otherwise 0\n",
        "            embedding_meta_data (dict): dict containing tokenizer and word embedding matrix\n",
        "            model_save_directory (str): working directory for where to save models\n",
        "        Returns:\n",
        "            return (best_model_path):  path of best model\n",
        "        \"\"\"\n",
        "        tokenizer, embedding_matrix = embedding_meta_data['tokenizer'], embedding_meta_data['embedding_matrix']\n",
        "\n",
        "        train_data_x1, train_data_x2, train_labels, \\\n",
        "        val_data_x1, val_data_x2, val_labels = create_train_dev_set(tokenizer, sentences_pair,\n",
        "                                                                               is_similar, self.max_sequence_length,\n",
        "                                                                               self.validation_split_ratio)\n",
        "        if train_data_x1 is None:\n",
        "            print(\"++++ !! Failure: Unable to train model ++++\")\n",
        "            return None\n",
        "\n",
        "        nb_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "        # Creating word embedding layer\n",
        "        embedding_layer = Embedding(nb_words, self.embedding_dim, weights=[embedding_matrix],\n",
        "                                    input_length=self.max_sequence_length, trainable=False)\n",
        "\n",
        "        # Creating LSTM Encoder\n",
        "        lstm_layer = Bidirectional(LSTM(self.number_lstm_units, dropout=self.rate_drop_lstm, recurrent_dropout=self.rate_drop_lstm))\n",
        "\n",
        "        # Creating LSTM Encoder layer for First Sentence\n",
        "        sequence_1_input = Input(shape=(self.max_sequence_length,), dtype='int32')\n",
        "        embedded_sequences_1 = embedding_layer(sequence_1_input)\n",
        "        x1 = lstm_layer(embedded_sequences_1)\n",
        "\n",
        "        # Creating LSTM Encoder layer for Second Sentence\n",
        "        sequence_2_input = Input(shape=(self.max_sequence_length,), dtype='int32')\n",
        "        embedded_sequences_2 = embedding_layer(sequence_2_input)\n",
        "        x2 = lstm_layer(embedded_sequences_2)\n",
        "\n",
        "        # Merging two LSTM encodes vectors from sentences to\n",
        "        # pass it to dense layer applying dropout and batch normalisation\n",
        "        merged = concatenate([x1, x2])\n",
        "        merged = BatchNormalization()(merged)\n",
        "        merged = Dropout(self.rate_drop_dense)(merged)\n",
        "        merged = Dense(self.number_dense_units, activation=self.activation_function)(merged)\n",
        "        merged = BatchNormalization()(merged)\n",
        "        merged = Dropout(self.rate_drop_dense)(merged)\n",
        "        preds = Dense(1, activation='sigmoid')(merged)\n",
        "\n",
        "        model = Model(inputs=[sequence_1_input, sequence_2_input], outputs=preds)\n",
        "        model.compile(loss ='binary_crossentropy', optimizer='nadam', metrics=['acc'])\n",
        "\n",
        "        early_stopping = EarlyStopping(monitor='loss', patience=20)\n",
        "\n",
        "        STAMP = 'lstm_%d_%d_%.2f_%.2f' % (self.number_lstm_units, self.number_dense_units, self.rate_drop_lstm, self.rate_drop_dense)\n",
        "\n",
        "        checkpoint_dir = model_save_directory + 'checkpoints/' + str(int(time.time())) + '/'\n",
        "\n",
        "        if not os.path.exists(checkpoint_dir):\n",
        "            os.makedirs(checkpoint_dir)\n",
        "\n",
        "        bst_model_path = checkpoint_dir + STAMP + '.h5'\n",
        "\n",
        "        model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=False)\n",
        "\n",
        "        tensorboard = TensorBoard(log_dir=checkpoint_dir + \"logs/{}\".format(time.time()))\n",
        "\n",
        "        model.fit([train_data_x1, train_data_x2], train_labels,\n",
        "                  validation_data=([val_data_x1, val_data_x2], val_labels),\n",
        "                  epochs=100, batch_size=64, shuffle=True,\n",
        "                  callbacks=[early_stopping, model_checkpoint, tensorboard])\n",
        "\n",
        "        # Save the trained model to a file\n",
        "        model.save(model_save_directory + 'best_model.h5')\n",
        "\n",
        "        return bst_model_path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def train_model_char(self, sentences_pair, is_similar, char_embedding_meta_data, model_save_directory='./', fold=1):\n",
        "        \"\"\"\n",
        "        Train Siamese network to find similarity between sentences in `sentences_pair`.\n",
        "            Steps Involved:\n",
        "                1. Pass each sentence from sentences_pair to bidirectional LSTM encoder.\n",
        "                2. Merge the vectors from LSTM encoders and pass them to dense layer.\n",
        "                3. Pass the dense layer vectors to sigmoid output layer.\n",
        "                4. Use cross entropy loss to train weights.\n",
        "        Args:\n",
        "            sentences_pair (list): List of tuples of sentence pairs.\n",
        "            is_similar (list): Target value 1 if the same sentences pair are similar, otherwise 0.\n",
        "            char_embedding_meta_data (dict): Dictionary containing tokenizer and character embedding matrix.\n",
        "            model_save_directory (str): Working directory where to save models.\n",
        "        Returns:\n",
        "            return (best_model_path): Path of the best model.\n",
        "        \"\"\"\n",
        "        tokenizer, char_embedding_matrix = char_embedding_meta_data['tokenizer'], char_embedding_meta_data['char_embedding_matrix']\n",
        "\n",
        "        train_data_x1, train_data_x2, train_labels, \\\n",
        "        val_data_x1, val_data_x2, val_labels = create_train_dev_set(tokenizer, sentences_pair,\n",
        "                                                                    is_similar, self.max_sequence_length,\n",
        "                                                                    self.validation_split_ratio)\n",
        "        if train_data_x1 is None:\n",
        "            print(\"++++ !! Failure: Unable to train model ++++\")\n",
        "            return None\n",
        "\n",
        "        nb_chars = len(tokenizer.word_index) + 1\n",
        "\n",
        "        # Creating character embedding layer\n",
        "        char_embedding_layer = Embedding(nb_chars, self.embedding_dim, weights=[char_embedding_matrix],\n",
        "                                         input_length=self.max_sequence_length, trainable=False)\n",
        "\n",
        "        # Creating LSTM Encoder\n",
        "        lstm_layer = Bidirectional(LSTM(self.number_lstm_units, dropout=self.rate_drop_lstm, recurrent_dropout=self.rate_drop_lstm))\n",
        "\n",
        "        # Creating LSTM Encoder layer for First Sentence\n",
        "        sequence_1_input = Input(shape=(self.max_sequence_length,), dtype='int32')\n",
        "        embedded_sequences_1 = char_embedding_layer(sequence_1_input)\n",
        "        x1 = lstm_layer(embedded_sequences_1)\n",
        "\n",
        "        # Creating LSTM Encoder layer for Second Sentence\n",
        "        sequence_2_input = Input(shape=(self.max_sequence_length,), dtype='int32')\n",
        "        embedded_sequences_2 = char_embedding_layer(sequence_2_input)\n",
        "        x2 = lstm_layer(embedded_sequences_2)\n",
        "\n",
        "        # Merging two LSTM encoded vectors from sentences\n",
        "        # and passing them to the dense layer, applying dropout and batch normalization\n",
        "        merged = concatenate([x1, x2])\n",
        "        merged = BatchNormalization()(merged)\n",
        "        merged = Dropout(self.rate_drop_dense)(merged)\n",
        "        merged = Dense(self.number_dense_units, activation=self.activation_function)(merged)\n",
        "        merged = BatchNormalization()(merged)\n",
        "        merged = Dropout(self.rate_drop_dense)(merged)\n",
        "        preds = Dense(1, activation='sigmoid')(merged)\n",
        "\n",
        "        model = Model(inputs=[sequence_1_input, sequence_2_input], outputs=preds)\n",
        "        model.compile(loss ='binary_crossentropy', optimizer='nadam', metrics=['acc'])\n",
        "\n",
        "        early_stopping = EarlyStopping(monitor='loss', patience=20)\n",
        "\n",
        "        STAMP = 'lstm_%d_%d_%.2f_%.2f' % (\n",
        "        self.number_lstm_units, self.number_dense_units, self.rate_drop_lstm, self.rate_drop_dense)\n",
        "\n",
        "        checkpoint_dir = model_save_directory + 'checkpoints/' + str(int(time.time())) + '/'\n",
        "\n",
        "        if not os.path.exists(checkpoint_dir):\n",
        "            os.makedirs(checkpoint_dir)\n",
        "\n",
        "        bst_model_path = checkpoint_dir + STAMP + '.h5'\n",
        "\n",
        "        model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=False)\n",
        "\n",
        "        tensorboard = TensorBoard(log_dir=checkpoint_dir + \"logs/{}\".format(time.time()))\n",
        "\n",
        "        model.fit([train_data_x1, train_data_x2], train_labels,\n",
        "                  validation_data=([val_data_x1, val_data_x2], val_labels),\n",
        "                  epochs=100, batch_size=64, shuffle=True,\n",
        "                  callbacks=[early_stopping, model_checkpoint, tensorboard])\n",
        "\n",
        "        # Save the trained model to a file\n",
        "        model.save(model_save_directory + 'best_model_char.h5')\n",
        "\n",
        "        return bst_model_path\n",
        "\n",
        "    def train_model_Flair(self, sentences_pair, is_similar, Flair_embedding_matrix, model_save_directory='./', fold=1):\n",
        "          \"\"\"\n",
        "          Train Siamese network to find similarity between sentences in `sentences_pair`.\n",
        "              Steps Involved:\n",
        "                  1. Pass each sentence from sentences_pair to bidirectional LSTM encoder.\n",
        "                  2. Merge the vectors from LSTM encoders and pass them to dense layer.\n",
        "                  3. Pass the dense layer vectors to sigmoid output layer.\n",
        "                  4. Use cross entropy loss to train weights.\n",
        "          Args:\n",
        "              sentences_pair (list): List of tuples of sentence pairs.\n",
        "              is_similar (list): Target value 1 if the same sentences pair are similar, otherwise 0.\n",
        "              char_embedding_meta_data (dict): Dictionary containing tokenizer and character embedding matrix.\n",
        "              model_save_directory (str): Working directory where to save models.\n",
        "          Returns:\n",
        "              return (best_model_path): Path of the best model.\n",
        "          \"\"\"\n",
        "\n",
        "\n",
        "          train_data_x1, train_data_x2, train_labels, \\\n",
        "          val_data_x1, val_data_x2, val_labels = create_train_dev_set_with_flair(Flair_embedding_matrix, sentences_pair,\n",
        "                                                                      is_similar, self.max_sequence_length,\n",
        "                                                                      self.validation_split_ratio)\n",
        "          if train_data_x1 is None:\n",
        "              print(\"++++ !! Failure: Unable to train model ++++\")\n",
        "              return None\n",
        "\n",
        "          nb_chars = len(tokenizer.word_index) + 1\n",
        "\n",
        "          # Creating character embedding layer\n",
        "          char_embedding_layer = Embedding(nb_chars, self.embedding_dim, weights=[Flair_embedding_matrix],\n",
        "                                          input_length=self.max_sequence_length, trainable=False)\n",
        "\n",
        "          # Creating LSTM Encoder\n",
        "          lstm_layer = Bidirectional(LSTM(self.number_lstm_units, dropout=self.rate_drop_lstm, recurrent_dropout=self.rate_drop_lstm))\n",
        "\n",
        "          # Creating LSTM Encoder layer for First Sentence\n",
        "          sequence_1_input = Input(shape=(self.max_sequence_length,), dtype='int32')\n",
        "          embedded_sequences_1 = char_embedding_layer(sequence_1_input)\n",
        "          x1 = lstm_layer(embedded_sequences_1)\n",
        "\n",
        "          # Creating LSTM Encoder layer for Second Sentence\n",
        "          sequence_2_input = Input(shape=(self.max_sequence_length,), dtype='int32')\n",
        "          embedded_sequences_2 = char_embedding_layer(sequence_2_input)\n",
        "          x2 = lstm_layer(embedded_sequences_2)\n",
        "\n",
        "          # Merging two LSTM encoded vectors from sentences\n",
        "          # and passing them to the dense layer, applying dropout and batch normalization\n",
        "          merged = concatenate([x1, x2])\n",
        "          merged = BatchNormalization()(merged)\n",
        "          merged = Dropout(self.rate_drop_dense)(merged)\n",
        "          merged = Dense(self.number_dense_units, activation=self.activation_function)(merged)\n",
        "          merged = BatchNormalization()(merged)\n",
        "          merged = Dropout(self.rate_drop_dense)(merged)\n",
        "          preds = Dense(1, activation='sigmoid')(merged)\n",
        "\n",
        "          model = Model(inputs=[sequence_1_input, sequence_2_input], outputs=preds)\n",
        "          model.compile(loss ='binary_crossentropy', optimizer='nadam', metrics=['acc'])\n",
        "\n",
        "          early_stopping = EarlyStopping(monitor='loss', patience=20)\n",
        "\n",
        "          STAMP = 'lstm_%d_%d_%.2f_%.2f' % (\n",
        "          self.number_lstm_units, self.number_dense_units, self.rate_drop_lstm, self.rate_drop_dense)\n",
        "\n",
        "          checkpoint_dir = model_save_directory + 'checkpoints/' + str(int(time.time())) + '/'\n",
        "\n",
        "          if not os.path.exists(checkpoint_dir):\n",
        "              os.makedirs(checkpoint_dir)\n",
        "\n",
        "          bst_model_path = checkpoint_dir + STAMP + '.h5'\n",
        "\n",
        "          model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=False)\n",
        "\n",
        "          tensorboard = TensorBoard(log_dir=checkpoint_dir + \"logs/{}\".format(time.time()))\n",
        "\n",
        "          model.fit([train_data_x1, train_data_x2], train_labels,\n",
        "                    validation_data=([val_data_x1, val_data_x2], val_labels),\n",
        "                    epochs=100, batch_size=64, shuffle=True,\n",
        "                    callbacks=[early_stopping, model_checkpoint, tensorboard])\n",
        "\n",
        "          # Save the trained model to a file\n",
        "          model.save(model_save_directory + 'best_model_flair.h5')\n",
        "\n",
        "          return bst_model_path\n",
        "\n",
        "    def train_model_no_embedding(self, sentences_pair, is_similar, model_save_directory='./', fold=1):\n",
        "        \"\"\"\n",
        "        Train a Siamese LSTM model without any embedding.\n",
        "        Args:\n",
        "            sentences_pair (list): List of tuple of sentence pairs.\n",
        "            is_similar (list): Target value 1 if the same sentence pairs are similar, otherwise 0.\n",
        "            model_save_directory (str): Working directory for where to save models.\n",
        "            fold (int): Fold number for the model.\n",
        "        Returns:\n",
        "            best_model_path (str): Path of the best model.\n",
        "        \"\"\"\n",
        "        train_data_x1, train_data_x2, train_labels, \\\n",
        "        val_data_x1, val_data_x2, val_labels = create_train_dev_set_no_embedding(sentences_pair,\n",
        "                                                                              is_similar, self.max_sequence_length,\n",
        "                                                                              self.validation_split_ratio)\n",
        "        if train_data_x1 is None:\n",
        "            print(\"++++ !! Failure: Unable to train model ++++\")\n",
        "            return None\n",
        "\n",
        "        # Creating LSTM Encoder\n",
        "        lstm_layer = Bidirectional(LSTM(self.number_lstm_units, dropout=self.rate_drop_lstm,\n",
        "                                        recurrent_dropout=self.rate_drop_lstm, return_sequences=True))\n",
        "\n",
        "        # Creating LSTM Encoder layer for First Sentence\n",
        "        sequence_1_input = Input(shape=(self.max_sequence_length, 1), dtype='float32')\n",
        "        x1 = lstm_layer(sequence_1_input)\n",
        "\n",
        "        # Creating LSTM Encoder layer for Second Sentence\n",
        "        sequence_2_input = Input(shape=(self.max_sequence_length, 1), dtype='float32')\n",
        "        x2 = lstm_layer(sequence_2_input)\n",
        "\n",
        "        # Merging two LSTM-encoded vectors from sentences to\n",
        "        # pass them to dense layer applying dropout and batch normalization\n",
        "        merged = concatenate([x1, x2])\n",
        "        merged = BatchNormalization()(merged)\n",
        "        merged = Dropout(self.rate_drop_dense)(merged)\n",
        "        merged = Dense(self.number_dense_units, activation=self.activation_function)(merged)\n",
        "        merged = BatchNormalization()(merged)\n",
        "        merged = Dropout(self.rate_drop_dense)(merged)\n",
        "        preds = Dense(1, activation='sigmoid')(merged)\n",
        "\n",
        "        model = Model(inputs=[sequence_1_input, sequence_2_input], outputs=preds)\n",
        "        model.compile(loss ='binary_crossentropy', optimizer='nadam', metrics=['acc'])\n",
        "\n",
        "        early_stopping = EarlyStopping(monitor='loss', patience=20)\n",
        "\n",
        "        model_save_path = os.path.join(model_save_directory, f\"model_fold_{fold}.h5\")\n",
        "        model_checkpoint = ModelCheckpoint(model_save_path, save_best_only=True, save_weights_only=False)\n",
        "\n",
        "        tensorboard_log_dir = os.path.join(model_save_directory, f\"logs/fold_{fold}\")\n",
        "        tensorboard = TensorBoard(log_dir=tensorboard_log_dir)\n",
        "\n",
        "        # Reshape the target labels to match the shape of predicted logits\n",
        "        train_labels = train_labels.reshape((-1, 1))\n",
        "        val_labels = val_labels.reshape((-1, 1))\n",
        "\n",
        "        model.fit([train_data_x1, train_data_x2], train_labels,\n",
        "                  validation_data=([val_data_x1, val_data_x2], val_labels),\n",
        "                  epochs=100, batch_size=64, shuffle=True,\n",
        "                  callbacks=[early_stopping, model_checkpoint, tensorboard])\n",
        "\n",
        "        # Save the trained model to a file\n",
        "        model.save(model_save_directory + 'best_model_no.h5')\n",
        "\n",
        "        return model_save_path\n",
        "\n",
        "\n",
        "    def find_best_fold(self, sentences_pair, is_similar, embedding_meta_data, model_save_directory='./', num_folds = 10):\n",
        "        \"\"\"\n",
        "        Train Siamese network to find similarity between sentences in `sentences_pair`\n",
        "            Steps Involved:\n",
        "                1. Pass the each from sentences_pairs  to bidirectional LSTM encoder.\n",
        "                2. Merge the vectors from LSTM encodes and passed to dense layer.\n",
        "                3. Pass the  dense layer vectors to sigmoid output layer.\n",
        "                4. Use cross entropy loss to train weights\n",
        "        Args:\n",
        "            sentences_pair (list): list of tuple of sentence pairs\n",
        "            is_similar (list): target value 1 if same sentences pair are similar otherwise 0\n",
        "            embedding_meta_data (dict): dict containing tokenizer and word embedding matrix\n",
        "            model_save_directory (str): working directory for where to save models\n",
        "        Returns:\n",
        "            return (best_model_path):  path of best model\n",
        "        \"\"\"\n",
        "        tokenizer, embedding_matrix = embedding_meta_data['tokenizer'], embedding_meta_data['embedding_matrix']\n",
        "\n",
        "\n",
        "        train_data_x1, train_data_x2, train_labels, leaks_train, \\\n",
        "        val_data_x1, val_data_x2, val_labels, leaks_val = create_train_dev_set(tokenizer, sentences_pair,\n",
        "                                                                               is_similar, self.max_sequence_length,\n",
        "                                                                               self.validation_split_ratio)\n",
        "\n",
        "        inputs1, inputs2, targets, leaks = create_train_dev_set_for_folds(tokenizer, sentences_pair,\n",
        "                                                                               is_similar, self.max_sequence_length,\n",
        "                                                                               self.validation_split_ratio)\n",
        "        if inputs1 is None:\n",
        "            print(\"++++ !! Failure: Unable to train model ++++\")\n",
        "            return None\n",
        "\n",
        "        nb_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "        # define the kfolds\n",
        "        kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "        # Define per-fold score containers\n",
        "        acc_per_fold = []\n",
        "        loss_per_fold = []\n",
        "\n",
        "\n",
        "        inputs = []\n",
        "        for i in range(len(inputs1)):\n",
        "            inputs.append([inputs1[i],inputs2[i], leaks[i]])\n",
        "\n",
        "        inputs = np.array(inputs)\n",
        "\n",
        "        best_fold = None\n",
        "        best_accuracy = 0.0\n",
        "        fold_no = 1\n",
        "\n",
        "\n",
        "        for train, test in kfold.split(inputs, targets):\n",
        "            print(\"train:\" + str(train))\n",
        "            print(\"test:\" + str(test))\n",
        "\n",
        "            # Creating word embedding layer\n",
        "            embedding_layer = Embedding(nb_words, self.embedding_dim, weights=[embedding_matrix],\n",
        "                                        input_length=self.max_sequence_length, trainable=False)\n",
        "\n",
        "            # Creating LSTM Encoder\n",
        "            lstm_layer = Bidirectional(LSTM(self.number_lstm_units, dropout=self.rate_drop_lstm, recurrent_dropout=self.rate_drop_lstm))\n",
        "\n",
        "            # Creating LSTM Encoder layer for First Sentence\n",
        "            sequence_1_input = Input(shape=(self.max_sequence_length,), dtype='int32')\n",
        "            embedded_sequences_1 = embedding_layer(sequence_1_input)\n",
        "            x1 = lstm_layer(embedded_sequences_1)\n",
        "\n",
        "            # Creating LSTM Encoder layer for Second Sentence\n",
        "            sequence_2_input = Input(shape=(self.max_sequence_length,), dtype='int32')\n",
        "            embedded_sequences_2 = embedding_layer(sequence_2_input)\n",
        "            x2 = lstm_layer(embedded_sequences_2)\n",
        "\n",
        "            # Creating leaks input\n",
        "            leaks_input = Input(shape=(leaks_train.shape[1],))\n",
        "            leaks_dense = Dense(int(self.number_dense_units/2), activation=self.activation_function)(leaks_input)\n",
        "\n",
        "            # Merging two LSTM encodes vectors from sentences to\n",
        "            # pass it to dense layer applying dropout and batch normalisation\n",
        "            merged = concatenate([x1, x2, leaks_dense])\n",
        "            merged = BatchNormalization()(merged)\n",
        "            merged = Dropout(self.rate_drop_dense)(merged)\n",
        "            merged = Dense(self.number_dense_units, activation=self.activation_function)(merged)\n",
        "            merged = BatchNormalization()(merged)\n",
        "            merged = Dropout(self.rate_drop_dense)(merged)\n",
        "            preds = Dense(1, activation='sigmoid')(merged)\n",
        "\n",
        "            model = Model(inputs=[sequence_1_input, sequence_2_input, leaks_input], outputs=preds)\n",
        "            model.compile(loss ='binary_crossentropy', optimizer='nadam', metrics=['acc'])\n",
        "\n",
        "            # Generate a print\n",
        "            print('------------------------------------------------------------------------')\n",
        "            print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "            early_stopping = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "            STAMP = 'lstm_%d_%d_%.2f_%.2f' % (self.number_lstm_units, self.number_dense_units, self.rate_drop_lstm, self.rate_drop_dense)\n",
        "\n",
        "            checkpoint_dir = model_save_directory + 'checkpoints/' + str(int(time.time())) + '/'\n",
        "\n",
        "            if not os.path.exists(checkpoint_dir):\n",
        "                os.makedirs(checkpoint_dir)\n",
        "\n",
        "            bst_model_path = checkpoint_dir + STAMP + '.h5'\n",
        "\n",
        "            model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=False)\n",
        "\n",
        "            tensorboard = TensorBoard(log_dir=checkpoint_dir + \"logs/{}\".format(time.time()))\n",
        "\n",
        "            model.fit([inputs1[train],inputs2[train],leaks[train]],np.array(targets)[train],\n",
        "                      epochs=100, batch_size=64, shuffle=True,\n",
        "                      callbacks=[early_stopping, model_checkpoint, tensorboard])\n",
        "\n",
        "            # Generate generalization metrics\n",
        "            scores = model.evaluate([inputs1[test],inputs2[test],leaks[test]], targets[test], verbose=0)\n",
        "            print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "            acc_per_fold.append(scores[1] * 100)\n",
        "            loss_per_fold.append(scores[0])\n",
        "\n",
        "            # Check if current fold has better accuracy than previous best\n",
        "            if acc_fold > best_accuracy:\n",
        "              best_accuracy = acc_fold\n",
        "              best_fold = fold_no\n",
        "              best_model_path = bst_model_path\n",
        "\n",
        "\n",
        "            # Increase fold number\n",
        "            fold_no = fold_no + 1\n",
        "\n",
        "        # == Provide average scores ==\n",
        "        print('------------------------------------------------------------------------')\n",
        "        print('Score per fold')\n",
        "        for i in range(0, len(acc_per_fold)):\n",
        "            print('------------------------------------------------------------------------')\n",
        "            print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "        print('------------------------------------------------------------------------')\n",
        "        print('Average scores for all folds:')\n",
        "        print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "        print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "        print('------------------------------------------------------------------------')\n",
        "\n",
        "        # Save the best model from the best fold\n",
        "        if best_fold is not None:\n",
        "          print(f\"Best fold: {best_fold}\")\n",
        "          print(f\"Best accuracy: {best_accuracy}%\")\n",
        "          print(f\"Saving best model from fold {best_fold}...\")\n",
        "\n",
        "          # Load the best model from the saved checkpoint\n",
        "          best_model = keras.models.load_model(best_model_path)\n",
        "\n",
        "          # Save the best model to a separate file\n",
        "          best_model_save_path = os.path.join(model_save_directory, \"best_model.h5\")\n",
        "          best_model.save(best_model_save_path)\n",
        "          print(f\"Best model saved to {best_model_save_path}\")\n",
        "\n",
        "          return best_model_save_path\n",
        "\n",
        "    def update_model_char(self, saved_model_path, new_sentences_pair, is_similar, char_embedding_meta_data):\n",
        "        \"\"\"\n",
        "        Update trained siamese model for given new sentence pairs.\n",
        "            Steps Involved:\n",
        "                1. Pass each sentence from new_sentences_pair to bidirectional LSTM encoder.\n",
        "                2. Merge the vectors from LSTM encoders and pass them to the dense layer.\n",
        "                3. Pass the dense layer vectors to the sigmoid output layer.\n",
        "                4. Use cross-entropy loss to train weights.\n",
        "        Args:\n",
        "            saved_model_path (str): Model path of the already trained siamese model.\n",
        "            new_sentences_pair (list): List of tuples of new sentence pairs.\n",
        "            is_similar (list): Target value 1 if the same sentence pairs are similar, otherwise 0.\n",
        "            char_embedding_meta_data (dict): Dictionary containing tokenizer and character embedding matrix.\n",
        "        Returns:\n",
        "            return (best_model_path): Path of the best model.\n",
        "        \"\"\"\n",
        "        tokenizer = char_embedding_meta_data['tokenizer']\n",
        "        train_data_x1, train_data_x2, train_labels, \\\n",
        "        val_data_x1, val_data_x2, val_labels = create_train_dev_set(tokenizer, new_sentences_pair,\n",
        "                                                                  is_similar, self.max_sequence_length,\n",
        "                                                                  self.validation_split_ratio)\n",
        "        model = load_model(saved_model_path)\n",
        "        model_file_name = saved_model_path.split('/')[-1]\n",
        "        new_model_checkpoint_path = saved_model_path.split('/')[:-2] + str(int(time.time())) + '/'\n",
        "\n",
        "        new_model_path = new_model_checkpoint_path + model_file_name\n",
        "        model_checkpoint = ModelCheckpoint(new_model_checkpoint_path + model_file_name,\n",
        "                                          save_best_only=True, save_weights_only=False)\n",
        "\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "        tensorboard = TensorBoard(log_dir=new_model_checkpoint_path + \"logs/{}\".format(time.time()))\n",
        "\n",
        "        model.fit([train_data_x1, train_data_x2], train_labels,\n",
        "                  validation_data=([val_data_x1, val_data_x2], val_labels),\n",
        "                  epochs=50, batch_size=3, shuffle=True,\n",
        "                  callbacks=[early_stopping, model_checkpoint, tensorboard])\n",
        "\n",
        "        return new_model_path\n",
        "\n",
        "    def update_model_word(self, saved_model_path, new_sentences_pair, is_similar, embedding_meta_data):\n",
        "        \"\"\"\n",
        "        Update trained siamese model for given new sentences pairs\n",
        "            Steps Involved:\n",
        "                1. Pass the each from sentences from new_sentences_pair to bidirectional LSTM encoder.\n",
        "                2. Merge the vectors from LSTM encodes and passed to dense layer.\n",
        "                3. Pass the  dense layer vectors to sigmoid output layer.\n",
        "                4. Use cross entropy loss to train weights\n",
        "        Args:\n",
        "            model_path (str): model path of already trained siamese model\n",
        "            new_sentences_pair (list): list of tuple of new sentences pairs\n",
        "            is_similar (list): target value 1 if same sentences pair are similar otherwise 0\n",
        "            embedding_meta_data (dict): dict containing tokenizer and word embedding matrix\n",
        "        Returns:\n",
        "            return (best_model_path):  path of best model\n",
        "        \"\"\"\n",
        "        tokenizer = embedding_meta_data['tokenizer']\n",
        "        train_data_x1, train_data_x2, train_labels, \\\n",
        "        val_data_x1, val_data_x2, val_labels  = create_train_dev_set(tokenizer, new_sentences_pair,\n",
        "                                                                               is_similar, self.max_sequence_length,\n",
        "                                                                               self.validation_split_ratio)\n",
        "        model = load_model(saved_model_path)\n",
        "        model_file_name = saved_model_path.split('/')[-1]\n",
        "        new_model_checkpoint_path  = saved_model_path.split('/')[:-2] + str(int(time.time())) + '/'\n",
        "\n",
        "        new_model_path = new_model_checkpoint_path + model_file_name\n",
        "        model_checkpoint = ModelCheckpoint(new_model_checkpoint_path + model_file_name,\n",
        "                                           save_best_only=True, save_weights_only=False)\n",
        "\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "        tensorboard = TensorBoard(log_dir=new_model_checkpoint_path + \"logs/{}\".format(time.time()))\n",
        "\n",
        "        model.fit([train_data_x1, train_data_x2, leaks_train], train_labels,\n",
        "                  validation_data=([val_data_x1, val_data_x2, leaks_val], val_labels),\n",
        "                  epochs=50, batch_size=3, shuffle=True,\n",
        "                  callbacks=[early_stopping, model_checkpoint, tensorboard])\n",
        "\n",
        "        return new_model_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LeqYvOpWpRc"
      },
      "source": [
        "# Data normalisation\n",
        "\n",
        "### Western style adress normalisation\n",
        "\n",
        "-> Street number, street name, postal code , city name\n",
        "\n",
        "-> Stop words removal\n",
        "\n",
        "-> UTF-8 decoding\n",
        "\n",
        "-> Comma deletion\n",
        "\n",
        "-> Punctuations strip\n",
        "\n",
        "-> Tags strip\n",
        "\n",
        "-> Special character deletion\n",
        "\n",
        "-> Adding random names or company names before the adress (new token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Tbw1PzXWpRd",
        "outputId": "a039afca-b23a-4589-aec8-5d580637ed0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 url\n",
            "2                         reeves 1 huelgaass altwies\n",
            "3                      browning 11 huelgaass altwies\n",
            "4                       padilla 13 huelgaass altwies\n",
            "7  vestian global workplace services  1 brem wee ...\n",
            "8                    keihin fie  2a brem wee altwies\n",
            "                                                      url\n",
            "187104  yalamanchili software exports  13 duerfstrooss...\n",
            "187105                        lowe 17 duerfstrooss zittig\n",
            "187108                                      reed 1 zittig\n",
            "187111                        athena bpo  1 millen zittig\n",
            "187112            tube products of india  2 millen zittig\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import csv\n",
        "import random\n",
        "import json\n",
        "from gensim.parsing.preprocessing import remove_stopwords,strip_punctuation,STOPWORDS,strip_tags\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from collections import Counter\n",
        "\n",
        "person_names = []\n",
        "company_names = []\n",
        "\n",
        "# Prepare the data by reading the file decoding and removing non interesting row\n",
        "def prepare_dataframe():\n",
        "\n",
        "    # Context manager\n",
        "    with open(\"drive/MyDrive/urls_3.json\", \"r\", encoding=\"utf-8\") as json_file:\n",
        "      data = json.load(json_file)\n",
        "\n",
        "    # Create a DataFrame from the loaded JSON data\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Convert url from object to str\n",
        "    df['url'] = df['url'].astype('str')\n",
        "\n",
        "    # Select rows that are actual adresses (removes header such as {\"title\": \"Addresses\", \"url\": \"/addresses/?lang=en\"})\n",
        "    filtered = df[df['url'].str.match(\"\\/addresses\\/\\S+\\/.*\")]\n",
        "\n",
        "    return filtered\n",
        "\n",
        "# Normalize adress from the JSON file\n",
        "def western_normalization(x,special_char_delete = False,strip_punctuations = True,strip_tag = True, stop_word_normalize = True, delete_comma = True, delete_special_character = False, digit_word_split = False, word_digit_split = True):\n",
        "    # Lower-case it\n",
        "    x = x.lower()\n",
        "\n",
        "    # Supress '?','\\addresses\\'lang=.*,[],\n",
        "    x = re.sub(r\"\\?|lang=.*|\\/addresses\\/|\\[|\\]\" ,\"\",x)\n",
        "\n",
        "    # Tokenize by splitting on the separator\n",
        "    x = x.split(\"/\")\n",
        "\n",
        "    # Re-order token to Street number, street name, postal code and city name by swapping element position\n",
        "    temp = x[0]\n",
        "    x[0] = x[-1]\n",
        "    x[-1]= temp\n",
        "\n",
        "    # Combine all elements between the first and last element of the list\n",
        "    x[1 : -1] = [\"\".join(x[1 : -1])]\n",
        "\n",
        "    # List to String\n",
        "    x = ' '.join(x)\n",
        "\n",
        "    # Options\n",
        "    if stop_word_normalize:\n",
        "        # Delete stop word\n",
        "        x = stop_word_normalization(x)\n",
        "\n",
        "    if delete_comma:\n",
        "        # Delete commas\n",
        "        x = comma_deletion(x)\n",
        "\n",
        "    if digit_word_split:\n",
        "        # Digit-word split\n",
        "        x = re.sub(r'([-+]?[0-9]+\\.?[0-9]*)([A-Za-z]+)', r'\\1 \\2', x)\n",
        "\n",
        "    if word_digit_split:\n",
        "        # Word-digit split\n",
        "        x = re.sub(r'([A-Za-z]+)([-+]?[0-9]+\\.?[0-9]*)', r'\\1 \\2', x)\n",
        "\n",
        "    if strip_punctuations:\n",
        "        # Strip punctuation\n",
        "        x = strip_punctuation(x)\n",
        "\n",
        "    if strip_tag:\n",
        "        # Strip tags\n",
        "        x = strip_tags(x)\n",
        "\n",
        "    if special_char_delete:\n",
        "        # Delete special characters\n",
        "        x = special_char_deletion(x)\n",
        "\n",
        "    # Remove single character remaining\n",
        "    x = re.sub(r\"\\b[a-zA-Z]\\s\",\"\",x)\n",
        "    # Replace multiple spaces occurence with one\n",
        "    return re.sub(' +', ' ', x)\n",
        "\n",
        "# Delete comma\n",
        "def comma_deletion(x):\n",
        "    return re.sub(r\",\",\"\",x)\n",
        "\n",
        "# Delete special character\n",
        "def special_char_deletion(x):\n",
        "    return re.sub(\"[^A-Z]\", \" \", x,0,re.IGNORECASE)\n",
        "\n",
        "# Define a list of adresses stop words and delete them from the street names return a str without stop words\n",
        "def stop_word_normalization(x):\n",
        "\n",
        "    # TODO: place all of the stop words in an external file and load it with context manager\n",
        "\n",
        "    # Deleting adresses stop words could introduce ambiguity e.g: street x, city y AND route x, city y coul lead to x,y and x,y\n",
        "\n",
        "\n",
        "    # English adresses stop words\n",
        "    english_adresses_stop_words = ['avenue','ave','blvd','boulevard','box','cir','court','ct','drive','dr','lane','ln'\n",
        "    ,'loop','lp','pl','place','po','pob','pt','rd','road','route','rr','rte','rural','sq','st','ste','rural','sq',\n",
        "    'st','ste','street','suit','trl','way','wy','a','an','and','are','as','at','be','but','by','for','if','in','into',\n",
        "    'is','it','no','not','of','on','or','such','that','the','their','then','there','these','they','to','this','to','was',\n",
        "    'will','with','parc',' l ',' d ']\n",
        "\n",
        "    # French adresses stop words\n",
        "    french_adresses_stop_words = ['avenue','ave','boulevard','blvd','rue','Route','route','route de','chemin','de','du',\"l '\",'des',\n",
        "                                 'impasse','la','les','le','à','a','cité','résidence',\"d '\",'ruelle','cours','quartier',\n",
        "                                 'lotissement','allée',\"l'\",\"d'\",\"-\"]\n",
        "    # German adresses stop words\n",
        "    german_stop_words = ['op der','gare','um','bei der','Hannert dem','op','der','an','am','beim','de','bei','zaer','zëtteger']\n",
        "\n",
        "    # All of the stop words\n",
        "    stop_words = english_adresses_stop_words + french_adresses_stop_words + german_stop_words\n",
        "\n",
        "    # All of the stop words + gensim dictionnary of stop words\n",
        "    all_stopwords_gensim = STOPWORDS.union(set(stop_words))\n",
        "\n",
        "    # Remove stop words\n",
        "    return \" \".join(w for w in x.split() if w not in all_stopwords_gensim)\n",
        "\n",
        "def initialize_names():\n",
        "\n",
        "    global person_names\n",
        "    with open('drive/MyDrive/most-common-name_2Fsurnames.csv', 'r') as file:\n",
        "        reader = csv.reader(file)\n",
        "        person_names = list(reader)\n",
        "    random.shuffle(person_names)\n",
        "\n",
        "def initialize_company_names():\n",
        "\n",
        "    global company_names\n",
        "    with open('drive/MyDrive/campanydata.csv', 'r') as file:\n",
        "        reader = csv.reader(file)\n",
        "        company_names = list(reader)\n",
        "    random.shuffle(company_names)  # Shuffle the list of names\n",
        "\n",
        "# Input x: string output x: string with an entity added\n",
        "def add_name(x):\n",
        "    global person_names, company_names\n",
        "    # Decide if we add company or person name\n",
        "    decision = random.choice([0,1])\n",
        "\n",
        "    # Pick a random name\n",
        "    if decision == 0 and person_names:\n",
        "\n",
        "      random_name = person_names.pop()[1]\n",
        "      x = random_name + ' ' + x\n",
        "\n",
        "      if not person_names:\n",
        "        initialize_names()\n",
        "        random_name = person_names.pop()[1]\n",
        "        x = random_name + ' ' + x\n",
        "\n",
        "    # Pick a random company name\n",
        "    if decision == 1 and company_names:\n",
        "        random_company_name = company_names.pop()[0]\n",
        "        x = random_company_name + ' ' + x\n",
        "\n",
        "        if not company_names:\n",
        "          initialize_company_names()\n",
        "          random_company_name = company_names.pop()[0]\n",
        "          x = random_company_name + ' ' + x\n",
        "\n",
        "    return x.lower()\n",
        "\n",
        "# Restructure the dataframe by spliting the column in 3 (street_number, street, city)\n",
        "def structure_data(address_df, seperator):\n",
        "\n",
        "    # Split in 3\n",
        "    address_df[['street_number','street','city']] = address_df['url'].str.split(seperator, expand = True)\n",
        "\n",
        "    # Delete duplicated\n",
        "    address_df = address_df.drop('url', axis=1)\n",
        "\n",
        "    return address_df\n",
        "\n",
        "# Return a normalized adress dataframe from a filered dataframe\n",
        "def normalize_adress(filtered_df):\n",
        "\n",
        "    # Apply the selected normalization to the filtered dataset\n",
        "    normalized = filtered_df['url'].apply(western_normalization)\n",
        "\n",
        "    # Convert normalized and unnormalized to a dataframe\n",
        "    normalized = normalized.to_frame()\n",
        "\n",
        "    return normalized\n",
        "\n",
        "def add_entity(normalized):\n",
        "\n",
        "    normalized = normalized['url'].apply(add_name)\n",
        "\n",
        "    # Convert normalized and unnormalized to a dataframe\n",
        "    normalized = normalized.to_frame()\n",
        "\n",
        "    return normalized\n",
        "\n",
        "\n",
        "# Testing purposes\n",
        "\n",
        "filtered_df = prepare_dataframe()\n",
        "initialize_company_names()\n",
        "initialize_names()\n",
        "normalized_df = normalize_adress(filtered_df)\n",
        "normalized_df = add_entity(normalized_df)\n",
        "\n",
        "print(normalized_df.head())\n",
        "print(normalized_df.tail())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB0kGvqSWpRf"
      },
      "source": [
        "# Data augmentation\n",
        "\n",
        "### - Keyboard subsitution typo () / done\n",
        "\n",
        "### - Random token permutation\n",
        "\n",
        "### - Character deletion\n",
        "\n",
        "### - Character insertion\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaIYKiQ5Ai-x",
        "outputId": "8f60c02d-9138-4699-e6b6-dd3656eca6d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Levenshtein\n",
            "  Downloading Levenshtein-0.21.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=2.3.0 (from Levenshtein)\n",
            "  Downloading rapidfuzz-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\n",
            "Successfully installed Levenshtein-0.21.1 rapidfuzz-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fBWuPoFWpRf",
        "outputId": "75e363c9-3e03-4cb6-80ce-a7eb7fb44b80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-4a7030bc0ba6>:145: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:145: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:145: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:161: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:161: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:161: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:129: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:129: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:129: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:177: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:177: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:177: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:194: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:194: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:194: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:145: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:161: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:129: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:145: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:161: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:129: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:145: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:161: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:129: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:177: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:194: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:177: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:194: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:177: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n",
            "<ipython-input-15-4a7030bc0ba6>:194: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return normalized_df.append(augmented_df)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evalAdd length: 500\n",
            "evalAddNegative length: 500\n",
            "evalAddTypo1 length: 500\n",
            "evalAddTypo2 length: 500\n",
            "evalAddTypo3 length: 500\n",
            "evalAddToken1 length: 500\n",
            "evalAddToken2 length: 500\n",
            "evalAddToken3 length: 500\n"
          ]
        }
      ],
      "source": [
        "import nlpaug.augmenter.char as nac\n",
        "import nlpaug.augmenter.word as naw\n",
        "import nlpaug.augmenter.sentence as nas\n",
        "import nlpaug.flow as nafc\n",
        "import numpy as np\n",
        "import string\n",
        "import random\n",
        "import string\n",
        "import math\n",
        "from random import randrange\n",
        "from nlpaug.util import Action\n",
        "\n",
        "\n",
        "# Keyboard substitution param\n",
        "# Higher-end of typo errors value :\n",
        "\n",
        "keyboard_aug_probability = 0.3\n",
        "keyboard_aug_max = 1\n",
        "\n",
        "# Aug tool\n",
        "aug = nac.KeyboardAug(include_numeric=False, include_special_char=False, aug_char_max=keyboard_aug_max, aug_word_p=keyboard_aug_probability)\n",
        "\n",
        "# Insertion param\n",
        "insertion_aug_proportion = 10\n",
        "\n",
        "# Deletion param\n",
        "deletion_aug_proportion = 10\n",
        "\n",
        "# Insert an element into a list at a random position\n",
        "def random_insert(lst, item):\n",
        "    lst.insert(randrange(len(lst)+1), item)\n",
        "    return \"\".join(lst)\n",
        "\n",
        "\n",
        "# Keyboard augmentation function\n",
        "def aug_keyboard(x, target_distance):\n",
        "    result = x\n",
        "    for _ in range(target_distance):\n",
        "        result = aug.augment(result)\n",
        "        result = \" \".join(result)\n",
        "        result = result.strip(\"'[]'\")\n",
        "        result = result.lower()\n",
        "    return result\n",
        "\n",
        "# Character insertion controlled by the number of insertions\n",
        "def aug_char_insert(x, target_distance):\n",
        "    x_augmented = list(x)\n",
        "    for _ in range(target_distance):\n",
        "        random_index = random.randint(0, len(x_augmented))\n",
        "        random_letter = random.choice(string.ascii_letters)\n",
        "        x_augmented.insert(random_index, random_letter.lower())\n",
        "    return ''.join(x_augmented)\n",
        "\n",
        "# Character deletion controlled by the number of deletions\n",
        "def aug_char_delete(x, target_distance):\n",
        "    x_augmented = list(x)\n",
        "    for _ in range(target_distance):\n",
        "        while True:\n",
        "            random_index = random.randint(0, len(x_augmented) - 1)\n",
        "            random_character = x_augmented[random_index]\n",
        "            if random_character != \" \":\n",
        "                break\n",
        "        x_augmented.pop(random_index)\n",
        "    return ''.join(x_augmented)\n",
        "\n",
        "# Permute tokens within the string according to the number of permutations\n",
        "def aug_random_permutation(x, target_distance):\n",
        "    x_augmented = x.split(\" \")\n",
        "    x_augmented[1: -1] = [\" \".join(x_augmented[1: -1])]\n",
        "    for _ in range(target_distance):\n",
        "        random.shuffle(x_augmented)\n",
        "    return unlist(x_augmented)\n",
        "\n",
        "\n",
        "# delete x amount of tokens\n",
        "def aug_delete_tokens(x, target_distance):\n",
        "    x_augmented = x.split(\" \")\n",
        "    x_augmented[1: -1] = [\" \".join(x_augmented[1: -1])]\n",
        "\n",
        "    num_tokens = len(x_augmented)\n",
        "\n",
        "    if target_distance > num_tokens:\n",
        "        return unlist(x_augmented)\n",
        "\n",
        "    for _ in range(target_distance):\n",
        "        random_index = random.randint(0, len(x_augmented) - 1)\n",
        "        x_augmented.pop(random_index)\n",
        "\n",
        "    return unlist(x_augmented)\n",
        "\n",
        "\n",
        "\n",
        "# Remove '[]' e.g: input: '[hello world]' -> output: hello world\n",
        "def unlist(x):\n",
        "    return ' '.join(x).strip(\"'[]'\")\n",
        "\n",
        "# return a sample of a df and indexes of the sampled records according to a proportion\n",
        "def get_sample_and_idx(normalized_df, proportion):\n",
        "\n",
        "    # Sample a proportion of the filtered set\n",
        "    to_augment_idx = normalized_df[\"url\"].sample(frac = proportion).index\n",
        "\n",
        "    # Create the dataframe using indexes\n",
        "    to_augment_df = normalized_df[\"url\"].loc[to_augment_idx]\n",
        "\n",
        "    # Convert to frame\n",
        "    to_augment_df = to_augment_df.to_frame()\n",
        "\n",
        "    # Sync the IDs of the augmented and normalized data\n",
        "    to_augment_df[\"ID\"] = normalized_df[\"ID\"].loc[to_augment_idx]\n",
        "\n",
        "    return to_augment_df, to_augment_idx\n",
        "\n",
        "# Augment the data by performing random keyboard substitution of character\n",
        "def augment_substitute_normalized_data(normalized_df, proportion, target_distance, append = False):\n",
        "\n",
        "    to_augment_df, to_augment_idx = get_sample_and_idx(normalized_df, proportion)\n",
        "\n",
        "    # Apply keyboard substitution\n",
        "    augmented_df = to_augment_df[\"url\"].apply(aug_keyboard, args=(target_distance,))\n",
        "\n",
        "    augmented_df = augmented_df.to_frame()\n",
        "\n",
        "    augmented_df[\"ID\"] = to_augment_df[\"ID\"]\n",
        "\n",
        "    if not append:\n",
        "        normalized_df = normalized_df.drop(to_augment_idx)\n",
        "\n",
        "    return normalized_df.append(augmented_df)\n",
        "\n",
        "# Augment the data by performing random character insertion\n",
        "def augment_insert_normalized_data(normalized_df, proportion, target_distance, append = False):\n",
        "\n",
        "    to_augment_df, to_augment_idx = get_sample_and_idx(normalized_df, proportion)\n",
        "\n",
        "    augmented_df = to_augment_df[\"url\"].apply(aug_char_insert, args=(target_distance,))\n",
        "\n",
        "    augmented_df = augmented_df.to_frame()\n",
        "\n",
        "    augmented_df[\"ID\"] = to_augment_df[\"ID\"]\n",
        "\n",
        "    if not append:\n",
        "        normalized_df = normalized_df.drop(to_augment_idx)\n",
        "\n",
        "    return normalized_df.append(augmented_df)\n",
        "\n",
        "# Augment the data by performing random character deletion\n",
        "def augment_delete_normalized_data(normalized_df, proportion, target_distance, append = False):\n",
        "\n",
        "    to_augment_df, to_augment_idx = get_sample_and_idx(normalized_df, proportion)\n",
        "\n",
        "    augmented_df = to_augment_df[\"url\"].apply(aug_char_delete, args=(target_distance,))\n",
        "\n",
        "    augmented_df = augmented_df.to_frame()\n",
        "\n",
        "    augmented_df[\"ID\"] = to_augment_df[\"ID\"]\n",
        "\n",
        "    if not append:\n",
        "        normalized_df = normalized_df.drop(to_augment_idx)\n",
        "\n",
        "    return normalized_df.append(augmented_df)\n",
        "\n",
        "# Randomly permute tokens in the string\n",
        "def augment_permute_tokens(normalized_df, proportion, target_distance, append = False):\n",
        "\n",
        "    to_augment_df, to_augment_idx = get_sample_and_idx(normalized_df, proportion)\n",
        "\n",
        "    augmented_df = to_augment_df[\"url\"].apply(aug_random_permutation, args=(target_distance,))\n",
        "\n",
        "    augmented_df = augmented_df.to_frame()\n",
        "\n",
        "    augmented_df[\"ID\"] = to_augment_df[\"ID\"]\n",
        "\n",
        "    if not append:\n",
        "        normalized_df = normalized_df.drop(to_augment_idx)\n",
        "\n",
        "    return normalized_df.append(augmented_df)\n",
        "\n",
        "\n",
        "# Randomly delete tokens\n",
        "def augment_delete_tokens(normalized_df,  proportion, target_distance, append = False):\n",
        "\n",
        "    to_augment_df, to_augment_idx = get_sample_and_idx(normalized_df, proportion)\n",
        "\n",
        "    augmented_df = to_augment_df[\"url\"].apply(aug_delete_tokens, args=(target_distance,))\n",
        "\n",
        "    augmented_df = augmented_df.to_frame()\n",
        "\n",
        "    augmented_df[\"ID\"] = to_augment_df[\"ID\"]\n",
        "\n",
        "    if not append:\n",
        "        normalized_df = normalized_df.drop(to_augment_idx)\n",
        "\n",
        "    return normalized_df.append(augmented_df)\n",
        "\n",
        "\n",
        "# Augmentation function for the training\n",
        "def augment_df(normalized_df, insert_char = True, delete_char = True, substitute_char = True, permute_tokens = True, delete_tokens = True):\n",
        "\n",
        "    augmented_df = normalized_df.copy()  # Create a copy of the original DataFrame\n",
        "\n",
        "    if insert_char:\n",
        "        augmented_df = augment_insert_normalized_data(augmented_df, 0.016, 1)\n",
        "        augmented_df = augment_insert_normalized_data(augmented_df, 0.016, 2)\n",
        "        augmented_df = augment_insert_normalized_data(augmented_df, 0.016, 3)\n",
        "    if delete_char:\n",
        "        augmented_df = augment_delete_normalized_data(augmented_df, 0.016, 1)\n",
        "        augmented_df = augment_delete_normalized_data(augmented_df, 0.016, 2)\n",
        "        augmented_df = augment_delete_normalized_data(augmented_df, 0.016, 3)\n",
        "    if substitute_char:\n",
        "        augmented_df = augment_substitute_normalized_data(augmented_df, 0.016, 1)\n",
        "        augmented_df = augment_substitute_normalized_data(augmented_df, 0.016, 2)\n",
        "        augmented_df = augment_substitute_normalized_data(augmented_df, 0.016, 3)\n",
        "    if permute_tokens:\n",
        "        augmented_df = augment_permute_tokens(augmented_df, 0.016, 1)\n",
        "        augmented_df = augment_permute_tokens(augmented_df, 0.016, 2)\n",
        "        augmented_df = augment_permute_tokens(augmented_df, 0.016, 3)\n",
        "    if delete_tokens:\n",
        "        augmented_df = augment_delete_tokens(augmented_df, 0.016, 1)\n",
        "        augmented_df = augment_delete_tokens(augmented_df, 0.016, 2)\n",
        "        augmented_df = augment_delete_tokens(augmented_df, 0.016, 3)\n",
        "\n",
        "\n",
        "    return augmented_df\n",
        "\n",
        "\n",
        "\n",
        "def augment_df_char(normalized_df, edit_distance, num_records):\n",
        "    total_records = normalized_df.shape[0]\n",
        "\n",
        "    # Calculate the number of records for each augmentation method\n",
        "    insert_records = int(num_records * 0.34)\n",
        "    delete_records = int(num_records * 0.33)\n",
        "    substitute_records = num_records - (insert_records + delete_records)\n",
        "\n",
        "    # Randomly select records for each augmentation method\n",
        "    insert_df = normalized_df.sample(n=insert_records)\n",
        "    insert_df = augment_insert_normalized_data(insert_df, 1.0, edit_distance)\n",
        "\n",
        "    delete_df = normalized_df.drop(insert_df.index).sample(n=delete_records)\n",
        "    delete_df = augment_delete_normalized_data(delete_df, 1.0, edit_distance)\n",
        "\n",
        "    substitute_df = normalized_df.drop(insert_df.index).drop(delete_df.index)\n",
        "    substitute_df = augment_substitute_normalized_data(substitute_df, 1.0, edit_distance)\n",
        "\n",
        "    # Concatenate the augmented dataframes for each method\n",
        "    augmented_df = pd.concat([insert_df, delete_df, substitute_df])\n",
        "\n",
        "    return augmented_df\n",
        "\n",
        "\n",
        "def augment_df_tokens(normalized_df, edit_distance, num_records):\n",
        "    total_records = normalized_df.shape[0]\n",
        "    half_records = num_records // 2\n",
        "\n",
        "    # Randomly select records for token permutation\n",
        "    permute_df = normalized_df.sample(n=half_records)\n",
        "    permute_df = augment_permute_tokens(permute_df, 1.0, edit_distance)\n",
        "\n",
        "    # Select the remaining records for token deletion\n",
        "    delete_df = normalized_df.drop(permute_df.index).sample(n=half_records)\n",
        "    delete_df = augment_delete_tokens(delete_df, 1.0, edit_distance)\n",
        "\n",
        "    # Concatenate the two augmented dataframes\n",
        "    augmented_df = pd.concat([permute_df, delete_df])\n",
        "\n",
        "    return augmented_df\n",
        "\n",
        "\n",
        "# Create the training file with pair of adresses ad1 , ad2 , is_near_duplicate using the clean and dirty df\n",
        "def create_training_data(normalized_df, augmented_df, size):\n",
        "    coinflip = [1,0]\n",
        "    decision = random.choice(coinflip)\n",
        "    df_len = augmented_df.shape[0]\n",
        "    pointer = 0\n",
        "    training_data = []\n",
        "    for i in range(size):\n",
        "\n",
        "        # Pick same ID (near-duplicate, label as 1)\n",
        "        if decision == 1:\n",
        "\n",
        "            # Pick two element near duplicate (90%)\n",
        "            try:\n",
        "                element1 =  normalized_df.query(\"ID ==  @i\")[\"url\"].tolist()[0]\n",
        "                element2 =  augmented_df.query(\"ID ==  @i\")[\"url\"].tolist()[0]\n",
        "                # Swap city token (10%)\n",
        "                if i % 5 == 0 :\n",
        "                    random_pick = random.randint(0, (df_len-3))\n",
        "                    random_element = normalized_df.query(\"ID ==  @random_pick\")[\"url\"].tolist()[0]\n",
        "                    element2 = element2.split(\" \")\n",
        "                    element2[-1] = random_element.split(\" \")[-1]\n",
        "                    element2 = \" \".join(element2)\n",
        "                    decision= 0\n",
        "\n",
        "            except:\n",
        "                print(\"pick: \" + str(i))\n",
        "                print(\"value: \" + augmented_df.query(\"ID ==  @i\")[\"url\"].tolist())\n",
        "\n",
        "            training_data.append([element1, element2, decision])\n",
        "\n",
        "        # Pick another random ID (non duplicate label as 0)\n",
        "        else:\n",
        "            element1 =  augmented_df.query(\"ID ==  @i\")[\"url\"].tolist()[0]\n",
        "            try:\n",
        "                while True:\n",
        "                    random_pick = random.randint(0, (df_len-3))\n",
        "                    if random_pick is not i:\n",
        "                        element2 =  augmented_df.query(\"ID ==  @random_pick\")[\"url\"].tolist()[0]\n",
        "                        break;\n",
        "            except:\n",
        "                print(\"pick: \" + str(random_pick))\n",
        "                print(\"value: \" + augmented_df.query(\"ID ==  @random_pick\")[\"url\"])\n",
        "            training_data.append([element1, element2, decision])\n",
        "        decision = random.choice(coinflip)\n",
        "\n",
        "    return training_data\n",
        "\n",
        "def create_training_data2(normalized_df, augmented_df, size):\n",
        "    coinflip = [1, 0]\n",
        "    decision = random.choice(coinflip)\n",
        "    df_len = augmented_df.shape[0]\n",
        "    training_data = []\n",
        "\n",
        "    for i in range(size):\n",
        "        if decision == 1:\n",
        "            try:\n",
        "                element1 = normalized_df.iloc[i][\"url\"]\n",
        "                element2 = augmented_df.iloc[i][\"url\"]\n",
        "                if i % 5 == 0:\n",
        "                    random_pick = random.randint(0, df_len - 3)\n",
        "                    random_element = normalized_df.iloc[random_pick][\"url\"]\n",
        "                    element2 = element2.rsplit(\" \", 1)[0] + \" \" + random_element.rsplit(\" \", 1)[1]\n",
        "                    decision = 0\n",
        "            except Exception as e:\n",
        "                print(\"pick: \" + str(i))\n",
        "                print(\"value: \" + str(augmented_df.iloc[i][\"url\"]))\n",
        "                print(e)\n",
        "                continue\n",
        "            training_data.append([element1, element2, decision])\n",
        "        else:\n",
        "            element1 = augmented_df.iloc[i][\"url\"]\n",
        "            try:\n",
        "                while True:\n",
        "                    random_pick = random.randint(0, df_len - 3)\n",
        "                    if random_pick != i:\n",
        "                        element2 = augmented_df.iloc[random_pick][\"url\"]\n",
        "                        break\n",
        "            except Exception as e:\n",
        "                print(\"pick: \" + str(random_pick))\n",
        "                print(\"value: \" + str(augmented_df.iloc[random_pick][\"url\"]))\n",
        "                print(e)\n",
        "                continue\n",
        "            training_data.append([element1, element2, decision])\n",
        "        decision = random.choice(coinflip)\n",
        "\n",
        "    return training_data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_eval_data(normalized_df, augmented_df, near_duplicate, max_records=500):\n",
        "    evaluation_data = []\n",
        "\n",
        "    if near_duplicate == 1:\n",
        "        for idx in range(min(augmented_df.shape[0], max_records)):\n",
        "            element1 = normalized_df.iloc[idx][\"url\"]\n",
        "            element2 = augmented_df.iloc[idx][\"url\"]\n",
        "            evaluation_data.append([element1, element2, 1])\n",
        "    else:\n",
        "        for _ in range(min(augmented_df.shape[0], max_records)):\n",
        "            random_idx_1 = random.randint(0, normalized_df.shape[0] - 1)\n",
        "            random_idx_2 = random.randint(0, augmented_df.shape[0] - 1)\n",
        "            while random_idx_2 == random_idx_1:\n",
        "                random_idx_2 = random.randint(0, augmented_df.shape[0] - 1)\n",
        "            element1 = normalized_df.iloc[random_idx_1][\"url\"]\n",
        "            element2 = augmented_df.iloc[random_idx_2][\"url\"]\n",
        "            evaluation_data.append([element1, element2, 0])\n",
        "\n",
        "    return evaluation_data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create pairs of adresses to be passed as the model input\n",
        "def create_addresses_pairs(training_data):\n",
        "    # Pairs add1, add2, label\n",
        "    address1 = []\n",
        "    address2 = []\n",
        "    is_similar = []\n",
        "\n",
        "    for e in training_data:\n",
        "        address1.append(list(e)[0])\n",
        "        address2.append(list(e)[1])\n",
        "        is_similar.append(list(e)[2])\n",
        "\n",
        "    return address1,address2,is_similar\n",
        "\n",
        "\n",
        "def generate_evaluation_sets(normalized_df):\n",
        "    # Create the evaluation sets without any augmentation\n",
        "    eval_add = create_eval_data(normalized_df, normalized_df, 1)\n",
        "    eval_add_negative = create_eval_data(normalized_df, normalized_df, 0)\n",
        "\n",
        "\n",
        "\n",
        "    # Generate near-duplicate addresses with 1, 2, and 3 character manipulations\n",
        "    eval_add_typo1 = augment_df_char(normalized_df,1,500)\n",
        "    eval_add_typo1 = eval_add_typo1.sort_values(\"ID\")\n",
        "    eval_typo1_data = create_eval_data(normalized_df, eval_add_typo1, 1)\n",
        "\n",
        "    eval_add_typo2 = augment_df_char(normalized_df,2,500)\n",
        "    eval_add_typo2 = eval_add_typo2.sort_values(\"ID\")\n",
        "    eval_typo2_data = create_eval_data(normalized_df, eval_add_typo2, 1)\n",
        "\n",
        "    eval_add_typo3 = augment_df_char(normalized_df,3,500)\n",
        "    eval_add_typo3 = eval_add_typo3.sort_values(\"ID\")\n",
        "    eval_typo3_data = create_eval_data(normalized_df, eval_add_typo3, 1)\n",
        "\n",
        "    # Generate near-duplicate addresses with 1, 2, and 3 token manipulations\n",
        "    eval_add_token1 = augment_df_tokens(normalized_df, 1,500)\n",
        "    eval_add_token1 = eval_add_token1.sort_values(\"ID\")\n",
        "    eval_token1_data = create_eval_data(normalized_df, eval_add_token1, 1)\n",
        "\n",
        "    eval_add_token2 = augment_df_tokens(normalized_df, 2,500)\n",
        "    eval_add_token2 = eval_add_token2.sort_values(\"ID\")\n",
        "    eval_token2_data = create_eval_data(normalized_df, eval_add_token2, 1)\n",
        "\n",
        "    eval_add_token3 = augment_df_tokens(normalized_df, 3,500)\n",
        "    eval_add_token3 = eval_add_token3.sort_values(\"ID\")\n",
        "    eval_token3_data = create_eval_data(normalized_df, eval_add_token3, 1)\n",
        "\n",
        "\n",
        "\n",
        "    return eval_add, eval_add_negative, eval_typo1_data, eval_typo2_data, eval_typo3_data, eval_token1_data, eval_token2_data, eval_token3_data\n",
        "\n",
        "\n",
        "# Uncomment at each Kernel restart\n",
        "# normalized_df.insert(0, 'ID', range(0,len(normalized_df)))\n",
        "\n",
        "\n",
        "# Augment the data in one df\n",
        "augmented_df = augment_df(normalized_df)\n",
        "\n",
        "# Sync\n",
        "augmented_df = augmented_df.sort_values(\"ID\")\n",
        "\n",
        "# Create the training data\n",
        "training_data = create_training_data2(normalized_df, augmented_df, 15000)\n",
        "\n",
        "\n",
        "# Split the training data in pairs\n",
        "sentences1, sentences2, is_similar = create_addresses_pairs(training_data)\n",
        "\n",
        "\n",
        "# Evaluation sets\n",
        "evalAdd, evalAddNegative, evalAddTypo1, evalAddTypo2, evalAddTypo3, evalAddToken1, evalAddToken2, evalAddToken3 = generate_evaluation_sets(normalized_df)\n",
        "\n",
        "print(\"evalAdd length:\", len(evalAdd))\n",
        "print(\"evalAddNegative length:\", len(evalAddNegative))\n",
        "print(\"evalAddTypo1 length:\", len(evalAddTypo1))\n",
        "print(\"evalAddTypo2 length:\", len(evalAddTypo2))\n",
        "print(\"evalAddTypo3 length:\", len(evalAddTypo3))\n",
        "print(\"evalAddToken1 length:\", len(evalAddToken1))\n",
        "print(\"evalAddToken2 length:\", len(evalAddToken2))\n",
        "print(\"evalAddToken3 length:\", len(evalAddToken3))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoVcmzcNWpRh"
      },
      "source": [
        "# Finding best fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "YGSfWeFmWpRh",
        "outputId": "2366fadd-91fd-460b-c338-40b5825f936b",
        "scrolled": true
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-505086a7b8da>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m######## Word Embedding ############\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_embed_meta_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_pair\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0msiamese_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EMBEDDING_DIM'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m embedding_meta_data = {\n",
            "\u001b[0;32m<ipython-input-27-2174b074dd5b>\u001b[0m in \u001b[0;36mword_embed_meta_data\u001b[0;34m(documents, embedding_dim)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0membedding_matrix\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mword_index\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvector\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \"\"\"\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-2174b074dd5b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0membedding_matrix\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mword_index\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvector\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \"\"\"\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'lower'"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "\n",
        "\n",
        "\n",
        "######## Word Embedding ############\n",
        "\n",
        "tokenizer, embedding_matrix = word_embed_meta_data(sentences1 + sentences2,  siamese_config['EMBEDDING_DIM'])\n",
        "\n",
        "embedding_meta_data = {\n",
        "\t'tokenizer': tokenizer,\n",
        "\t'embedding_matrix': embedding_matrix\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "######## Training ########\n",
        "\n",
        "class Configuration(object):\n",
        "    \"\"\"Dump stuff here\"\"\"\n",
        "\n",
        "CONFIG = Configuration()\n",
        "\n",
        "CONFIG.embedding_dim = siamese_config['EMBEDDING_DIM']\n",
        "CONFIG.max_sequence_length = siamese_config['MAX_SEQUENCE_LENGTH']\n",
        "CONFIG.number_lstm_units = siamese_config['NUMBER_LSTM']\n",
        "CONFIG.rate_drop_lstm = siamese_config['RATE_DROP_LSTM']\n",
        "CONFIG.number_dense_units = siamese_config['NUMBER_DENSE_UNITS']\n",
        "CONFIG.activation_function = siamese_config['ACTIVATION_FUNCTION']\n",
        "CONFIG.rate_drop_dense = siamese_config['RATE_DROP_DENSE']\n",
        "CONFIG.validation_split_ratio = siamese_config['VALIDATION_SPLIT']\n",
        "\n",
        "siamese = SiameseBiLSTM(CONFIG.embedding_dim , CONFIG.max_sequence_length, CONFIG.number_lstm_units , CONFIG.number_dense_units, CONFIG.rate_drop_lstm, CONFIG.rate_drop_dense, CONFIG.activation_function, CONFIG.validation_split_ratio)\n",
        "\n",
        "best_model = siamese.find_best_fold(sentences_pair, is_similar, embedding_meta_data, model_save_directory='./')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwfMqAxJWpRi"
      },
      "source": [
        "# Training Siamese LSTM (word embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn4wHTg1WpRi",
        "outputId": "a513d39d-fe26-4d2e-96e8-ede0f1cb2a50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding matrix shape: (17602, 300)\n",
            "Null word embeddings: 1\n",
            "Epoch 1/100\n",
            "211/211 [==============================] - 57s 182ms/step - loss: 0.5101 - acc: 0.7662 - val_loss: 0.4971 - val_acc: 0.8487\n",
            "Epoch 2/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.3500 - acc: 0.8564 - val_loss: 0.3147 - val_acc: 0.8887\n",
            "Epoch 3/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.2913 - acc: 0.8816 - val_loss: 0.2356 - val_acc: 0.9160\n",
            "Epoch 4/100\n",
            "211/211 [==============================] - 40s 188ms/step - loss: 0.2668 - acc: 0.8973 - val_loss: 0.1929 - val_acc: 0.9240\n",
            "Epoch 5/100\n",
            "211/211 [==============================] - 38s 180ms/step - loss: 0.2377 - acc: 0.9056 - val_loss: 0.1783 - val_acc: 0.9260\n",
            "Epoch 6/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.2239 - acc: 0.9113 - val_loss: 0.1916 - val_acc: 0.9293\n",
            "Epoch 7/100\n",
            "211/211 [==============================] - 37s 174ms/step - loss: 0.2115 - acc: 0.9153 - val_loss: 0.1639 - val_acc: 0.9327\n",
            "Epoch 8/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.2066 - acc: 0.9181 - val_loss: 0.1596 - val_acc: 0.9420\n",
            "Epoch 9/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.1946 - acc: 0.9198 - val_loss: 0.1485 - val_acc: 0.9407\n",
            "Epoch 10/100\n",
            "211/211 [==============================] - 41s 196ms/step - loss: 0.1984 - acc: 0.9225 - val_loss: 0.1579 - val_acc: 0.9340\n",
            "Epoch 11/100\n",
            "211/211 [==============================] - 37s 173ms/step - loss: 0.1879 - acc: 0.9261 - val_loss: 0.1643 - val_acc: 0.9380\n",
            "Epoch 12/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.1806 - acc: 0.9284 - val_loss: 0.1614 - val_acc: 0.9333\n",
            "Epoch 13/100\n",
            "211/211 [==============================] - 37s 174ms/step - loss: 0.1769 - acc: 0.9260 - val_loss: 0.1487 - val_acc: 0.9427\n",
            "Epoch 14/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.1758 - acc: 0.9279 - val_loss: 0.1500 - val_acc: 0.9387\n",
            "Epoch 15/100\n",
            "211/211 [==============================] - 37s 177ms/step - loss: 0.1766 - acc: 0.9289 - val_loss: 0.1384 - val_acc: 0.9420\n",
            "Epoch 16/100\n",
            "211/211 [==============================] - 41s 194ms/step - loss: 0.1686 - acc: 0.9310 - val_loss: 0.1452 - val_acc: 0.9367\n",
            "Epoch 17/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.1650 - acc: 0.9324 - val_loss: 0.1686 - val_acc: 0.9353\n",
            "Epoch 18/100\n",
            "211/211 [==============================] - 38s 180ms/step - loss: 0.1672 - acc: 0.9295 - val_loss: 0.1477 - val_acc: 0.9373\n",
            "Epoch 19/100\n",
            "211/211 [==============================] - 37s 178ms/step - loss: 0.1667 - acc: 0.9293 - val_loss: 0.1348 - val_acc: 0.9473\n",
            "Epoch 20/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.1588 - acc: 0.9357 - val_loss: 0.1313 - val_acc: 0.9420\n",
            "Epoch 21/100\n",
            "211/211 [==============================] - 41s 194ms/step - loss: 0.1617 - acc: 0.9347 - val_loss: 0.1363 - val_acc: 0.9380\n",
            "Epoch 22/100\n",
            "211/211 [==============================] - 37s 174ms/step - loss: 0.1549 - acc: 0.9367 - val_loss: 0.1384 - val_acc: 0.9433\n",
            "Epoch 23/100\n",
            "211/211 [==============================] - 37s 174ms/step - loss: 0.1610 - acc: 0.9324 - val_loss: 0.1356 - val_acc: 0.9433\n",
            "Epoch 24/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.1449 - acc: 0.9416 - val_loss: 0.1258 - val_acc: 0.9493\n",
            "Epoch 25/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.1529 - acc: 0.9373 - val_loss: 0.1230 - val_acc: 0.9520\n",
            "Epoch 26/100\n",
            "211/211 [==============================] - 40s 192ms/step - loss: 0.1518 - acc: 0.9378 - val_loss: 0.1280 - val_acc: 0.9427\n",
            "Epoch 27/100\n",
            "211/211 [==============================] - 37s 177ms/step - loss: 0.1485 - acc: 0.9406 - val_loss: 0.1369 - val_acc: 0.9447\n",
            "Epoch 28/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.1458 - acc: 0.9389 - val_loss: 0.1283 - val_acc: 0.9400\n",
            "Epoch 29/100\n",
            "211/211 [==============================] - 37s 174ms/step - loss: 0.1472 - acc: 0.9376 - val_loss: 0.1312 - val_acc: 0.9460\n",
            "Epoch 30/100\n",
            "211/211 [==============================] - 37s 174ms/step - loss: 0.1397 - acc: 0.9447 - val_loss: 0.1248 - val_acc: 0.9520\n",
            "Epoch 31/100\n",
            "211/211 [==============================] - 37s 173ms/step - loss: 0.1415 - acc: 0.9382 - val_loss: 0.1172 - val_acc: 0.9453\n",
            "Epoch 32/100\n",
            "211/211 [==============================] - 41s 194ms/step - loss: 0.1427 - acc: 0.9404 - val_loss: 0.1228 - val_acc: 0.9500\n",
            "Epoch 33/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.1364 - acc: 0.9419 - val_loss: 0.1332 - val_acc: 0.9460\n",
            "Epoch 34/100\n",
            "211/211 [==============================] - 37s 174ms/step - loss: 0.1409 - acc: 0.9402 - val_loss: 0.1219 - val_acc: 0.9467\n",
            "Epoch 35/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.1332 - acc: 0.9449 - val_loss: 0.1221 - val_acc: 0.9480\n",
            "Epoch 36/100\n",
            "211/211 [==============================] - 36s 173ms/step - loss: 0.1329 - acc: 0.9447 - val_loss: 0.1181 - val_acc: 0.9487\n",
            "Epoch 37/100\n",
            "211/211 [==============================] - 39s 185ms/step - loss: 0.1362 - acc: 0.9437 - val_loss: 0.1241 - val_acc: 0.9440\n",
            "Epoch 38/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.1327 - acc: 0.9438 - val_loss: 0.1174 - val_acc: 0.9527\n",
            "Epoch 39/100\n",
            "211/211 [==============================] - 36s 169ms/step - loss: 0.1353 - acc: 0.9431 - val_loss: 0.1202 - val_acc: 0.9467\n",
            "Epoch 40/100\n",
            "211/211 [==============================] - 38s 180ms/step - loss: 0.1307 - acc: 0.9475 - val_loss: 0.1155 - val_acc: 0.9527\n",
            "Epoch 41/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.1329 - acc: 0.9431 - val_loss: 0.1278 - val_acc: 0.9447\n",
            "Epoch 42/100\n",
            "211/211 [==============================] - 38s 179ms/step - loss: 0.1361 - acc: 0.9457 - val_loss: 0.1284 - val_acc: 0.9487\n",
            "Epoch 43/100\n",
            "211/211 [==============================] - 43s 205ms/step - loss: 0.1319 - acc: 0.9453 - val_loss: 0.1170 - val_acc: 0.9500\n",
            "Epoch 44/100\n",
            "211/211 [==============================] - 37s 178ms/step - loss: 0.1318 - acc: 0.9439 - val_loss: 0.1258 - val_acc: 0.9493\n",
            "Epoch 45/100\n",
            "211/211 [==============================] - 38s 179ms/step - loss: 0.1271 - acc: 0.9461 - val_loss: 0.1143 - val_acc: 0.9520\n",
            "Epoch 46/100\n",
            "211/211 [==============================] - 38s 179ms/step - loss: 0.1284 - acc: 0.9453 - val_loss: 0.1153 - val_acc: 0.9560\n",
            "Epoch 47/100\n",
            "211/211 [==============================] - 38s 180ms/step - loss: 0.1309 - acc: 0.9460 - val_loss: 0.1099 - val_acc: 0.9573\n",
            "Epoch 48/100\n",
            "211/211 [==============================] - 42s 199ms/step - loss: 0.1281 - acc: 0.9482 - val_loss: 0.1131 - val_acc: 0.9533\n",
            "Epoch 49/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.1273 - acc: 0.9465 - val_loss: 0.1186 - val_acc: 0.9540\n",
            "Epoch 50/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.1250 - acc: 0.9490 - val_loss: 0.1075 - val_acc: 0.9580\n",
            "Epoch 51/100\n",
            "211/211 [==============================] - 37s 177ms/step - loss: 0.1260 - acc: 0.9483 - val_loss: 0.1187 - val_acc: 0.9580\n",
            "Epoch 52/100\n",
            "211/211 [==============================] - 37s 177ms/step - loss: 0.1183 - acc: 0.9514 - val_loss: 0.1139 - val_acc: 0.9567\n",
            "Epoch 53/100\n",
            "211/211 [==============================] - 42s 200ms/step - loss: 0.1255 - acc: 0.9474 - val_loss: 0.1110 - val_acc: 0.9553\n",
            "Epoch 54/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.1206 - acc: 0.9508 - val_loss: 0.1101 - val_acc: 0.9533\n",
            "Epoch 55/100\n",
            "211/211 [==============================] - 38s 180ms/step - loss: 0.1238 - acc: 0.9487 - val_loss: 0.1127 - val_acc: 0.9527\n",
            "Epoch 56/100\n",
            "211/211 [==============================] - 38s 178ms/step - loss: 0.1249 - acc: 0.9493 - val_loss: 0.1201 - val_acc: 0.9533\n",
            "Epoch 57/100\n",
            "211/211 [==============================] - 38s 180ms/step - loss: 0.1247 - acc: 0.9497 - val_loss: 0.1302 - val_acc: 0.9533\n",
            "Epoch 58/100\n",
            "211/211 [==============================] - 38s 181ms/step - loss: 0.1217 - acc: 0.9469 - val_loss: 0.1090 - val_acc: 0.9573\n",
            "Epoch 59/100\n",
            "211/211 [==============================] - 43s 203ms/step - loss: 0.1194 - acc: 0.9507 - val_loss: 0.1115 - val_acc: 0.9560\n",
            "Epoch 60/100\n",
            "211/211 [==============================] - 38s 179ms/step - loss: 0.1205 - acc: 0.9515 - val_loss: 0.1060 - val_acc: 0.9540\n",
            "Epoch 61/100\n",
            "211/211 [==============================] - 38s 178ms/step - loss: 0.1174 - acc: 0.9527 - val_loss: 0.1148 - val_acc: 0.9487\n",
            "Epoch 62/100\n",
            "211/211 [==============================] - 38s 179ms/step - loss: 0.1233 - acc: 0.9477 - val_loss: 0.1128 - val_acc: 0.9527\n",
            "Epoch 63/100\n",
            "211/211 [==============================] - 38s 179ms/step - loss: 0.1196 - acc: 0.9490 - val_loss: 0.1028 - val_acc: 0.9547\n",
            "Epoch 64/100\n",
            "211/211 [==============================] - 42s 200ms/step - loss: 0.1146 - acc: 0.9533 - val_loss: 0.1014 - val_acc: 0.9573\n",
            "Epoch 65/100\n",
            "211/211 [==============================] - 38s 179ms/step - loss: 0.1133 - acc: 0.9530 - val_loss: 0.1006 - val_acc: 0.9547\n",
            "Epoch 66/100\n",
            "211/211 [==============================] - 38s 178ms/step - loss: 0.1166 - acc: 0.9507 - val_loss: 0.1014 - val_acc: 0.9533\n",
            "Epoch 67/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.1163 - acc: 0.9519 - val_loss: 0.1007 - val_acc: 0.9560\n",
            "Epoch 68/100\n",
            "211/211 [==============================] - 38s 179ms/step - loss: 0.1118 - acc: 0.9533 - val_loss: 0.0985 - val_acc: 0.9540\n",
            "Epoch 69/100\n",
            "211/211 [==============================] - 39s 186ms/step - loss: 0.1154 - acc: 0.9516 - val_loss: 0.1012 - val_acc: 0.9627\n",
            "Epoch 70/100\n",
            "211/211 [==============================] - 39s 183ms/step - loss: 0.1121 - acc: 0.9539 - val_loss: 0.1018 - val_acc: 0.9547\n",
            "Epoch 71/100\n",
            "211/211 [==============================] - 37s 178ms/step - loss: 0.1141 - acc: 0.9529 - val_loss: 0.1064 - val_acc: 0.9547\n",
            "Epoch 72/100\n",
            "211/211 [==============================] - 38s 180ms/step - loss: 0.1129 - acc: 0.9513 - val_loss: 0.1011 - val_acc: 0.9567\n",
            "Epoch 73/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.1153 - acc: 0.9527 - val_loss: 0.1155 - val_acc: 0.9580\n",
            "Epoch 74/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.1152 - acc: 0.9538 - val_loss: 0.1072 - val_acc: 0.9573\n",
            "Epoch 75/100\n",
            "211/211 [==============================] - 42s 198ms/step - loss: 0.1139 - acc: 0.9536 - val_loss: 0.1075 - val_acc: 0.9533\n",
            "Epoch 76/100\n",
            "211/211 [==============================] - 38s 180ms/step - loss: 0.1117 - acc: 0.9542 - val_loss: 0.1072 - val_acc: 0.9560\n",
            "Epoch 77/100\n",
            "211/211 [==============================] - 38s 178ms/step - loss: 0.1115 - acc: 0.9529 - val_loss: 0.0981 - val_acc: 0.9607\n",
            "Epoch 78/100\n",
            "211/211 [==============================] - 38s 179ms/step - loss: 0.1071 - acc: 0.9556 - val_loss: 0.1036 - val_acc: 0.9580\n",
            "Epoch 79/100\n",
            "211/211 [==============================] - 38s 180ms/step - loss: 0.1093 - acc: 0.9553 - val_loss: 0.0964 - val_acc: 0.9613\n",
            "Epoch 80/100\n",
            "211/211 [==============================] - 41s 195ms/step - loss: 0.1076 - acc: 0.9567 - val_loss: 0.1122 - val_acc: 0.9553\n",
            "Epoch 81/100\n",
            "211/211 [==============================] - 37s 177ms/step - loss: 0.1105 - acc: 0.9559 - val_loss: 0.1022 - val_acc: 0.9593\n",
            "Epoch 82/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.1100 - acc: 0.9556 - val_loss: 0.0974 - val_acc: 0.9560\n",
            "Epoch 83/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.1067 - acc: 0.9564 - val_loss: 0.1071 - val_acc: 0.9560\n",
            "Epoch 84/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.1040 - acc: 0.9570 - val_loss: 0.1021 - val_acc: 0.9567\n",
            "Epoch 85/100\n",
            "211/211 [==============================] - 37s 174ms/step - loss: 0.1028 - acc: 0.9585 - val_loss: 0.1008 - val_acc: 0.9553\n",
            "Epoch 86/100\n",
            "211/211 [==============================] - 41s 196ms/step - loss: 0.1112 - acc: 0.9533 - val_loss: 0.1134 - val_acc: 0.9560\n",
            "Epoch 87/100\n",
            "211/211 [==============================] - 38s 178ms/step - loss: 0.1083 - acc: 0.9576 - val_loss: 0.1086 - val_acc: 0.9507\n",
            "Epoch 88/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.1049 - acc: 0.9587 - val_loss: 0.1017 - val_acc: 0.9593\n",
            "Epoch 89/100\n",
            "211/211 [==============================] - 38s 182ms/step - loss: 0.1010 - acc: 0.9584 - val_loss: 0.0945 - val_acc: 0.9627\n",
            "Epoch 90/100\n",
            "211/211 [==============================] - 38s 179ms/step - loss: 0.1087 - acc: 0.9551 - val_loss: 0.1058 - val_acc: 0.9587\n",
            "Epoch 91/100\n",
            "211/211 [==============================] - 37s 177ms/step - loss: 0.1045 - acc: 0.9570 - val_loss: 0.0968 - val_acc: 0.9580\n",
            "Epoch 92/100\n",
            "211/211 [==============================] - 41s 195ms/step - loss: 0.1025 - acc: 0.9582 - val_loss: 0.1060 - val_acc: 0.9567\n",
            "Epoch 93/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.1033 - acc: 0.9569 - val_loss: 0.1061 - val_acc: 0.9600\n",
            "Epoch 94/100\n",
            "211/211 [==============================] - 37s 177ms/step - loss: 0.1036 - acc: 0.9570 - val_loss: 0.1077 - val_acc: 0.9533\n",
            "Epoch 95/100\n",
            "211/211 [==============================] - 38s 180ms/step - loss: 0.0935 - acc: 0.9621 - val_loss: 0.0936 - val_acc: 0.9600\n",
            "Epoch 96/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.1036 - acc: 0.9588 - val_loss: 0.0956 - val_acc: 0.9627\n",
            "Epoch 97/100\n",
            "211/211 [==============================] - 42s 200ms/step - loss: 0.0969 - acc: 0.9570 - val_loss: 0.0951 - val_acc: 0.9647\n",
            "Epoch 98/100\n",
            "211/211 [==============================] - 38s 179ms/step - loss: 0.1014 - acc: 0.9592 - val_loss: 0.0956 - val_acc: 0.9593\n",
            "Epoch 99/100\n",
            "211/211 [==============================] - 37s 177ms/step - loss: 0.0985 - acc: 0.9592 - val_loss: 0.0931 - val_acc: 0.9627\n",
            "Epoch 100/100\n",
            "211/211 [==============================] - 38s 179ms/step - loss: 0.1059 - acc: 0.9562 - val_loss: 0.0952 - val_acc: 0.9653\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "\n",
        "\n",
        "######## Word Embedding ############\n",
        "\n",
        "tokenizer, embedding_matrix = word_embed_meta_data(sentences1 + sentences2,  siamese_config['EMBEDDING_DIM'])\n",
        "\n",
        "embedding_meta_data = {\n",
        "\t'tokenizer': tokenizer,\n",
        "\t'embedding_matrix': embedding_matrix\n",
        "}\n",
        "\n",
        "## creating sentence pairs\n",
        "sentences_pair = [(x1, x2) for x1, x2 in zip(sentences1, sentences2)]\n",
        "\n",
        "\n",
        "######## Training ########\n",
        "\n",
        "class Configuration(object):\n",
        "    \"\"\"Dump stuff here\"\"\"\n",
        "\n",
        "CONFIG = Configuration()\n",
        "\n",
        "CONFIG.embedding_dim = siamese_config['EMBEDDING_DIM']\n",
        "CONFIG.max_sequence_length = siamese_config['MAX_SEQUENCE_LENGTH']\n",
        "CONFIG.number_lstm_units = siamese_config['NUMBER_LSTM']\n",
        "CONFIG.rate_drop_lstm = siamese_config['RATE_DROP_LSTM']\n",
        "CONFIG.number_dense_units = siamese_config['NUMBER_DENSE_UNITS']\n",
        "CONFIG.activation_function = siamese_config['ACTIVATION_FUNCTION']\n",
        "CONFIG.rate_drop_dense = siamese_config['RATE_DROP_DENSE']\n",
        "CONFIG.validation_split_ratio = siamese_config['VALIDATION_SPLIT']\n",
        "\n",
        "siamese = SiameseBiLSTM(CONFIG.embedding_dim , CONFIG.max_sequence_length, CONFIG.number_lstm_units , CONFIG.number_dense_units, CONFIG.rate_drop_lstm, CONFIG.rate_drop_dense, CONFIG.activation_function, CONFIG.validation_split_ratio)\n",
        "\n",
        "best_model_path = siamese.train_model_word(sentences_pair, is_similar, embedding_meta_data, model_save_directory='./', fold = 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgvIo0FBxseB"
      },
      "source": [
        "# Training Siamese LSTM (char embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nlo8Q4tUxyAj",
        "outputId": "53bf389e-a815-4bde-815b-e971a7261722"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentences1 and sentences2 are not empty\n",
            "Epoch 1/100\n",
            "211/211 [==============================] - 57s 186ms/step - loss: 0.6449 - acc: 0.6073 - val_loss: 0.7115 - val_acc: 0.6040\n",
            "Epoch 2/100\n",
            "211/211 [==============================] - 37s 174ms/step - loss: 0.5876 - acc: 0.6330 - val_loss: 0.5851 - val_acc: 0.6393\n",
            "Epoch 3/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.5753 - acc: 0.6387 - val_loss: 0.5364 - val_acc: 0.6793\n",
            "Epoch 4/100\n",
            "211/211 [==============================] - 41s 194ms/step - loss: 0.5702 - acc: 0.6421 - val_loss: 0.5416 - val_acc: 0.6107\n",
            "Epoch 5/100\n",
            "211/211 [==============================] - 36s 172ms/step - loss: 0.5668 - acc: 0.6404 - val_loss: 0.5458 - val_acc: 0.6753\n",
            "Epoch 6/100\n",
            "211/211 [==============================] - 37s 174ms/step - loss: 0.5599 - acc: 0.6464 - val_loss: 0.5384 - val_acc: 0.6120\n",
            "Epoch 7/100\n",
            "211/211 [==============================] - 37s 178ms/step - loss: 0.5565 - acc: 0.6523 - val_loss: 0.5406 - val_acc: 0.6767\n",
            "Epoch 8/100\n",
            "211/211 [==============================] - 36s 172ms/step - loss: 0.5534 - acc: 0.6501 - val_loss: 0.5428 - val_acc: 0.6767\n",
            "Epoch 9/100\n",
            "211/211 [==============================] - 37s 174ms/step - loss: 0.5554 - acc: 0.6530 - val_loss: 0.5374 - val_acc: 0.6767\n",
            "Epoch 10/100\n",
            "211/211 [==============================] - 40s 192ms/step - loss: 0.5561 - acc: 0.6541 - val_loss: 0.5325 - val_acc: 0.6793\n",
            "Epoch 11/100\n",
            "211/211 [==============================] - 37s 174ms/step - loss: 0.5561 - acc: 0.6513 - val_loss: 0.5374 - val_acc: 0.6773\n",
            "Epoch 12/100\n",
            "211/211 [==============================] - 38s 177ms/step - loss: 0.5523 - acc: 0.6583 - val_loss: 0.5383 - val_acc: 0.6807\n",
            "Epoch 13/100\n",
            "211/211 [==============================] - 37s 177ms/step - loss: 0.5514 - acc: 0.6590 - val_loss: 0.5342 - val_acc: 0.6800\n",
            "Epoch 14/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.5498 - acc: 0.6595 - val_loss: 0.5299 - val_acc: 0.6827\n",
            "Epoch 15/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.5490 - acc: 0.6590 - val_loss: 0.5323 - val_acc: 0.6813\n",
            "Epoch 16/100\n",
            "211/211 [==============================] - 40s 190ms/step - loss: 0.5482 - acc: 0.6606 - val_loss: 0.5394 - val_acc: 0.6167\n",
            "Epoch 17/100\n",
            "211/211 [==============================] - 40s 190ms/step - loss: 0.5503 - acc: 0.6564 - val_loss: 0.5348 - val_acc: 0.6180\n",
            "Epoch 18/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.5495 - acc: 0.6590 - val_loss: 0.5376 - val_acc: 0.6800\n",
            "Epoch 19/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.5497 - acc: 0.6568 - val_loss: 0.5342 - val_acc: 0.6833\n",
            "Epoch 20/100\n",
            "211/211 [==============================] - 38s 179ms/step - loss: 0.5479 - acc: 0.6604 - val_loss: 0.5350 - val_acc: 0.6827\n",
            "Epoch 21/100\n",
            "211/211 [==============================] - 37s 174ms/step - loss: 0.5492 - acc: 0.6599 - val_loss: 0.5332 - val_acc: 0.6827\n",
            "Epoch 22/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.5482 - acc: 0.6585 - val_loss: 0.5357 - val_acc: 0.6847\n",
            "Epoch 23/100\n",
            "211/211 [==============================] - 41s 195ms/step - loss: 0.5470 - acc: 0.6561 - val_loss: 0.5363 - val_acc: 0.6827\n",
            "Epoch 24/100\n",
            "211/211 [==============================] - 38s 179ms/step - loss: 0.5473 - acc: 0.6626 - val_loss: 0.5351 - val_acc: 0.6840\n",
            "Epoch 25/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.5476 - acc: 0.6607 - val_loss: 0.5381 - val_acc: 0.6820\n",
            "Epoch 26/100\n",
            "211/211 [==============================] - 37s 177ms/step - loss: 0.5470 - acc: 0.6628 - val_loss: 0.5408 - val_acc: 0.6167\n",
            "Epoch 27/100\n",
            "211/211 [==============================] - 37s 173ms/step - loss: 0.5480 - acc: 0.6592 - val_loss: 0.5350 - val_acc: 0.6820\n",
            "Epoch 28/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.5471 - acc: 0.6598 - val_loss: 0.5342 - val_acc: 0.6827\n",
            "Epoch 29/100\n",
            "211/211 [==============================] - 41s 195ms/step - loss: 0.5462 - acc: 0.6635 - val_loss: 0.5370 - val_acc: 0.6820\n",
            "Epoch 30/100\n",
            "211/211 [==============================] - 38s 178ms/step - loss: 0.5478 - acc: 0.6599 - val_loss: 0.5331 - val_acc: 0.6827\n",
            "Epoch 31/100\n",
            "211/211 [==============================] - 37s 177ms/step - loss: 0.5444 - acc: 0.6624 - val_loss: 0.5332 - val_acc: 0.6820\n",
            "Epoch 32/100\n",
            "211/211 [==============================] - 38s 180ms/step - loss: 0.5464 - acc: 0.6584 - val_loss: 0.5334 - val_acc: 0.6847\n",
            "Epoch 33/100\n",
            "211/211 [==============================] - 38s 179ms/step - loss: 0.5464 - acc: 0.6620 - val_loss: 0.5341 - val_acc: 0.6827\n",
            "Epoch 34/100\n",
            "211/211 [==============================] - 38s 179ms/step - loss: 0.5437 - acc: 0.6579 - val_loss: 0.5362 - val_acc: 0.6833\n",
            "Epoch 35/100\n",
            "211/211 [==============================] - 38s 178ms/step - loss: 0.5448 - acc: 0.6604 - val_loss: 0.5351 - val_acc: 0.6820\n",
            "Epoch 36/100\n",
            "211/211 [==============================] - 42s 201ms/step - loss: 0.5462 - acc: 0.6633 - val_loss: 0.5387 - val_acc: 0.6813\n",
            "Epoch 37/100\n",
            "211/211 [==============================] - 38s 180ms/step - loss: 0.5428 - acc: 0.6626 - val_loss: 0.5348 - val_acc: 0.6820\n",
            "Epoch 38/100\n",
            "211/211 [==============================] - 37s 174ms/step - loss: 0.5443 - acc: 0.6608 - val_loss: 0.5335 - val_acc: 0.6827\n",
            "Epoch 39/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.5446 - acc: 0.6635 - val_loss: 0.5335 - val_acc: 0.6820\n",
            "Epoch 40/100\n",
            "211/211 [==============================] - 38s 178ms/step - loss: 0.5439 - acc: 0.6647 - val_loss: 0.5358 - val_acc: 0.6813\n",
            "Epoch 41/100\n",
            "211/211 [==============================] - 37s 174ms/step - loss: 0.5445 - acc: 0.6630 - val_loss: 0.5378 - val_acc: 0.6813\n",
            "Epoch 42/100\n",
            "211/211 [==============================] - 41s 193ms/step - loss: 0.5449 - acc: 0.6581 - val_loss: 0.5341 - val_acc: 0.6813\n",
            "Epoch 43/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.5429 - acc: 0.6611 - val_loss: 0.5392 - val_acc: 0.6820\n",
            "Epoch 44/100\n",
            "211/211 [==============================] - 37s 173ms/step - loss: 0.5437 - acc: 0.6607 - val_loss: 0.5341 - val_acc: 0.6807\n",
            "Epoch 45/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.5444 - acc: 0.6603 - val_loss: 0.5349 - val_acc: 0.6807\n",
            "Epoch 46/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.5429 - acc: 0.6649 - val_loss: 0.5351 - val_acc: 0.6820\n",
            "Epoch 47/100\n",
            "211/211 [==============================] - 38s 179ms/step - loss: 0.5442 - acc: 0.6594 - val_loss: 0.5361 - val_acc: 0.6813\n",
            "Epoch 48/100\n",
            "211/211 [==============================] - 37s 177ms/step - loss: 0.5431 - acc: 0.6621 - val_loss: 0.5366 - val_acc: 0.6147\n",
            "Epoch 49/100\n",
            "211/211 [==============================] - 42s 201ms/step - loss: 0.5430 - acc: 0.6672 - val_loss: 0.5358 - val_acc: 0.6800\n",
            "Epoch 50/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.5445 - acc: 0.6650 - val_loss: 0.5328 - val_acc: 0.6813\n",
            "Epoch 51/100\n",
            "211/211 [==============================] - 36s 172ms/step - loss: 0.5421 - acc: 0.6632 - val_loss: 0.5331 - val_acc: 0.6820\n",
            "Epoch 52/100\n",
            "211/211 [==============================] - 36s 172ms/step - loss: 0.5408 - acc: 0.6642 - val_loss: 0.5332 - val_acc: 0.6827\n",
            "Epoch 53/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.5419 - acc: 0.6647 - val_loss: 0.5347 - val_acc: 0.6833\n",
            "Epoch 54/100\n",
            "211/211 [==============================] - 37s 174ms/step - loss: 0.5421 - acc: 0.6628 - val_loss: 0.5343 - val_acc: 0.6813\n",
            "Epoch 55/100\n",
            "211/211 [==============================] - 37s 177ms/step - loss: 0.5431 - acc: 0.6596 - val_loss: 0.5346 - val_acc: 0.6820\n",
            "Epoch 56/100\n",
            "211/211 [==============================] - 42s 197ms/step - loss: 0.5417 - acc: 0.6640 - val_loss: 0.5375 - val_acc: 0.6813\n",
            "Epoch 57/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.5434 - acc: 0.6599 - val_loss: 0.5384 - val_acc: 0.6807\n",
            "Epoch 58/100\n",
            "211/211 [==============================] - 37s 177ms/step - loss: 0.5415 - acc: 0.6625 - val_loss: 0.5393 - val_acc: 0.6807\n",
            "Epoch 59/100\n",
            "211/211 [==============================] - 37s 174ms/step - loss: 0.5427 - acc: 0.6676 - val_loss: 0.5369 - val_acc: 0.6820\n",
            "Epoch 60/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.5421 - acc: 0.6647 - val_loss: 0.5350 - val_acc: 0.6820\n",
            "Epoch 61/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.5429 - acc: 0.6656 - val_loss: 0.5359 - val_acc: 0.6813\n",
            "Epoch 62/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.5429 - acc: 0.6624 - val_loss: 0.5357 - val_acc: 0.6813\n",
            "Epoch 63/100\n",
            "211/211 [==============================] - 41s 197ms/step - loss: 0.5429 - acc: 0.6656 - val_loss: 0.5373 - val_acc: 0.6813\n",
            "Epoch 64/100\n",
            "211/211 [==============================] - 37s 177ms/step - loss: 0.5410 - acc: 0.6612 - val_loss: 0.5352 - val_acc: 0.6827\n",
            "Epoch 65/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.5402 - acc: 0.6645 - val_loss: 0.5366 - val_acc: 0.6840\n",
            "Epoch 66/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.5434 - acc: 0.6615 - val_loss: 0.5337 - val_acc: 0.6820\n",
            "Epoch 67/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.5420 - acc: 0.6630 - val_loss: 0.5329 - val_acc: 0.6833\n",
            "Epoch 68/100\n",
            "211/211 [==============================] - 37s 174ms/step - loss: 0.5438 - acc: 0.6636 - val_loss: 0.5379 - val_acc: 0.6820\n",
            "Epoch 69/100\n",
            "211/211 [==============================] - 39s 184ms/step - loss: 0.5408 - acc: 0.6639 - val_loss: 0.5351 - val_acc: 0.6827\n",
            "Epoch 70/100\n",
            "211/211 [==============================] - 39s 183ms/step - loss: 0.5426 - acc: 0.6630 - val_loss: 0.5341 - val_acc: 0.6833\n",
            "Epoch 71/100\n",
            "211/211 [==============================] - 36s 173ms/step - loss: 0.5403 - acc: 0.6673 - val_loss: 0.5356 - val_acc: 0.6833\n",
            "Epoch 72/100\n",
            "211/211 [==============================] - 37s 174ms/step - loss: 0.5439 - acc: 0.6616 - val_loss: 0.5349 - val_acc: 0.6820\n",
            "Epoch 73/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.5409 - acc: 0.6652 - val_loss: 0.5365 - val_acc: 0.6820\n",
            "Epoch 74/100\n",
            "211/211 [==============================] - 36s 170ms/step - loss: 0.5408 - acc: 0.6671 - val_loss: 0.5355 - val_acc: 0.6840\n",
            "Epoch 75/100\n",
            "211/211 [==============================] - 38s 180ms/step - loss: 0.5400 - acc: 0.6656 - val_loss: 0.5324 - val_acc: 0.6840\n",
            "Epoch 76/100\n",
            "211/211 [==============================] - 36s 171ms/step - loss: 0.5411 - acc: 0.6635 - val_loss: 0.5337 - val_acc: 0.6847\n",
            "Epoch 77/100\n",
            "211/211 [==============================] - 39s 184ms/step - loss: 0.5404 - acc: 0.6667 - val_loss: 0.5329 - val_acc: 0.6847\n",
            "Epoch 78/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.5403 - acc: 0.6690 - val_loss: 0.5365 - val_acc: 0.6833\n",
            "Epoch 79/100\n",
            "211/211 [==============================] - 38s 178ms/step - loss: 0.5391 - acc: 0.6672 - val_loss: 0.5333 - val_acc: 0.6847\n",
            "Epoch 80/100\n",
            "211/211 [==============================] - 36s 172ms/step - loss: 0.5400 - acc: 0.6631 - val_loss: 0.5333 - val_acc: 0.6847\n",
            "Epoch 81/100\n",
            "211/211 [==============================] - 37s 174ms/step - loss: 0.5391 - acc: 0.6660 - val_loss: 0.5340 - val_acc: 0.6827\n",
            "Epoch 82/100\n",
            "211/211 [==============================] - 37s 178ms/step - loss: 0.5419 - acc: 0.6699 - val_loss: 0.5367 - val_acc: 0.6847\n",
            "Epoch 83/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.5411 - acc: 0.6625 - val_loss: 0.5366 - val_acc: 0.6833\n",
            "Epoch 84/100\n",
            "211/211 [==============================] - 41s 197ms/step - loss: 0.5400 - acc: 0.6653 - val_loss: 0.5323 - val_acc: 0.6840\n",
            "Epoch 85/100\n",
            "211/211 [==============================] - 37s 173ms/step - loss: 0.5418 - acc: 0.6669 - val_loss: 0.5328 - val_acc: 0.6853\n",
            "Epoch 86/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.5427 - acc: 0.6652 - val_loss: 0.5357 - val_acc: 0.6820\n",
            "Epoch 87/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.5433 - acc: 0.6636 - val_loss: 0.5353 - val_acc: 0.6833\n",
            "Epoch 88/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.5413 - acc: 0.6649 - val_loss: 0.5340 - val_acc: 0.6840\n",
            "Epoch 89/100\n",
            "211/211 [==============================] - 37s 177ms/step - loss: 0.5398 - acc: 0.6616 - val_loss: 0.5342 - val_acc: 0.6847\n",
            "Epoch 90/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.5409 - acc: 0.6664 - val_loss: 0.5347 - val_acc: 0.6840\n",
            "Epoch 91/100\n",
            "211/211 [==============================] - 39s 184ms/step - loss: 0.5418 - acc: 0.6676 - val_loss: 0.5343 - val_acc: 0.6833\n",
            "Epoch 92/100\n",
            "211/211 [==============================] - 39s 187ms/step - loss: 0.5412 - acc: 0.6633 - val_loss: 0.5357 - val_acc: 0.6840\n",
            "Epoch 93/100\n",
            "211/211 [==============================] - 37s 173ms/step - loss: 0.5401 - acc: 0.6681 - val_loss: 0.5336 - val_acc: 0.6840\n",
            "Epoch 94/100\n",
            "211/211 [==============================] - 37s 175ms/step - loss: 0.5391 - acc: 0.6667 - val_loss: 0.5348 - val_acc: 0.6840\n",
            "Epoch 95/100\n",
            "211/211 [==============================] - 36s 171ms/step - loss: 0.5397 - acc: 0.6664 - val_loss: 0.5367 - val_acc: 0.6840\n",
            "Epoch 96/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.5419 - acc: 0.6665 - val_loss: 0.5364 - val_acc: 0.6840\n",
            "Epoch 97/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.5410 - acc: 0.6648 - val_loss: 0.5352 - val_acc: 0.6840\n",
            "Epoch 98/100\n",
            "211/211 [==============================] - 37s 176ms/step - loss: 0.5409 - acc: 0.6663 - val_loss: 0.5336 - val_acc: 0.6833\n",
            "Epoch 99/100\n",
            "211/211 [==============================] - 36s 170ms/step - loss: 0.5398 - acc: 0.6624 - val_loss: 0.5351 - val_acc: 0.6827\n",
            "Epoch 100/100\n",
            "211/211 [==============================] - 41s 196ms/step - loss: 0.5393 - acc: 0.6671 - val_loss: 0.5354 - val_acc: 0.6820\n"
          ]
        }
      ],
      "source": [
        "######## Character Embedding ############\n",
        "if sentences1 and sentences2:\n",
        "    print(\"sentences1 and sentences2 are not empty\")\n",
        "else:\n",
        "    print(\"sentences1 and/or sentences2 are empty\")\n",
        "\n",
        "all_sentences = sentences1 + sentences2\n",
        "\n",
        "tokenizer, embedding_matrix = char_embed_meta_data(all_sentences, siamese_config['EMBEDDING_DIM'])\n",
        "\n",
        "embedding_meta_data = {\n",
        "\t'tokenizer': tokenizer,\n",
        "\t'embedding_matrix': embedding_matrix\n",
        "}\n",
        "\n",
        "## creating sentence pairs\n",
        "sentences_pair = [(x1, x2) for x1, x2 in zip(sentences1, sentences2)]\n",
        "\n",
        "\n",
        "######## Training ########\n",
        "\n",
        "class Configuration(object):\n",
        "    \"\"\"Dump stuff here\"\"\"\n",
        "\n",
        "CONFIG = Configuration()\n",
        "\n",
        "CONFIG.embedding_dim = siamese_config['EMBEDDING_DIM']\n",
        "CONFIG.max_sequence_length = siamese_config['MAX_SEQUENCE_LENGTH']\n",
        "CONFIG.number_lstm_units = siamese_config['NUMBER_LSTM']\n",
        "CONFIG.rate_drop_lstm = siamese_config['RATE_DROP_LSTM']\n",
        "CONFIG.number_dense_units = siamese_config['NUMBER_DENSE_UNITS']\n",
        "CONFIG.activation_function = siamese_config['ACTIVATION_FUNCTION']\n",
        "CONFIG.rate_drop_dense = siamese_config['RATE_DROP_DENSE']\n",
        "CONFIG.validation_split_ratio = siamese_config['VALIDATION_SPLIT']\n",
        "\n",
        "siamese = SiameseBiLSTM(CONFIG.embedding_dim , CONFIG.max_sequence_length, CONFIG.number_lstm_units , CONFIG.number_dense_units, CONFIG.rate_drop_lstm, CONFIG.rate_drop_dense, CONFIG.activation_function, CONFIG.validation_split_ratio)\n",
        "\n",
        "best_model_path = siamese.train_model_word(sentences_pair, is_similar, embedding_meta_data, model_save_directory='./', fold = 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6-SKnJLyD_P"
      },
      "source": [
        "# Training LSTM without embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xczm5FhyyJ4K",
        "outputId": "de74e129-b226-4219-abf0-43ee4d283e8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "211/211 [==============================] - 41s 99ms/step - loss: 0.6891 - acc: 0.6016 - val_loss: 0.5781 - val_acc: 0.7531\n",
            "Epoch 2/100\n",
            "211/211 [==============================] - 19s 89ms/step - loss: 0.5617 - acc: 0.7046 - val_loss: 0.4880 - val_acc: 0.7787\n",
            "Epoch 3/100\n",
            "211/211 [==============================] - 20s 94ms/step - loss: 0.5029 - acc: 0.7634 - val_loss: 0.4345 - val_acc: 0.8093\n",
            "Epoch 4/100\n",
            "211/211 [==============================] - 19s 92ms/step - loss: 0.4750 - acc: 0.7857 - val_loss: 0.4274 - val_acc: 0.8157\n",
            "Epoch 5/100\n",
            "211/211 [==============================] - 19s 90ms/step - loss: 0.4637 - acc: 0.7916 - val_loss: 0.3895 - val_acc: 0.8418\n",
            "Epoch 6/100\n",
            "211/211 [==============================] - 19s 92ms/step - loss: 0.4440 - acc: 0.8057 - val_loss: 0.3840 - val_acc: 0.8406\n",
            "Epoch 7/100\n",
            "211/211 [==============================] - 19s 90ms/step - loss: 0.4330 - acc: 0.8128 - val_loss: 0.3803 - val_acc: 0.8357\n",
            "Epoch 8/100\n",
            "211/211 [==============================] - 20s 96ms/step - loss: 0.4192 - acc: 0.8214 - val_loss: 0.3596 - val_acc: 0.8541\n",
            "Epoch 9/100\n",
            "211/211 [==============================] - 19s 90ms/step - loss: 0.4113 - acc: 0.8261 - val_loss: 0.3514 - val_acc: 0.8564\n",
            "Epoch 10/100\n",
            "211/211 [==============================] - 19s 92ms/step - loss: 0.4066 - acc: 0.8286 - val_loss: 0.3781 - val_acc: 0.8362\n",
            "Epoch 11/100\n",
            "211/211 [==============================] - 19s 88ms/step - loss: 0.4020 - acc: 0.8303 - val_loss: 0.3455 - val_acc: 0.8603\n",
            "Epoch 12/100\n",
            "211/211 [==============================] - 19s 91ms/step - loss: 0.4027 - acc: 0.8289 - val_loss: 0.3966 - val_acc: 0.8276\n",
            "Epoch 13/100\n",
            "211/211 [==============================] - 19s 89ms/step - loss: 0.3976 - acc: 0.8325 - val_loss: 0.3497 - val_acc: 0.8455\n",
            "Epoch 14/100\n",
            "211/211 [==============================] - 19s 90ms/step - loss: 0.3966 - acc: 0.8315 - val_loss: 0.4246 - val_acc: 0.8131\n",
            "Epoch 15/100\n",
            "211/211 [==============================] - 20s 92ms/step - loss: 0.3962 - acc: 0.8317 - val_loss: 0.3511 - val_acc: 0.8503\n",
            "Epoch 16/100\n",
            "211/211 [==============================] - 19s 90ms/step - loss: 0.3907 - acc: 0.8349 - val_loss: 0.3448 - val_acc: 0.8523\n",
            "Epoch 17/100\n",
            "211/211 [==============================] - 19s 89ms/step - loss: 0.3933 - acc: 0.8338 - val_loss: 0.3497 - val_acc: 0.8484\n",
            "Epoch 18/100\n",
            "211/211 [==============================] - 19s 91ms/step - loss: 0.3876 - acc: 0.8367 - val_loss: 0.3385 - val_acc: 0.8553\n",
            "Epoch 19/100\n",
            "211/211 [==============================] - 21s 101ms/step - loss: 0.3841 - acc: 0.8407 - val_loss: 0.3403 - val_acc: 0.8587\n",
            "Epoch 20/100\n",
            "211/211 [==============================] - 20s 93ms/step - loss: 0.3817 - acc: 0.8420 - val_loss: 0.3327 - val_acc: 0.8631\n",
            "Epoch 21/100\n",
            "211/211 [==============================] - 19s 92ms/step - loss: 0.3794 - acc: 0.8428 - val_loss: 0.3310 - val_acc: 0.8607\n",
            "Epoch 22/100\n",
            "211/211 [==============================] - 20s 93ms/step - loss: 0.3779 - acc: 0.8420 - val_loss: 0.3247 - val_acc: 0.8674\n",
            "Epoch 23/100\n",
            "211/211 [==============================] - 19s 92ms/step - loss: 0.3775 - acc: 0.8439 - val_loss: 0.3418 - val_acc: 0.8583\n",
            "Epoch 24/100\n",
            "211/211 [==============================] - 19s 89ms/step - loss: 0.3815 - acc: 0.8405 - val_loss: 0.3455 - val_acc: 0.8511\n",
            "Epoch 25/100\n",
            "211/211 [==============================] - 19s 91ms/step - loss: 0.3816 - acc: 0.8385 - val_loss: 0.3257 - val_acc: 0.8703\n",
            "Epoch 26/100\n",
            "211/211 [==============================] - 19s 89ms/step - loss: 0.3806 - acc: 0.8397 - val_loss: 0.3269 - val_acc: 0.8667\n",
            "Epoch 27/100\n",
            "211/211 [==============================] - 19s 90ms/step - loss: 0.3725 - acc: 0.8443 - val_loss: 0.3218 - val_acc: 0.8699\n",
            "Epoch 28/100\n",
            "211/211 [==============================] - 19s 90ms/step - loss: 0.3723 - acc: 0.8461 - val_loss: 0.3179 - val_acc: 0.8715\n",
            "Epoch 29/100\n",
            "211/211 [==============================] - 19s 89ms/step - loss: 0.3718 - acc: 0.8479 - val_loss: 0.3249 - val_acc: 0.8682\n",
            "Epoch 30/100\n",
            "211/211 [==============================] - 19s 90ms/step - loss: 0.3733 - acc: 0.8475 - val_loss: 0.3182 - val_acc: 0.8689\n",
            "Epoch 31/100\n",
            "211/211 [==============================] - 19s 90ms/step - loss: 0.3691 - acc: 0.8497 - val_loss: 0.3157 - val_acc: 0.8782\n",
            "Epoch 32/100\n",
            "211/211 [==============================] - 19s 89ms/step - loss: 0.3671 - acc: 0.8504 - val_loss: 0.3204 - val_acc: 0.8646\n",
            "Epoch 33/100\n",
            "211/211 [==============================] - 19s 89ms/step - loss: 0.3651 - acc: 0.8529 - val_loss: 0.3083 - val_acc: 0.8781\n",
            "Epoch 34/100\n",
            "211/211 [==============================] - 19s 92ms/step - loss: 0.3669 - acc: 0.8495 - val_loss: 0.3112 - val_acc: 0.8757\n",
            "Epoch 35/100\n",
            "211/211 [==============================] - 19s 89ms/step - loss: 0.3706 - acc: 0.8477 - val_loss: 0.3132 - val_acc: 0.8683\n",
            "Epoch 36/100\n",
            "211/211 [==============================] - 19s 91ms/step - loss: 0.3717 - acc: 0.8473 - val_loss: 0.3199 - val_acc: 0.8586\n",
            "Epoch 37/100\n",
            "211/211 [==============================] - 22s 102ms/step - loss: 0.3673 - acc: 0.8492 - val_loss: 0.3165 - val_acc: 0.8669\n",
            "Epoch 38/100\n",
            "211/211 [==============================] - 20s 97ms/step - loss: 0.3700 - acc: 0.8485 - val_loss: 0.3113 - val_acc: 0.8651\n",
            "Epoch 39/100\n",
            "211/211 [==============================] - 19s 89ms/step - loss: 0.3665 - acc: 0.8498 - val_loss: 0.2983 - val_acc: 0.8801\n",
            "Epoch 40/100\n",
            "211/211 [==============================] - 19s 91ms/step - loss: 0.3775 - acc: 0.8430 - val_loss: 0.3151 - val_acc: 0.8680\n",
            "Epoch 41/100\n",
            "211/211 [==============================] - 19s 90ms/step - loss: 0.3691 - acc: 0.8489 - val_loss: 0.3093 - val_acc: 0.8761\n",
            "Epoch 42/100\n",
            "211/211 [==============================] - 19s 90ms/step - loss: 0.3695 - acc: 0.8474 - val_loss: 0.2997 - val_acc: 0.8764\n",
            "Epoch 43/100\n",
            "211/211 [==============================] - 20s 95ms/step - loss: 0.3652 - acc: 0.8498 - val_loss: 0.3006 - val_acc: 0.8749\n",
            "Epoch 44/100\n",
            "211/211 [==============================] - 19s 88ms/step - loss: 0.3702 - acc: 0.8472 - val_loss: 0.3043 - val_acc: 0.8728\n",
            "Epoch 45/100\n",
            "211/211 [==============================] - 19s 92ms/step - loss: 0.3636 - acc: 0.8492 - val_loss: 0.3005 - val_acc: 0.8763\n",
            "Epoch 46/100\n",
            "211/211 [==============================] - 20s 92ms/step - loss: 0.3554 - acc: 0.8538 - val_loss: 0.2957 - val_acc: 0.8819\n",
            "Epoch 47/100\n",
            "211/211 [==============================] - 19s 89ms/step - loss: 0.3689 - acc: 0.8488 - val_loss: 0.3068 - val_acc: 0.8689\n",
            "Epoch 48/100\n",
            "211/211 [==============================] - 20s 93ms/step - loss: 0.3575 - acc: 0.8528 - val_loss: 0.2915 - val_acc: 0.8787\n",
            "Epoch 49/100\n",
            "211/211 [==============================] - 19s 92ms/step - loss: 0.3506 - acc: 0.8535 - val_loss: 0.2775 - val_acc: 0.8895\n",
            "Epoch 50/100\n",
            "211/211 [==============================] - 19s 92ms/step - loss: 0.3502 - acc: 0.8555 - val_loss: 0.2783 - val_acc: 0.8804\n",
            "Epoch 51/100\n",
            "211/211 [==============================] - 20s 96ms/step - loss: 0.3571 - acc: 0.8540 - val_loss: 0.2864 - val_acc: 0.8805\n",
            "Epoch 52/100\n",
            "211/211 [==============================] - 19s 90ms/step - loss: 0.3486 - acc: 0.8555 - val_loss: 0.2722 - val_acc: 0.8885\n",
            "Epoch 53/100\n",
            "211/211 [==============================] - 19s 90ms/step - loss: 0.3497 - acc: 0.8558 - val_loss: 0.2891 - val_acc: 0.8760\n",
            "Epoch 54/100\n",
            "211/211 [==============================] - 19s 91ms/step - loss: 0.3506 - acc: 0.8556 - val_loss: 0.2789 - val_acc: 0.8811\n",
            "Epoch 55/100\n",
            "211/211 [==============================] - 19s 90ms/step - loss: 0.3521 - acc: 0.8552 - val_loss: 0.2868 - val_acc: 0.8831\n",
            "Epoch 56/100\n",
            "211/211 [==============================] - 23s 109ms/step - loss: 0.3471 - acc: 0.8547 - val_loss: 0.2753 - val_acc: 0.8813\n",
            "Epoch 57/100\n",
            "211/211 [==============================] - 19s 89ms/step - loss: 0.3398 - acc: 0.8588 - val_loss: 0.2707 - val_acc: 0.8877\n",
            "Epoch 58/100\n",
            "211/211 [==============================] - 20s 93ms/step - loss: 0.3578 - acc: 0.8518 - val_loss: 0.3202 - val_acc: 0.8620\n",
            "Epoch 59/100\n",
            "211/211 [==============================] - 19s 90ms/step - loss: 0.3657 - acc: 0.8467 - val_loss: 0.2975 - val_acc: 0.8734\n",
            "Epoch 60/100\n",
            "211/211 [==============================] - 19s 92ms/step - loss: 0.3616 - acc: 0.8472 - val_loss: 0.2943 - val_acc: 0.8775\n",
            "Epoch 61/100\n",
            "211/211 [==============================] - 19s 90ms/step - loss: 0.3547 - acc: 0.8517 - val_loss: 0.3028 - val_acc: 0.8772\n",
            "Epoch 62/100\n",
            "211/211 [==============================] - 19s 92ms/step - loss: 0.3582 - acc: 0.8506 - val_loss: 0.2945 - val_acc: 0.8779\n",
            "Epoch 63/100\n",
            "211/211 [==============================] - 19s 91ms/step - loss: 0.3521 - acc: 0.8535 - val_loss: 0.2982 - val_acc: 0.8747\n",
            "Epoch 64/100\n",
            "211/211 [==============================] - 19s 91ms/step - loss: 0.3567 - acc: 0.8537 - val_loss: 0.2912 - val_acc: 0.8848\n",
            "Epoch 65/100\n",
            "211/211 [==============================] - 19s 91ms/step - loss: 0.3485 - acc: 0.8573 - val_loss: 0.2935 - val_acc: 0.8831\n",
            "Epoch 66/100\n",
            "211/211 [==============================] - 19s 91ms/step - loss: 0.3475 - acc: 0.8581 - val_loss: 0.2858 - val_acc: 0.8828\n",
            "Epoch 67/100\n",
            "211/211 [==============================] - 19s 89ms/step - loss: 0.3452 - acc: 0.8594 - val_loss: 0.2888 - val_acc: 0.8801\n",
            "Epoch 68/100\n",
            "211/211 [==============================] - 19s 91ms/step - loss: 0.3447 - acc: 0.8583 - val_loss: 0.2818 - val_acc: 0.8847\n",
            "Epoch 69/100\n",
            "211/211 [==============================] - 19s 92ms/step - loss: 0.3522 - acc: 0.8520 - val_loss: 0.2816 - val_acc: 0.8829\n",
            "Epoch 70/100\n",
            "211/211 [==============================] - 19s 89ms/step - loss: 0.3494 - acc: 0.8569 - val_loss: 0.2880 - val_acc: 0.8807\n",
            "Epoch 71/100\n",
            "211/211 [==============================] - 19s 89ms/step - loss: 0.3476 - acc: 0.8569 - val_loss: 0.2788 - val_acc: 0.8849\n",
            "Epoch 72/100\n",
            "211/211 [==============================] - 19s 90ms/step - loss: 0.3435 - acc: 0.8602 - val_loss: 0.2890 - val_acc: 0.8769\n",
            "Epoch 73/100\n",
            "211/211 [==============================] - 19s 89ms/step - loss: 0.3436 - acc: 0.8571 - val_loss: 0.2839 - val_acc: 0.8833\n",
            "Epoch 74/100\n",
            "211/211 [==============================] - 23s 108ms/step - loss: 0.3671 - acc: 0.8423 - val_loss: 0.3006 - val_acc: 0.8762\n",
            "Epoch 75/100\n",
            "211/211 [==============================] - 19s 90ms/step - loss: 0.3580 - acc: 0.8479 - val_loss: 0.2998 - val_acc: 0.8711\n",
            "Epoch 76/100\n",
            "211/211 [==============================] - 19s 90ms/step - loss: 0.3615 - acc: 0.8464 - val_loss: 0.2967 - val_acc: 0.8720\n",
            "Epoch 77/100\n",
            "211/211 [==============================] - 19s 89ms/step - loss: 0.3601 - acc: 0.8478 - val_loss: 0.3076 - val_acc: 0.8662\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Creating sentence pairs\n",
        "sentences_pair = [(x1, x2) for x1, x2 in zip(sentences1, sentences2)]\n",
        "\n",
        "\n",
        "######## Training ########\n",
        "\n",
        "class Configuration(object):\n",
        "    \"\"\"Dump stuff here\"\"\"\n",
        "\n",
        "CONFIG = Configuration()\n",
        "\n",
        "CONFIG.embedding_dim = siamese_config['EMBEDDING_DIM']\n",
        "CONFIG.max_sequence_length = siamese_config['MAX_SEQUENCE_LENGTH']\n",
        "CONFIG.number_lstm_units = siamese_config['NUMBER_LSTM']\n",
        "CONFIG.rate_drop_lstm = siamese_config['RATE_DROP_LSTM']\n",
        "CONFIG.number_dense_units = siamese_config['NUMBER_DENSE_UNITS']\n",
        "CONFIG.activation_function = siamese_config['ACTIVATION_FUNCTION']\n",
        "CONFIG.rate_drop_dense = siamese_config['RATE_DROP_DENSE']\n",
        "CONFIG.validation_split_ratio = siamese_config['VALIDATION_SPLIT']\n",
        "\n",
        "siamese = SiameseBiLSTM(CONFIG.embedding_dim , CONFIG.max_sequence_length, CONFIG.number_lstm_units , CONFIG.number_dense_units, CONFIG.rate_drop_lstm, CONFIG.rate_drop_dense, CONFIG.activation_function, CONFIG.validation_split_ratio)\n",
        "\n",
        "best_model_path = siamese.train_model_no_embedding(sentences_pair, is_similar, model_save_directory='./', fold = 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV1xjlqiWpRj"
      },
      "source": [
        "# Training Siamese LTSM + Flair Embedding\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHjnjZOkqoBb",
        "outputId": "4d8342e6-2084-4bda-e7b3-8c7ad7da84aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-08-01 11:44:39,707 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmpouqx728e\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 153M/153M [00:07<00:00, 22.3MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-08-01 11:44:47,328 copying /tmp/tmpouqx728e to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-08-01 11:44:47,854 removing temp file /tmp/tmpouqx728e\n",
            "2023-08-01 11:44:48,451 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim not found in cache, downloading to /tmp/tmpm_1p0ur8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20.5M/20.5M [00:01<00:00, 12.9MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-08-01 11:44:50,667 copying /tmp/tmpm_1p0ur8 to cache at /root/.flair/embeddings/glove.gensim\n",
            "2023-08-01 11:44:50,702 removing temp file /tmp/tmpm_1p0ur8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-08-01 11:44:57,160 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/news-forward-0.4.1.pt not found in cache, downloading to /tmp/tmpzue0xipf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 69.7M/69.7M [00:03<00:00, 20.1MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-08-01 11:45:01,250 copying /tmp/tmpzue0xipf to cache at /root/.flair/embeddings/news-forward-0.4.1.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-08-01 11:45:01,657 removing temp file /tmp/tmpzue0xipf\n"
          ]
        }
      ],
      "source": [
        "######## Flair ############\n",
        "\n",
        "\n",
        "all_sentences = sentences1 + sentences2\n",
        "\n",
        "embedding_matrix = flair_embed_meta_data(all_sentences)\n",
        "\n",
        "\n",
        "## creating sentence pairs\n",
        "sentences_pair = [(x1, x2) for x1, x2 in zip(sentences1, sentences2)]\n",
        "\n",
        "\n",
        "######## Training ########\n",
        "\n",
        "class Configuration(object):\n",
        "    \"\"\"Dump stuff here\"\"\"\n",
        "\n",
        "CONFIG = Configuration()\n",
        "\n",
        "CONFIG.embedding_dim = siamese_config['EMBEDDING_DIM']\n",
        "CONFIG.max_sequence_length = siamese_config['MAX_SEQUENCE_LENGTH']\n",
        "CONFIG.number_lstm_units = siamese_config['NUMBER_LSTM']\n",
        "CONFIG.rate_drop_lstm = siamese_config['RATE_DROP_LSTM']\n",
        "CONFIG.number_dense_units = siamese_config['NUMBER_DENSE_UNITS']\n",
        "CONFIG.activation_function = siamese_config['ACTIVATION_FUNCTION']\n",
        "CONFIG.rate_drop_dense = siamese_config['RATE_DROP_DENSE']\n",
        "CONFIG.validation_split_ratio = siamese_config['VALIDATION_SPLIT']\n",
        "\n",
        "siamese = SiameseBiLSTM(CONFIG.embedding_dim , CONFIG.max_sequence_length, CONFIG.number_lstm_units , CONFIG.number_dense_units, CONFIG.rate_drop_lstm, CONFIG.rate_drop_dense, CONFIG.activation_function, CONFIG.validation_split_ratio)\n",
        "\n",
        "best_model_path = siamese.train_model_Flair(sentences_pair, is_similar, embedding_matrix, model_save_directory='./', fold = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcZumskzWpRj",
        "outputId": "b114064f-cc46-4302-9bee-d4334ae3b1ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 3s 20ms/step\n",
            "[('signex technologies  2a brem wee altwies', 'signex technologies  2a brem wee altwies', 0.9661705), ('park 2 filsrodf', 'vashi electricals  14 porte ardennes erpeldange sur sûre', 0.9661705), ('stuart 11 filsdorf altwies', 'shah 4 eglise schouweiler', 0.9661705), ('duffy 21 filsdorf altwies', 'altwies duffy 21 filsdorf', 0.9661705), ('wagh bakri tea ggoul 2 framd rue algwiea', 'obrien ettelbruck 26', 0.9661705), ('melton 11 grand rue altwies', 'melton 11 grnd re altwies', 0.9661705), ('5ic mondorf altwies', 'ppwery 8 madf luxembourg', 0.9661705), ('travis 13 mondorf altwies', 'travis 13 mondorf altwies', 0.9661705), ('allen 22 mondorf altwies', 'allen 22 mondorf altwies', 0.9661705), ('pacheco 42 mondorf altwies', 'cain 65 romains bigonville', 0.9661705), ('horne 14 rojaims aihwies', 'lilavati hozpotal & research centff 19 hätewisx beaufort', 0.9661705), ('sarthee consultancy  7 luxembourg altwies', 'hill 5 kaulepad mertzig', 0.9661705), ('braun 15 luxembourg altwies', 'jp infra  3 eglise emerange', 0.9661705), ('gokaldas images  24 luxembourg altwies', 'ettelbruck prime focus  46 grand rue', 0.9661705), ('simmons 42 luxembourg altwies', 'avenue  130 principale tétange visas', 0.9661705), ('barr 6 sources altwies', 'heath 145 victor hugo esch sur alzette', 0.9661705), ('russell 3 emile kohn altwies', 'gelfaux wdzt 251 waassertrap', 0.9661705), ('goodwin 13a julien gergwr aofwies', 'daniels 141 longwy pétange', 0.9661705), ('software ag  16 duerfstrooss alscheid', 'software ag  16 duerfstrooss alscheid', 0.9661705), ('rishabh instruments  3 victor hugo altwies', 'altwuds rishabh instdumenhs 3 victor hugo', 0.9661705), ('le 12 victor hugo altwies', 'le 12 victor hugo altwies', 0.9661705), ('sterling auxiliaries  9a jean pierre koppes altwies', 'nsh nasser saeed alhajri co. qatar  6 hueschterterboesch senningerberg', 0.9661705), ('werner 27 jean pierre koppes altwies', 'wedned 27 kewn pierre koppes altwies', 0.9661705), ('crane 6 jean pierre molitor altwies', 'crane 6 jean pierre molitor altwies', 0.9661705), ('tlc alscheid', 'reeves 17 rénk bettborn', 0.9661705), ('xegtral tool room & rgaining dentrr 1 schüttbuerger millen alscheid', 'buildahome  28 kahlenberg grevenmacher', 0.9661705), ('green power international  5 aktivitéitszon allerborn', 'freshworks  43 neudorf luxembourg', 0.9661705), ('lucas 52 bläiminnestrooss allerborn', 'lucas 52 bläiminnestrooss allerborn', 0.9661705), ('castro 7 féitsch allerborn', 'hale 19 hiwelchen bettange sur mess', 0.9661705), ('dedket 3 vin ahn', 'mclean 25 faubourg esch sur alzette', 0.9661705), ('ujjivan small finance bank  39 vin ahn', '\\tnational skill development corporation  3 lilas bascharage', 0.9661705), ('howell 32 duerefstrooss', 'competent software  5c hollenfels tuntange', 0.9661705), ('lester 51 duerefstrooss allerborn', 'weiss 16a reckange mondercange', 0.9661705), ('ellison 2 village abweiler', 'techno kart india  31 langheck alzingen', 0.9661705), ('centillion solutions and services  16 village abweiler', 'centillion solutions and services  16 village abweiler', 0.9661705), ('caldwell 23 village abweiler', 'caldwell 23 village abweiler', 0.9661705), ('estes 31 village abweiler', 'estes c3y1 village abweiler', 0.9661705), ('dorsey 50a village abweiler', 'abweiler 50a village dorsey', 0.9661705), ('ballard 52b village abweiler', 'ballard 52b viilqge abwfiper', 0.9661705), ('baazar ahn', 'gutierrez 26 noertzange', 0.9661705), ('11 résistance ahn', 'confiance bizsol  2 rodemack hesperange', 0.9661705), ('netscribes  5 vignes ahn', 'dunn 20 bommert pétange', 0.9661705), ('house 36 vignes ahn', 'ahn house 36 vignes', 0.9661705), ('marquez 6 becherwee altrier', 'marquez 6 becherwee altrier', 0.9661705), ('wall 1 tumulus altrier', 'bender 21 forêt verte heisdorf', 0.9661705), ('secure value  11 tumulus altrier', 'garrison 124 dudelange', 0.9661705), ('ashley 8 niederdonven ahn', 'barnett 31 forêt schifflange', 0.9661705), ('bell 25a niederdonven ahn', 'transaction solktiin international india 57 golleridh luxemnoutg', 0.9661705), ('cg foods  5 heeschbregerwee altrier', 'cg foods  5 heeschbregerwee altrier', 0.9661705), ('summers 14 kreizenheicht altrier', 'summers 14 kreizenheicht altrier', 0.9661705), ('day 11 wameschbur altrier', 'day 11 wzmrschbur aitdier', 0.9661705), ('shalimar paints  2 schanz altrier', 'paints  2 schanz altrier shalimar', 0.9661705), ('international  14 schanz altrier magna', 'lyons 3 modeleurs dudelange', 0.9661705), ('max life insurance  27 schanz altrier', 'max life insurance  27 schanz altrier', 0.9661705), ('ict sms  40 schanz altrier', 'ict sms  40 schanz altrier', 0.9661705), ('montoya 48 schanz altrier', 'calderon 18 hooch wilwerdange', 0.9661705), ('marsh 58 schanz altrier', 'christnach 5 moellerdallerstrooss baird', 0.9661705), ('pena 2 godbrange altlinster', 'pena 2 godbrange altlinster', 0.9661705), ('cibersites india  3a junglinster altlinster', 'india  3a junglinster altlinster cibersites', 0.9661705), ('mack 9 junglinster altlinster', 'madm 9 juntiinster altlinster', 0.9661705), ('emitec emission control technologies  18a jeunesse sacrifiée 1940 1945 alzingen', 'emitec emission control yecynologies 18a ieunrsse sacrifkés 1940 1945 alzingen', 0.9661705), ('orange business services  32 jeunesse sacrifiée 1940 1945 alzingen', 'bakxj steel industries 32 hesperange jrzig', 0.9661705), ('landry 5 weiherchen alzingen', 'pacheco 42 izig hesperange', 0.9661705), ('kshema power and infrastructure company  15 larochette altlinster', 'kshema power and infrastructure company  15 larochette altlinster', 0.9661705), ('hurst 2 prés altlinster', 'uirzn foreign trade 40 bascharage vlemdncy', 0.9661705), ('ptc  1 haard alzingen', 'ptc  1 haard alzingen', 0.9661705), ('polmon instruments  10 hondsbreck alzingen', 'lee 61 noertzange huncherange', 0.9661705), ('interarch building product  5 rothweit alzingen', 'interarch alzingen building product  5 rothweit', 0.9661705), ('tradeindia.com  19 rothweit alzingen', 'tradeindia.com  19 rothweit alzingen', 0.9661705), ('turbo energy  8 abbé edouard garnich alzingen', 'avis  2 klensch bettembourg', 0.9661705), ('phillips 18 abbé edouard garnich alzingen', 'phillips 18 abbé edouard garnich alzingen', 0.9661705), ('salarpuria sattva  1a eglise alzingen', 'salarpuria sattva  1a eglise alzingen', 0.9661705), ('bharat wire ropes  8 eglise alzingen', 'bharat wire ropes  8 eglise', 0.9661705), ('meyers 427a thionville alzingen', 'baird 14 sélange clemency', 0.9661705), ('offshore infrastructures  467 thionville alzingen', 'griffin 37 maison reuler', 0.9661705), ('5 hesperange alzingen', 'axis solutions  2 kiem kehlen', 0.9661705), ('pittman 16 hesperange alzingen', 'jordan 18 massen troisvierges', 0.9661705), ('studds accessories  487 thionville alzingen', 'studds alzingen', 0.9661705), ('wolf 500 thionville alzingen', 'wolf 500 thionville alzingen', 0.9661705), ('e-solutions  518 thionville alzingen', 'schiller healthcare india  57 eich leudelange', 0.9661705), ('wilkins 44 hesperange alzingen', 'luna 6a champs steinfort', 0.9661705), ('pacific cyber technology  582 thionville alzingen', 'pratt 13 luxembourg imbringen', 0.9661705), ('hardin 6 albert bousser alzingen', 'jrnkijs 5 puellen nptgum', 0.9661705), ('light microfinance  2 roeser alzingen', 'light microfinance  2 roeser alzingen', 0.9661705), ('alsjngen mora 17 rowsdr', 'cbse  62 ehlerange esch sur alzette', 0.9661705), ('perry 30 roeser alzingen', 'mindgate solutions  19 jean braun crauthem', 0.9661705), ('kabra extrusion technik  40 roeser alzingen', 'eis associates  25 fond matin luxembourg', 0.9661705), ('dominguez 6 jean steichen alzingen', 'dominguez 6 jean steichen alzingen', 0.9661705), ('jet airways  12 jean steichen alzingen', 'cobb 51 henri lück rumelange', 0.9661705), ('knapp 9 cimetière alzingen', 'knapp 9 cimetière alzingen', 0.9661705), ('bray 5b syren alzingen', 'triton valves  23 mondercange ehlerange', 0.9661705), ('federal bank  10a syren alzingen', 'com 3 deich mensdorf', 0.9661705), ('shjah cooper standard antivibration syshfms 21a syren alzinhfn', 'barry 233x mirchbefg luxembourg', 0.9661705), ('kent 29 syren alzingen', 'kent 29 syren alzingen', 0.9661705), ('gcardetel infotech  40 syren alzinygen', 'galvan 44 marthe prim welter junglinster', 0.9661705), ('small 4 jean wolter alzingen', 'small 4 jean wolter alzingen', 0.9661705), ('jimenez 14 jean wolter alzingen', 'sloan 17 kierchestrooss schrondweiler', 0.9661705), ('leonard 12 josy haendel alzingen', 'moyrd 20 haaptsteposs tadler', 0.9661705), ('ratnamani metals and tubes  26 josy haendel alzingen', 'ratnamani alzingen', 0.9661705), ('brahmayya  13 jos paquet alzingen', 'brahmayya  13 jos paquet alzingen', 0.9661705), ('gibbs 2 brem wee altwies', 'gibbs 2 brem wee schifflange', 0.96405363), ('+ nxgek 3a filsdorf aptwids', 'qesterg refrireratjon 102 dahlem schouweiler', 0.96405363), ('indira gandhi international airport  12 filsdorf altwies', 'indira gandhi international airport  12 filsdorf biwer', 0.96405363), ('dyer 22 filsdorf altwies', 'dyer 22 filsdorf berbourg', 0.96405363), ('chang 3 grand rue altwies', 'tüv rheinland  13g ecole', 0.96405363), ('msghire 12 geajd rue altwies', 'mando automotjvf 38 mzrttrs esch sur aozrtte', 0.96405363), ('ortiz 6 mondorf altwies', 'ortiz 6 mondorf ehlerange', 0.96405363), ('afcadjs 14 ondorf algwirs', '73 koselh simon cabreffa wiltz', 0.96405363), ('sims 24 mondorf altwies', 'sims 24 mondorf mensdorf', 0.96405363), ('ramirez 44 mondorf altwies', 'ramirez 44 mondorf luxembourg', 0.96405363), ('jindal itf  15 romains altwies', 'apokll yr 12 aûde echternach', 0.96405363), ('mini muthoottu nidhi k  9a luxembourg altwies', 'mini muthoottu nidhi k  9a luxembourg luxembourg', 0.96405363), ('mic electronics  16 luxembourg altwies', 'vishwaraj hosital  16 lac bivels', 0.96405363), ('scott 25 luxembourg altwies', 'scott 25 luxejblurg rodange', 0.96405363), ('automotive research association of india  44 luxembourg altwies', 'automotive research association of india  44 luxembourg mertzig', 0.96405363), ('altwies click labs  7 sources', 'shivaik small finan ank   7 kohnerloch vianden', 0.96405363), ('dawson 4 emile kohn altwies', 'filatex india  42b belle vue lorentzweiler', 0.96405363), ('transparency market research  13b julien berger altwies', 'transparency market research  13b julien berger bascharage', 0.96405363), ('la technologies  22 duerfstrooss alscheid', 'la technologies  22 duerfstrooss contern', 0.96405363), ('minilec  4a victor hugo altwies', 'lowery 23 ierwescht duerf enscherange', 0.96405363), ('13 ckctor hiho altwies', 'ozbogne 1 jads syren', 0.96405363), ('chavez 9b jean pierre koppes altwies', 'chavez 9b jean pierre koppes fischbach', 0.96405363), ('bowers 29 jean pierre koppes altwies', 'pollard 9 charles quint luxembourg', 0.96405363), ('securitas  8 jean pierre molitor altwies', 'securitas  8 jean pierre molitor contern', 0.96405363), ('sap eariba  t8 mäerkelzer strooss kalscheida', 'peters 38 henri entringer howald', 0.96405363), ('jiva ayurvedic pharmacy  1 bëchel alscheid', 'jiva ayurvedic pharmacy  1 bëchel schifflange', 0.96405363), ('the global green company  7 aktivitéitszon allerborn', 'duke 78 principale lasauvage', 0.96405363), ('electropneumatics & hydraulics (i)  92 bläiminnestrooss allerborn', 'electropneumatics & hydraulics (i)  92 bläiminnestrooss bettembourg', 0.96405363), ('lee 8 féitsch allerborn', 'ministry of rural development india  17b château eau kleinbettingen', 0.96405363), ('potts 5 vin ahn', 'potts 5 vin luxembourg', 0.96405363), ('aguilat 43 vin ahn', 'lloyd 14 om biereg lieler', 0.96405363), ('hurley 35 duerefstrooss allerborn', 'assimilate aoljtions 4 cerisiers niedwrjorn', 0.96405363), ('rogers 55 duerefstrooss allerborn', 'colon 194 luxembourg bettembourg', 0.96405363), ('ntf 4 violahe abwelker', 'chemtrols industries  4a olingen betzdorf', 0.96405363), ('headstrong capital markets  17 village genpact abweiler', 'meadows 89 luxembourg dippach', 0.96405363), ('castaneda 25 village abweiler', 'castaneda 25 village stadtbredimus', 0.96405363), ('stout 33 village abweiler', 'sout 33 village heiderscheid', 0.96405363), ('sellers 50b village abweiler', 'sellers 50b village baschleiden', 0.96405363), ('madden 52c village abweiler', 'madden 52c villayf bettembourg', 0.96405363), ('dantu 3 réqistancr ahn', 'cohen 22 pruniers luxembourg', 0.96405363), ('liji intime 12 résistandf ahn', 'leach 4 romains sandweiler', 0.96405363), ('shree baidyanath ayurved bhawan  6 vignes ahn', 'shree baidyanath ayurved bhawan  6 vignes heiderscheid', 0.96405363), ('yang 39 vignes ahn', 'yang 39h vignes grevenmacher', 0.96405363), ('garner 8 becherwee altrier', 'garner 8 becherwee alzette', 0.96405363), ('mcdonald 2 tumulus altrier', 'mcdonald 2 tumulus howald', 0.96405363), ('gail altrier', 'knox 68 trèbeq luxsmbpurg', 0.96405363), ('yutaka autoparts pune  13 niederdonven ahn', 'yutaka autoparts pune  13 niederdonven winseler', 0.96405363), ('wolfe 25 niederdonven ahn', 'wppfe 25 niexerdonveh kleinbettingen', 0.96405363), ('isc projects  7 heeschbregerwee altrier', 'lowery 16 cimetière godbrange', 0.96405363), ('lafarge  18 kreizenheicht altrier', 'becton dickinson  59 acier esch sur alzette', 0.96405363), ('pagetraffic web-tech  2 hemstelerwee altrier', 'pagetraffic web-tech  2 hemstelerwee schweich', 0.96405363), ('nolan 4 schanz altrier', 'nklab 4 sdhagz junglinster', 0.96405363), ('ls soqble 15 schanz alrrker', 'blue consulting  52 anatole france luxembourg', 0.96405363), ('rashmi group  28 schanz altrier', 'sansera engineering  4 enner owent', 0.96405363), ('fullerton india  41a schanz altrier', 'fullerton india  41a schanz perlé', 0.96405363), ('scoreme altrier', 'bvc logistics  79 jos lommel niederkorn', 0.96405363), ('59 schanz altrier barron', 'emerspb climate technologies 7 udingen mwrech', 0.96405363), ('higgins 3 godbrange altlinster', 'higgins 3 godbrange capellen', 0.96405363), ('knight altlinster', 'koch 18 mathieu lambert schrobilgen luxembourg', 0.96405363), ('glass 10a junglinster altlinster', 'watson 1 vallée', 0.96405363), ('moore 18b jeunesse sacrifiée 1940 1945 alzingen', 'moore 18b jeunesse sacrifiée 1940 1945 crauthem', 0.96405363), ('rivers 34 jeunesse sacrifiée 1940 1945 alzingen', 'newo 10 dkennedy geidel', 0.96405363), ('marelli  6 weiherchen alzingen', 'marelli  6 weiherchen gare', 0.96405363), ('2 luxembourg altlinster suarez', 'acro paints  39 pontpierre mondercange', 0.96405363), ('bishop 3a prés altlinster', 'bishop 3a prés luxembourg', 0.96405363), ('parexel international  1 hondsbreck alzingen', 'parexel international  1 hondsbreck heiderscheid', 0.96405363), ('arctern consulting  11 hondsbreck alzingen', 'arctern consulting  11 hondsbreck senningerberg', 0.96405363), ('patel 6 rtehweit alzingen', 'walton 60 haaptstrooss ell', 0.96405363), ('csc e governance services  21 rothweit alzingen', 'e governance services  21 rothweit alzingen lamadelaine', 0.96405363), ('brilyant it solutions  9 abbé edouard garnich alzingen', 'brilyant it solutions  9 abbé edouard garnich remich', 0.96405363), ('huff 19 abbé edouard garnich alzingen', 'modern cojstruvtion sompaby 6 maeschgaqart goesdorf', 0.96405363), ('galvan 1 eglise alzingen', 'drive sysfejs 3 jesg wirfes dudelange', 0.96405363), ('watson 9 eglise alzinhigen', 'vibracoustic  22 heelt eschdorf', 0.96405363), ('garrison 427a thionville alzingen', 'garrison 427a thionville remich', 0.96405363), ('sp apparels  471 thionville alzingen', 'sp apparels  471 thionville luxembourg', 0.96405363), ('alzingen housing finance  7a hesperange pnb', 'apollo home healthcare  21 gioacchino rossini luxembourg', 0.96405363), ('english 18 hesperange alzingen', 'english 18 hesperange bettembourg', 0.96405363), ('realty assistant 489 tgioncille aozimgen', 'kfc  46 jean baptiste esch luxembourg', 0.96405363), ('blevins 504a thionville alzingen', 'lotus herbals  270 arlon strassen', 0.96405363), ('aloha technology  23 hesperange alzingen', 'aloha technology  23 hesperange greiveldange', 0.96405363), ('volvo  46 hesperange alzingen', 'volvo  46 hsperange gare', 0.96405363), ('wright 584 thionville alzingen', 'wright luxembourg', 0.96405363), ('toshiba jsw power systems  7 albert bousser alzingen', 'ylshiba jsw oowed systems 7 albert blusswr luxembourg', 0.96405363), ('fletcher 4 roeser alzingen', 'newman 9 aale waasser', 0.96405363), ('carter 18 roeser alzingen', 'carter 18 roeser assel', 0.96405363), ('parijat industries (india)  31a roeser alzingen', 'parijat industries (india)  31a roeser luxembourg', 0.96405363), ('cadbury  41 roeser alzingen', 'cadbury  41 roeser heinerscheid', 0.96405363), ('ford india  7 jean steichen alzingen', 'ford india  7 jean steichen echternach', 0.96405363), ('mcke 4 jea steichen alzingen', 'dunn 12 irbicht beringen', 0.96405363), ('holt 19 cimetière alzingen', 'encore healthcare  4 gruefkaul dalheim', 0.96405363), ('paharpur 3p  5c syren alzingen', 'sotc travel services  6 tom lellingen', 0.96405363), ('triumphant institute of management education  10 syren alzingen', 'dun & bradstreet  65 grand duc adolphe dudelange', 0.96405363), ('sutton 21 syren alzingen', 'vst indushtries 7 den jenxkrn pwétnhs', 0.96405363), ('bush 31 syren alzingen', 'bush 31 syren luxembourg', 0.96405363), ('hospet steels  41 syren alzingen', 'pearson 12 hétwnge kxyi', 0.96405363), ('golden 5 jean wolter alzingen', 'ritter 1 den aessen bech', 0.96405363), ('a.k.automatics  15 jean wolter alzingen', 'a.k.automatics  15 jean wolter deiffelt', 0.96405363), ('lopez 13 josy haendel alzingen', '7 luxembourg grevenmacher', 0.96405363), ('navarro 28 josy haendel alzingen', 'nxvwrro 28 jodh haendel kuborn', 0.96405363), ('airtel business  15 jos paquet alzingen', 'artech infosystems  47 michel welter luxembourg', 0.96405363), ('szco bank 1 beeh wee altwies', 'luxembourg 21i fernannd huart sotevens', 0.9478572), ('navin fluorine international  2a filsdorf altwies', 'carillion alawi llc  57 romains luxembourg', 0.9478572), ('potter 10 filsdorf altwies', 'potter 10 filsdorf altwies', 0.9478572), ('gpnd 19 filsdorf aotwids', 'jensen 12 ieweschtgaass bech', 0.9478572), ('akshaya  2a grand rue altwies', 'amshata 2a grand rue asltwiex', 0.9478572), ('roquette riddhi siddhi  10 grand rue altwies', 'roquette riiddhi siuddhi  10 grand rue altwies', 0.9478572), ('ortel communications  5b mondorf altwies', 'ortel commuications  5b mondorf altwies', 0.9478572), ('black 13a mondorf altwies', 'bak 13a mondorf altwies', 0.9478572), ('sollibs 20 mondorf wltwiee', '23 dahlem schouweiler', 0.9478572), ('mrcc solutions  40 mondorf altwies', 'mrcc solutions  40 mondorf altwies', 0.9478572), ('baker 12 romains altwies', 'baker altwies 12 romains', 0.9478572), ('intellipaat software solutions  6 luxembourg altwies', 'common service centres  11 den kreuzwiesen steinsel', 0.9478572), ('webster 14 luxembourg altwies', 'webster 14 luxembourg altwies', 0.9478572), ('winters 23 luxembourg altwies', 'winters 23 luxembourg altwies', 0.9478572), ('avantha technologies  40 luxembourg altwies', 'avantha technologies  40 luxembourg altwies', 0.9478572), ('haney 5 sources altwies', 'janfy 5 sources altwoez', 0.9478572), ('chambal fertilisers and chemicals  2 emile kohn altwies', 'mahindra rural housingk finpance  z81 luxembouvrg dippach', 0.9478572), ('keller 11 julien berger altwies', 'keller 11 julien berger altwies', 0.9478572), ('myteam11  14 duerfstrooss alscheid', 'myhfam11 14 duerfstrooss', 0.9478572), ('poly medicure  2 victor hugo altwies', 'poly medicure 2 bichor mugk altwies', 0.9478572), ('ibarra 11 victor hugo altwies', 'kansai nerolac paints  35 marche luxembourg', 0.9478572), ('parker 7 jean pierre koppes altwies', 'parker 7 jean pierre koppes altwies', 0.9478572), ('altiwies pasco moptors  25 jean pierre koppes', 'king 17 pierre maisonnet luxembourg', 0.9478572), ('vini cosmetics  4d jean pierre molitor altwies', 'vini cosmetics  4d jean pierre molitor altwies', 0.9478572), ('shepherd 4a mäerkelzer strooss alscheid', 'bell 7 posteck asselborn', 0.9478572), ('prime focus technologies  7 héicht alscheid', 'gandhi institute for technology  35 scheid oberanven', 0.9478572), ('jk cement  20 bëchel alscheid', 'jk cementr  20 bëchel alscheid', 0.9478572), ('adma solutions  50 bläiminnestrooss allerborn', 'stout 49 esch fennange', 0.9478572), ('igddl mkneu 8 schoulbierg alscheid', 'murillo 19 alphonse munchen bertrange', 0.9478572), ('bartplett 17 burren allerborn', 'weber 6 ydix septembre hautcharuqage', 0.9478572), ('hopkins 37 vin ahn', 'hopkins 37 vin ahn', 0.9478572), ('abbott nutrition international  26 duerefstrooss allerborn', 'abbott nutrition international  26 duerefstrooss allerborn', 0.9478572), ('balaji telefilms  46 duerefstrooss allerborn', 'balaji teleficlms  46 dueremfstrqooss allerborn', 0.9478572), ('rustomjee group  1 village abweiler', 'rustomjee group  1 village abweiler', 0.9478572), ('12 village haydenm abweiler', 'sharp 9 bois bigonville', 0.9478572), ('franklin 22 village abweiler', 'short 89 welscheid warken', 0.9478572), ('aga khan university hospital  30 village abweiler', 'wilkins 12 kiircjhepad rambroucsh', 0.9478572), ('the times of india  48b village abweiler', 'the times of india  48b village abweiler', 0.9478572), ('bautista 52maq village abweiler', 'goyal brothers prakashan  36 semois luxembourg', 0.9478572), ('robertson 1 résistance ahn', 'watson 1 vallée', 0.9478572), ('hughes 9 résistance ahn', 'hughes 9 résistance ahn', 0.9478572), ('geltec  4 vignes ahn', 'geltec  4 vignes ahn', 0.9478572), ('kaminenni hospitals  28e vignes ahn', 'santos 67 grand rue eischen', 0.9478572), ('xwchi foods 4 hechegwee altrier', 'ils hospital  55 hekt noertrange', 0.9478572), ('brennan it  10 aly duhr ahn', 'bowman 21 ecole lenningen', 0.9478572), ('thermax babcock wilcox energy solutions  10 tumulus altrier', 'autohangar  21 flebour boulaide', 0.9478572), ('schneider 7 niederdonven ahn', 'luna 90 victor hhro luxejbojrg', 0.9478572), ('heath 20 niederdonven ahn', 'micro focus  11 birkbour beaufort', 0.9478572), ('mason 3 heeschbregerwee altrier', 'mason 3 heeschbregerwee altrier', 0.9478572), ('su-kam power systems  12 kreizenheicht altrier', 'su-kam power systems  12 kreizenheicht altrier', 0.9478572), ('acosta 9 wameschbur altrier', 'acosta 9 wamschbu altrier', 0.9478572), ('mueller 29 rausch altrier', 'melle 29 rausch altrier', 0.9478572), ('power transmission 13 schanz zltdier kallaharu', 'mullen 23 xcmifflange esch sur alzdttw', 0.9478572), ('skanray technologies  26 schanz altrier', 'skanray technologies  26 schanz altrier', 0.9478572), ('cline 39 schanz altrier', 'cline 39 schanz altrier', 0.9478572), ('warren 47 schanz altrier', 'viveks 69 ponhpiegre momdercanve', 0.9478572), ('sidwal refrigeration industries  56 schanz altrier', 'holmes 29 luxembourg assel', 0.9478572), ('apollo speciality hospital  2a godbrange altlinster', 'apollo speciality hospital  2a godbrange altlinster', 0.9478572), ('fritz 2 junglinster altlinster', 'woqlfe 44 lac arsdorf', 0.9478572), ('altlinster hoover 8 junglinster', 'matrimony.com  14 canal ettelbruck', 0.9478572), ('macurex sensors  16 jeunesse sacrifiée 1940 1945 alzingen', 'resurgent india  9 vallée neuhaeusgen', 0.9478572), ('cross alzingen', 'hudia systems 16 jean pierre bipoert hespegangr', 0.9478572), ('patton 4 weiherchen alzingen', 'alzingen patton 4 weiherchen', 0.9478572), ('wilson 13 larochette altlinster', 'wilson 13 oarofdhette atltlinzfer', 0.9478572), ('shorthills tech  1 prés altlinster', 'shorthills tech  1 prés altlinster', 0.9478572), ('theme engineering services  12 prés altlinster', 'theme engineering services  12 prés altlinster', 0.9478572), ('barnes 9 hondsbreck alzingen', 'monsanto  17a gilsduerferstrooss ermsdorf', 0.9478572), ('burgess 4 rothweit alzingen', 'burgess 4 rothweit alzingen', 0.9478572), ('prepladder  17 rothweit alzingen', 'motilal oswal financial services  9 kiirfechtsstrooss rodershausen', 0.9478572), ('buchanan 7 wnbé edouard garnich apxingen', 'omics international  10 sellier bertrange', 0.9478572), ('cameron 17 abbé edouard garnich alzingen', 'cameron 17 abbé edouard garnich alzingen', 0.9478572), ('bharat eeahs 21 zbfé ediuadd garnich alzingen', 'petersen 11 rochefort luxembourg', 0.9478572), ('al shifa multispeciality hospital  7 eglise alzingen', 'sendan international co e 88 egalité luxvembourg', 0.9478572), ('booker 425 thionville alzingen', 'booker 425 thionvikie alzihgeb', 0.9478572), ('cannon 465 thionville alzingen', 'blanchard 32 klein ettelbruck', 0.9478572), ('trigo quality production services  5a hesperange alzingen', 'quality production services  5a hesperange alzingen trigo', 0.9478572), ('dodson 14 hesperange alzingen', 'dodson 14 hesperange alzingen', 0.9478572), ('hale 484 thionville alzingen', 'opulentus overseas careers  37 prinzenberg niederkorn', 0.9478572), ('cooper 498 thionville alzingen', 'voopwr 498 thionville alaingej', 0.9478572), ('suprajit engineering  516 thionville alzingen', 'suprajit engineering  516 thionville alzingen', 0.9478572), ('pebs pennar  42 hesperange alzingen', 'pebs pennar  42 hesperange alzingen', 0.9478572), ('clarke 580 thionville alzingen', 'clarke 580 thionville alzingen', 0.9478572), ('sit engineering  5 albert bousser alzingen', 'satra infrastructure management services  9a abbé henri muller ettelbruck', 0.9478572), ('poole 18 albert bousser alzingen', 'poovle 18 albert bousser alzingen', 0.9478572), ('weiss 16 roeser alzingen', 'weiss 16 roeser alzingen', 0.9478572), ('mcgrath 29 roeser alzingen', 'mcgrath 29 roeser alzingen', 0.9478572), ('mcbride 39 roeser alzingen', 'saurav chemicals  3a alzette roeser', 0.9478572), ('marshall 5 jean steichen alzingen', 'marshall 5 jean steichen alzingen', 0.9478572), ('zavala 11 jean steichen alzingen', 'henson 6 brfcl glnderangs', 0.9478572), ('morrow 7 cimetière alzingen', 'morrow 7 cimetière alzingen', 0.9478572), ('tata communications transformation services  5a syren alzingen', 'bec 151 ucen salentiny ettelbruck', 0.9478572), ('dfm foods  9 syren alzingen', 'dfm foods  9 syren alzingen', 0.9478572), ('rutdrrez 20 syren alainten', 'solokog 20 wengeryswef stadtbredimus', 0.9478572), ('besmak components  29b syren alzingen', 'besmak components  29b syren alzingen', 0.9478572), ('vincent 39 syren alzingen', 'vincent 39 syren alzingen', 0.9478572), ('smith 3 jean wolter alzingen', 'ptoptiner. com 20 rdaard steichen péfanye', 0.9478572), ('fhpl  13 jean wolter alzingen', ' 13 jean wolter alzingen fhpl', 0.9478572), ('zenith industrial rubber products  11 josy haendel alzingen', 'zenith induxtriak tuhber products 11 josy haendel alzkngeg', 0.9478572), ('mcmillan 24 josy haendel alzingen', 'benitez 105 esch luxembourg', 0.9478572), ('ani integrated services  11 jos paquet alzingen', 'alzingen integrated services  11 jos paquet ani', 0.9478572), ('sree vidyanikethan engineering college  4 brem wee altwies', 'sree vidyanikethan engineering college  4 brem wee altwies', 0.9225953), ('mars international india  3 filsdorf altwies', 'wipro enterprises ltd  18 beyren mensdorf', 0.9225953), ('jubilant generics  13 filsdorf altwies', 'jubilant generics  13 filsdorf altwies', 0.9225953), ('watkins 24 filsdorf altwies', 'wstkim 24 filsdorf wltwues', 0.9225953), ('walker 4 grand rue altwies', 'chang 5 liberté differdange', 0.9225953), ('oneclick it consultancy  13 grand rue altwies', 'harrij 18 franklin fooseveot olm', 0.9225953), ('morse 7 mondorf altwies', 'morse 7 mondorf altwies', 0.9225953), ('altwies browning 15 mondorf', 'hindustan composites  2c redeschbierg reckange', 0.9225953), ('falcon autotech  26 mondorf altwies', 'marc enterprises  8 kleinbettingen steinfort', 0.9225953), ('skinner 46 mondorf altwies', 'skinner 46 mondorf altwies', 0.9225953), ('pidilite industries  16 romains altwies', 'pidilite industries  16 romains altwies', 0.9225953), ('benjamin 9b luxembourg altwies', 'vishay precision transducers  8 palmberg ahn', 0.9225953), ('zigma technologies  16 luxembourg altwies', 'zigma tchnologis  16 luxembourg alties', 0.9225953), ('bryan 26 luxembourg altwies', 'hoffman 1 forge luxembourg', 0.9225953), ('pawilia 46 ljxemboutg altwies', 'johnson 70 oberkorn', 0.9225953), ('parks 8 sources altwies', 'parks 8 sources altwies', 0.9225953), ('amphenol omniconnect - india  5 emile kohn altwies', 'amphenol omniconnect - india  5 emile kohn altwies', 0.9225953), ('hc hospital  13c julien berger altwies', 'ingenero technologies  80 luxembourg consdorf', 0.9225953), ('boone 24 duerfstrooss alscheid', 'boone 24 duerfstrooss alscheid', 0.9225953), ('flowers 4 victor hugo altwies', 'my tpme constructions 81 bd rpbrrt scguhan olm', 0.9225953), ('care hospital  1 jean pierre koppes altwies', 'care hospital  1 jean pierre koppes altwies', 0.9225953), ('bajaj motors  9 jean pierre koppes altwies', 'bajaj motors  9 jean pierre koppes altwies', 0.9225953), ('bltan 1 jean perre molitor altwies', 'batgir 42 bkls linger', 0.9225953), ('huynh 31 jean pierre koppes altwies', 'embibe  1 duarrefstrooss basbellain', 0.9225953), ('vazquez 11 mäerkelzer strooss alscheid', 'warren 25 hemei dunant etrzssen', 0.9225953), ('rocha 4 bëdichel alscheid', 'colon 17 jean aveugle belvaux', 0.9225953), ('saarloha advanced materials  10 aktivitéitszon', 'test yantra software solutions  9 françois nemers buschdorf', 0.9225953), ('all india institute of medical sciences  93 bläiminnestrooss allerborn', 'hunter 106 eolejvre cidferdange', 0.9225953), ('entertainment network india  11 féitsch allerborn', 'platinum waltech  34 bongert luxembourg', 0.9225953), ('cloudmoyo  7 vin ahn', 'cloudmoyo  7 vi abcn', 0.9225953), ('brady 1 leudelange abweiler', 'brady 1 lrudelange abaeuler', 0.9225953), ('parrish 5 village abweiler', 'parrish 5 village abweiler', 0.9225953), (\"st. joseph's college  18 village abweiler\", 'telecommunications consultants  4 dem kundel oberfeulen', 0.9225953), ('simpson 27 village abweiler', 'simpson 27 village abweiler', 0.9225953), ('mayer 34 village abweiler', 'khazana jewellery  4a burgaass gostingen', 0.9225953), ('middleton 4 palmberg ahn', 'cabtrelp 119 vin', 0.9225953), ('richard 54 village abweiler', 'clay 25 fleurs', 0.9225953), ('davidson 4a résistance ahn', 'cuevas 79 millesch roodt sur syre', 0.9225953), ('mejia 13 résistance ahn', 'mejia 13 résistance ahn', 0.9225953), ('coal india  7a vignes ahn', 'coal india  7a vigne ahn', 0.9225953), ('gilmore 1 reimergaard altrier', 'cummings 30 faubourg kayl', 0.9225953), ('ram altruef kripal singh constrjxtion 10 beshetwee', 'shivam infocom 61b lusemhourg hrkdel', 0.9225953), ('jamia millia islamia  3 tumulus altrier', 'jamia millia islamia  3 tumulus altrier', 0.9225953), ('castrol  13 tumulus altrier', 'castrol  13 tumulus altrier', 0.9225953), ('mann 14 niederdonven ahn', 'iron triangle limited (back bone office)  10 ecole schrondweiler', 0.9225953), ('alvarado 27 niederdonven ahn', 'alfaraso 27 midwderdonvven ahn', 0.9225953), ('afellank 8 heeschgreyerwee altrier', 'leayan hlogal 5 colmar ferb oberfeulen', 0.9225953), ('murphy 20 kgeizenhficht alteuer', 'hooper 6 fënnefter gaarw mullendorf', 0.9225953), ('national dairy development board  4 hemstelerwee altrier', 'national dzirh development board 4 hfmstelerwef altrorr', 0.9225953), ('strickland 5 schanz altrier', 'downs 27a vieux marché vianden', 0.9225953), ('thompson 18 schanz altrier', 'teleperformance  3 forêt eisenborn', 0.9225953), ('iljin electronics  29 schanz altrier', 'iljin electronics  29 schanz altrier', 0.9225953), ('hm constructions  41 schanz altrier', 'hm constructions  41 schanz', 0.9225953), ('lancesoft  50a schanz altrier', 'lanxesoct 0a schanz', 0.9225953), ('srf  61 schanz altrier', 'srf  61 schanz altrier', 0.9225953), ('anabeeb  4 godbrange altlinster', 'herrera 16a mies mersch', 0.9225953), ('spence 4 junglinsterh altlinster', 'watkins 14 fleurs dudelange', 0.9225953), ('olam  10 junglinster altlinster', 'wade adams contracting  11 joseph hackin boevange sur attert', 0.9225953), ('vasta bio-informatics  18 jeunesse sacrifiée 1940 1945 alzingen', 'pope 27 edhesinde luxemgohrg', 0.9225953), ('weaver 36 jeunesse sacrifiée 1940 1945 alzingen', 'relationshwip managementg  91 pierre krier tlc luxeembourg', 0.9225953), ('lindsey 3 prés altlinster', 'thriveni earthmovers  jean pierre thoma luxembourg', 0.9225953), ('sloan 2 hondsbreck alzingen', 'sloan 2 hondsbreck alzingen', 0.9225953), ('avanti learning centres  12 hondsbreck alzingen', 'avanti learning centres  12 hondsbreck alzingen', 0.9225953), ('giles 7 rothweit alzingen', 'giles 7 rothweit alzingen', 0.9225953), ('hexaware technologies  25 rothweit alzingen', 'eware technoogies  25 rothweit alzingen', 0.9225953), ('noon.com  10 abbé edouard garnich alzingen', 'sheppard 9 orée bois bereldange', 0.9225953), ('donovan 27 rothweit alzingen', 'hunt 8 gôtw ville fxch sur zlzehte', 0.9225953), ('ajay industrial corporation  2 eglise alzingen', 'ajay industrial corporation  2 eglise alzingen', 0.9225953), ('cotmac electronics  10 eglise alzingen', 'charles 207 woiwer differdange', 0.9225953), ('annjet technologimes  f427 thionville alziqngen', 'trevino 10 oetrange', 0.9225953), ('williams 473 thionville alzingen', 'williams 473 thionville alzingen', 0.9225953), ('payne 7 hesperange alzingen', 'psynr 7 hesperange alzonhen', 0.9225953), ('frost 20 hesperange alzingen', 'bradley 14 nicolas margue luxembourg', 0.9225953), ('lynch 491 thionville alzingen', 'tcs e-serve international  25 waertzgaertchen elvange', 0.9225953), ('bombay intelligence security  504 thionville alzingen', 'dhani heapthcaee 39 päsxgen contern', 0.9225953), ('cochran 27 hesperange alzingen', 'energy  29 kinnikshaff refex wahl', 0.9225953), ('serrano 48 hesperange alzingen', 'xerrani 48 hesperange alsungen', 0.9225953), ('digicall telesefvkces 586 thionviold alzingen', 'christensen 12 kennedy soleuvre', 0.9225953), ('bsl  8 albert bousser alzingen', 'eaver 5 esh sur alzette', 0.9225953), ('apzlngen 6 roeded washington', 'house 1 bëtzen binsfeld', 0.9225953), ('hooper 19 roeser alzingen', '9 nic arfnw garnich', 0.9225953), ('joyce alzingen', 'rojas 9 champs fennange', 0.9225953), ('ralson india  42 roeser alzingen', 'raksob india 42 roeser slxingen', 0.9225953), ('church 8a jean steichen alzingen', 'church 8a jean steichen alzingen', 0.9225953), ('wood 2 camping alzingen', 'fhhure supply chain soijtions 39 yôpitql diekirch', 0.9225953), ('adyard afudtabi llc 21 cimetière alzkmgen', 'siemens industry software (india)  3 grouf bettendorf', 0.9225953), ('bada bisuness 5 syren aizinnen', 'uttam galva steels 5 ciij reckabfe', 0.9225953), ('shriram value services  11 syren alzingen', 'dean 71 bonnevoie luxembourg', 0.9225953), ('atkins 23a sjrsn aozinben', 'duran 46 trois cantons garnich', 0.9225953), ('rana motors  32 syren alzingen', 'rana motors  32 syren alzingen', 0.9225953), ('clariant chemicals 16 jean wklyer alsungen', 'bascharage landis+gyr  18 lou', 0.9225953), ('leach 14 josy haendel alzingen', 'leach 14 josy haendel alzingen', 0.9225953), ('fischer 32 josy haendel alzingen', 'soto 32 grass clemency', 0.9225953), ('walking tree  17 jos paquet alzingen', 'walking tree  17 jos paquet alzingen', 0.9225953), ('kaynes technology  49 vin ahn', 'fuller 50 fischbach lintgen', 0.92259526), ('hodge 36 duerefstrooss allerborn', 'hodge 36 duerefstrooss allerborn', 0.92259526), ('spears 7 weiherchen alzingen', 'spears 7 weiherchen alzingen', 0.92259526), ('duncan 3 luxembourg altlinster', 'visiontek  42 henri grey differdange', 0.92259526), ('farrell 42 syren alzingen', 'burns 119 lamadelaine', 0.92259526), ('macdonald 6 jean wolter alzingen', 'macdonald 6 jean wolter alzingen', 0.92259526), ('armstrong 5 brem wee altwies', 'armstrong 5 brem wee altwies', 0.90247065), ('kane 4 filsdorf altwies', 'max smwgt supsf xpwcialty hospital 31 mersch kopstal', 0.90247065), ('a2z infraservices  14 filsdorf altwies', 'a2z infraservices  14 filsdorf altwies', 0.90247065), ('cloud4c  26 filsdorf altwies', 'townsend 13 anémones strassen', 0.90247065), ('van heusen  5a grand rue altwies', 'van heusen  5a grand rue altwies', 0.90247065), ('gross 14 grand rue altwies', 'sweeney 45 bonnevoie luxembourg', 0.90247065), ('icpa health products  8 mondorf altwies', 'walker 30 bischoff luxembourg', 0.90247065), ('spencer 16 mondorf altwies', 'spencer 16 mondorf altwies', 0.90247065), ('everest blowers  28 mondorf altwies', 'owens 9 loushaff differdange', 0.90247065), ('keihin india manufacturing  1 romains altwies', 'keihin india manufacturing  1 romains altwies', 0.90247065), ('arthur j. gallagher & co  59 romains altwies', 'arthur j. gallagher & co  59 romains altwies', 0.90247065), ('rasandik engineering industries india  10a luxembourg altwies', 'rasandik engineering industries india  10a luxembourg altwies', 0.90247065), ('vihaan networks  17 luxembourg altwies', 'vihaan networks  17 luxembourg altwies', 0.90247065), ('trinity engineers  28 luxembourg altwies', 'international travel house  20b maison roder', 0.90247065), ('greene 48 luxembourg altwies', 'ggsene 48 lhxembokrg altwies', 0.90247065), ('chambers 10 sources altwies', 'comed echternach', 0.90247065), ('tds lithium-ion battery  1a julien berger altwies', 'tds lithium - ion battrdy 1a julorn berger altwisd', 0.90247065), ('hall 15 julien berger altwies', 'veeba food services  156 trèves niederanven', 0.90247065), ('groupe seb  29 duerfstrooss alscheid', 'cochran 2a maxomins mzner', 0.90247065), ('mcneil 5a victor hugo altwies', 'mcneil 5a victor hugo altwies', 0.90247065), ('griffith 2 jean pierre koppes altwies', 'griffith 2 jean pierre koppes altwies', 0.90247065), ('yodlee  11 jean pierre koppes altwies', 'yolee  11 jean pierre koppes altwies', 0.90247065), ('kirby 2a jean pierre molitor altwies', 'ciel hr  8 paul reuter', 0.90247065), ('miles 1 nic greef altwies', 'miles 1 nic greef altwies', 0.90247065), ('hitachi mgrm net  1 konerhaff alscheid', 'hitachi mgrm net  1 konerhaff alscheid', 0.90247065), ('aamby valley city  5 bëchel alscheid', 'jaob 9 spackltergaass senningerberg', 0.90247065), ('young 15 aktivitéitszon allerborn', 'maxwell 10 saule ingeldorf', 0.90247065), ('carr 94 bläiminnestrooss allerborn', 'carr allerborn', 0.90247065), ('sun n sand  16 féitsch allerborn', 'sun n sand  16 féitsch allerborn', 0.90247065), ('camacho 9 vin ahn', 'camacho 9 vin ahn', 0.90247065), ('hines 6 duerefstrooss allerborn', 'hines 6 duerefstrooss allerborn', 0.90247065), ('schroeder 37 duerefstrooss allerborn', 'schroeder 37 duerefstrooss allerborn', 0.90247065), ('knox 1 leudelange', 'informatica business solutions  68a luxembourg dippach', 0.90247065), ('international travel house  6 village abweiler', 'strickland 14 om kläppchen dalheim', 0.90247065), ('dennis 19 village abweiler', 'pepsico (india) holdings  3 ierwescht duerf enscherange', 0.90247065), ('robbins 28 village abweiler', 'robfons 28 village', 0.90247065), ('stanton 35 village abweiler', 'abweiler stanton 35 village', 0.90247065), ('phenix construction technologies  6 palmberg ahn', 'russell 119 prés lamadelaine', 0.90247065), ('jhn dre  56 village abweiler', 'woods 56 pierre schiltz tétange', 0.90247065), ('vcare trichology  4b résistance ahn', 'khan 2 cimetière sandweiler', 0.90247065), ('stewart 14 résistance ahn', 'stewart 14 résistance ahn', 0.90247065), ('orozco 7 vignes ahn', 'orozco 7 vignes ahn', 0.90247065), ('emirates national oil company  2 reimergaard altrier', 'wedf 28 xuarrefstroods binsfeld', 0.90247065), ('sheppard 1 aly duhr ahn', 'sheppard 1 aly duhr ahn', 0.90247065), ('rasmussen 4 tumulus altrier', 'radmussem 4 tumjlue altrier', 0.90247065), ('graham 14 tumulus altrier', 'graham 14 tumulus altrier', 0.90247065), ('pitney bowes  15a niederdonven ahn', 'pitnrh bpqes 15a niederdonven ahn', 0.90247065), ('robinson 27 niederdonven ahn', 'fobonson 27 niecerdonfen ahn', 0.90247065), ('6sense  11 heeschbregerwee altrier', 'lyons 9 roche bertrange', 0.90247065), ('indian public school  22 kreizenheicht altrier', 'french 12 dett cchkfflange', 0.90247065), ('agilent technologies international  1 héicht altlinster', 'cermenha niofech 15 carrefours bridel', 0.90247065), ('private practice  7 schanz altrier', 'rategain  41 montagne steinheim', 0.90247065), ('blanchard 19a schanz altrier', 'blanchard 19a schanz altrier', 0.90247065), ('paytm payments bank  30 schanz altrier', 'paytm payments bank  30 schanz altrier', 0.90247065), ('agriculture altrier insurance company of india  42a schanz', 'fawaz alhokair group  36 nicolas martha luxembourg', 0.90247065), ('vcs quality services  50b schanz altrier', 'vcs quality services  50b schanz altrier', 0.90247065), ('hubbard 62 schanz altrier', 'hubbard 62 schanz altrier', 0.90247065), ('i yogi technical services  5 godbrange altlinster', 'daimler financial services  1 sophie germain esch sur alzette', 0.90247065), ('aker solutions  5 junglinster altlinster', 'alzingen newton 3 jean steichen', 0.90247065), ('axa 11 jjnglinsfer altlinatef', 'henderson 4 differdange soleuvre', 0.90247065), ('atkinson 20a jeunesse sacrifiée 1940 1945 alzingen', 'atkinson 20a jeunsqse sacrifiée 1940 1945 alzungwn', 0.90247065), ('mcfarland 38 jeunesse sacrifiée 1940 1945 alzingen', 'mcfarland 38 jeunesse aacrifoée 1940 1945 aoaingen', 0.90247065), ('kanwar enterprises  1 larochette altlinster', 'national secyuritries depoksitkory  15 lauterbann nicederkorn', 0.90247065), ('sutherland global services  4 luxembourg altlinster', 'sutherland global services  4 luxembourg altlinster', 0.90247065), (\"dr. batras' positive health clinic  4 prés altlinster\", 'zycus infotech  12 tëntenerstrooss greisch', 0.90247065), ('york 3 hondsbreck alzingen', 'york 3 hondsbreck alzingen', 0.90247065), ('garden reach shipbuilders & engineers  13 hondsbreck alzingen', 'figueroa 19 luxembourg bascharage', 0.90247065), ('intas pharmaceuticals  8 rothweit alzingen', 'fisher 19 féischterbierg bourscheid', 0.90247065), ('durham 1 aghé ewouqrd garnich alzingen', 'fpoqers 39 fontaine lliète rodange', 0.90247065), ('ingram 11 abbé edouard garnich alzingen', 'ingram 11 abbé edouard garnich alzingen', 0.90247065), ('bates 29 rothweit alzingen', 'virinchi tdcmnologies 25 den espen houtforr', 0.90247065), ('jones 3a eglise alzingen', 'jones 3a sglisr aizinben', 0.90247065), ('rowe 11 eglise alzingen', 'mendez 11 genêts', 0.90247065), ('hart 429 thionville alzingen', 'hstt 429 tjionvilie alzingen', 0.90247065), ('grand view research  475 thionville alzingen', 'grand view research  475 thionville alzingen', 0.90247065), ('piramal capital housing finance  8 hesperange alzingen', 'ojramal capital housing finance 8 hssperxnge aisingen', 0.90247065), ('erickson 22 hesperange alzingen', 'phoeix ohyct 11 mreseflasd canach', 0.90247065), ('r systems international  492 thionville alzingen', 'cnh industrial 36 domaine neauregare goebkamge', 0.90247065), ('steele 506 thionville alzingen', 'steele 506 thionville alzingen', 0.90247065), ('woowd 29 hesperange alsingwn', 'ctjz 1 mathias adam létqnge', 0.90247065), ('levy 50 hesleranbe apzlngen', 'stuart 6 henri turod rosoory', 0.90247065), ('roberson 586 thionville alzingen', 'roberson 586 thionville alzingen', 0.90247065), ('boston scientific  9 albert bousser alzingen', 'boston scientific  9 albert bousser alzingen', 0.90247065), ('collier 10 roeser alzingen', 'collier 10 roeser alzingen', 0.90247065), ('sampson 20 roeser alzingen', 'swmpzon 20 rieeer alzingen', 0.90247065), ('valencia 32 roeser alzingen', 'nryab 90 dudelange', 0.90247065), ('indusind bank  43 roeser alzingen', 'indusind bank  43 roeser alzingen', 0.90247065), ('wilkerzoj 8 jean steicteb alzingen', 'name 20 aéroport findel', 0.90247065), ('ttk healthcare  3 camping alzingen', 'dunlap 45 trévires luxembourg', 0.90247065), ('gss infotech  22 cimetière alzingen', 'walter 3a schousterwee ringel', 0.90247065), ('shepard 6a syren alzingen', 'wmitef emissikj control gschnologies 11 fer tétange', 0.90247065), ('mcpi  14 syren alzingen', 'mcpi  14 syrn alzingen', 0.90247065), ('olaig gensol utilities  23 syren alzingen', 'dish infra services  41 ada lovelace eschv sur alzette', 0.90247065), ('blue dart aviation  33 syren alzingen', 'blue dart aviation  33 syren alzingen', 0.90247065), ('medall  43 syren alzingen', 'medall 43 cyreb alzingfn', 0.90247065), ('gm modular  7 jean wolter alzingen', 'gm modular  7 jean wolter alzingen', 0.90247065), ('stephenson 17 jean wolter alzingen', 'stephenson 17 jean wolter alzingen', 0.90247065), ('gspl  15 josy haendel alzingen', 'txpl 15 joah haendel alzingen', 0.90247065), ('montes 34 josy haendel alzingen', 'montes 34 josy haendel alzingen', 0.90247065), ('swanson 18 jean wolter alzingen', 'hvintosh 400 neudorf', 0.90247065), ('kfc  13 huelgaass altwies', 'kfc  13 huelgaass altwies', 0.8924286), ('seven hills hospital  10 brem wee altwies', 'hcl infotech  2 zare ouest ehlerange', 0.8924286), ('tata institute of social sciences  9 filsdorf altwies', 'tata institute of social sciences  9 filsdorf altwies', 0.8924286), ('grupo antolin  18 filsdorf altwies', 'parrish 41 agnès donckel mertert', 0.8924286), ('guerrero 1 grand rue altwies', 'oncquest laboraflries 54 begctem howald', 0.8924286), ('pyung hwa  9 grand rue altwies', 'pyung hwa  9 grand rue altwies', 0.8924286), ('cole 5a mondorf altwies', 'airtel business  31 vergers helmsange', 0.8924286), ('nichols 12 mondorf altwies', 'nichols 12 mondorf altwies', 0.8924286), ('akbar travels  19 mondorf altwies', 'akbar travels  19 mondorf altwies', 0.8924286), ('lanco infratech  38 mondorf altwies', 'prem henna  8 helpert boevange sur attert', 0.8924286), ('itcons e - soiuhions 10 rohzins zptwies', 'olectra greentech  51 belvaux oberkorn', 0.8924286), ('tran 5 luxembourg altwies', 'tran 5 luxembourg altwies', 0.8924286), ('gillespie 13 luxembourg', 'startek  21 halanzy luxembourg', 0.8924286), ('jubilant chmsys  22 luxembourg altwies', 'tran 5 luxembourg altwies', 0.8924286), ('edwards 38 luxembourg altwies', 'wall 4b ecole koerich', 0.8924286), ('vinculum solutions  5a sources altwies', 'benon 3a besfhexhen rehlane', 0.8924286), ('avery 1 emile kohn altwies', 'avery 1 emile kohn altwies', 0.8924286), ('jnet technologies  9 julien berger', 'valentine 32 horizon itzig', 0.8924286), ('sahtaba 13 duerfwtgooss alscheid', 'rose 46 lavande luxembourg', 0.8924286), ('impelsys  1 victor hugo altwies', 'impelsys  1 victor hugo altwies', 0.8924286), ('modicare  10 victor hugo altwies', 'modicare  10 victor hugo altwies', 0.8924286), ('jacobson 7 jean pierre koppes altwies', 'mspl  21b brouch tuntange', 0.8924286), ('dougherty 19 jean pierre koppes altwies', 'ougherty 9 jean pierre kllpes qltwifs', 0.8924286), ('mccarty 4c jean pierre molitor altwies', 'mccarty 4c jean pierre molitor altwies', 0.8924286), ('colon 4 donatus alscheid', 'glorious insight  21 cimetière ellange', 0.8924286), ('mahatma gandhi medical college & hospital  4 héicht alscheid', 'mahatks gsndhk medical college & hospitsi 4 héicht alscheid', 0.8924286), ('ztt  16 bëchel alscheid', 'manry 4 pierre weydeeh fentange', 0.8924286), ('kaiser 46 bläiminnestrooss allerborn', 'kaiser 46 bpäiminnestrkoss alletbogn', 0.8924286), ('proctor 7 schoulbierg alscheid', 'proctor 7 schoulbierg alscheid', 0.8924286), ('soto 3 burren allerborn', 'soto 3 burren allerborn', 0.8924286), ('alexander 35 vin ahn', 'dickson 6 lohrwies noertzange', 0.8924286), ('benson 19 duerefstrooss allerborn', 'benson 19 duegefstroocs zllerforn', 0.8924286), ('howe 44 duerefstrooss allerborn', 'moqe 44 duerefstrooss allrrbkrn', 0.8924286), ('qcon  101 leudelange abweiler', 'qcon  101 leudelange abweiler', 0.8924286), ('leadsquared  12 village abweiler', 'montes 34 josy haendel alzingen', 0.8924286), ('szndovwl 21c viloagr abweiler', 'mcxankel 3 albert fouzser alzingen', 0.8924286), ('mcdermott international  29e village abweiler', 'mcdermott international  29e village abweiler', 0.8924286), ('penna cement industries  48a village abweiler', 'penna cement industries  48a village abweiler', 0.8924286), ('veaslej 50e vjllabe abweiler', 'empower retirement   14 wangert beidweiler', 0.8924286), ('charles 1 roses ahn', 'charles 1 roses ahn', 0.8924286), ('lawson 7 résistance ahn', 'lawson 7 résistance ahn', 0.8924286), ('mutual industries  2 vignes ahn', 'mutual industries  2 vignes ahn', 0.8924286), ('aida cruises  26 vignes ahn', 'hamma 123 echterhadh luxembourg', 0.8924286), ('parsons 2 becherwee altrier', 'parsons 2 becherweee alatrier', 0.8924286), ('marwadi shares & finance  9 aly duhr ahn', 'marwadi shares & finance  9 aly duhr ahn', 0.8924286), ('rodgers 9 tumulus altrier', 'ovgeds 9 tunupus altrer', 0.8924286), (' 6 niederdonven ahn kptcl', 'santiago 54 tulipes bascharage', 0.8924286), ('estrada 19 niederdonven ahn', 'extrzda ahn 19 niedegdinven', 0.8924286), ('teoco software  2 heeschbregerwee altrier', 'teoco software  2 heeschbregerwee altrier', 0.8924286), ('dean 10 kreizenheicht altrier', 'dean 10 kreizenheicht altrier', 0.8924286), ('matthews 5 wameschbur altrier', 'mcbride 143 victor hugo esch sur alzette', 0.8924286), ('pateson 27 rausch altrier', 'karvy figtecg 3 châyfau differdange', 0.8924286), ('manning 12 schanz altrier', 'manning 12 schanz altrier', 0.8924286), ('npvzc yechnklogy solutions 26 schanz altrier', 'kelly 9 nilcolas schmitz btissen', 0.8924286), ('macias 38 schanz altrier', 'macias 38 schanz altrier', 0.8924286), ('ayers 46 schanz altrier', 'ayers 46 schanz altrier', 0.8924286), ('marquis technologies  55 schanz altrier', 'tokai rubber auto parts india  43 pierre dupong differdange', 0.8924286), ('mashreq global services  1 godbrange altlinster', 'gennova biopharmaceuticals  42b deckt wahlhausen', 0.8924286), ('jasmin infotech  1 junglinster altlinster', 'rm education solutions  19 jean pierre michels esch sur alzette', 0.8924286), ('espinoza 7 junglinster altlinster', 'espinoza 7 junglinster altlinster', 0.8924286), ('burton 16a jeunesse sacrifiée 1940 1945 alzingen', 'burton 16a jeunesse sacrifiée 1940 1945 alzingen', 0.8924286), ('haas 28 jeunesse sacrifiée 1940 1945 alzingen', 'rkles rijys 37 mathieu luxembourg', 0.8924286), ('norman 3 weiherchen alzingeunh', 'yokohama off-highway tires  2 girsterklaus hinkel', 0.8924286), ('ewing 11 larochette altlinster', 'mullins 7 hannelaanst weiswampach', 0.8924286), ('vaibhav fiobal 7 luxembourg altllnstdr', 'ebay  35 burgknapp consdorf', 0.8924286), ('gunnebo  10 prés altlinster', 'gujneno 10 prés alyiinster', 0.8924286), ('right tight fasteners  8 hondsbreck alzingen', 'right tight fqstenere 8 hondzbrsck', 0.8924286), ('gates unitta india company  3 rothweit alzingen', 'gates unitta india company  3 rothweit alzingen', 0.8924286), ('oen india  14 rothweit alzingen', 'asiapower overseas wmplojment serdoces 160 pétange niesefkorn', 0.8924286), ('jacobs 6 abbé edouard garnich alzingen', 'jacobs 6 abbé edouard garnich alzingen', 0.8924286), ('vivo  16 abbé edouard garnich alzingen', 'parexel international  76 aubourg kayl', 0.8924286), ('little 47 rothweit alzingen', 'littl 4 rothweit alzingen', 0.8924286), ('ajax engineering  6 eglise alzingen', 'ayas engigrering 6 eglise alzingen', 0.8924286), ('holloway 423 thionville alzingen', 'holloway 423 thionville alzingen', 0.8924286), ('infineon technologies  461 thionville alzingen', 'b. p. pddar hoapxl & mdiwo rsearch 41c pixsine létznge', 0.8924286), ('l&t technology services  3 hesperange alzingen', 'l&t technology services  3 hesperange alzingen', 0.8924286), ('anna university  13 hesperange alzingen', 'anna university  13 hesperange alzingen', 0.8924286), ('twego tourism services  484a thionville alzingen', 'twego tourism services  484a thionville alzingen', 0.8924286), ('mahoney 498a thionville alzingen', 'mahoney 498a thionville alzingen', 0.8924286), ('horn 516a thionville alzingen', 'amri hospital  81 muguets luxembourg', 0.8924286), ('ruloans  40 hesperange alzingen', 'ruloans  40 hesperange alzingen', 0.8924286), ('pollard 537 thionville alzingen', 'art housing finance (india)  1 kennedy ettelbruck', 0.8924286), ('l&t power transmission & distribution  4 albert bousser alzingen', 'vish gyana technology solutions  16 golf senningerberg', 0.8924286), ('laxmi-agni components and forging  16 albert bousser alzingen', 'laxmi-agni components and forging  16 albert bousser alzingen', 0.8924286), ('welch 15 roeser alzingen', 'rdmuch ptc 36 eutopw', 0.8924286), ('vesuvius  28 roeser alzingen', 'hdfc mutual fund  9 kircherweeg hautbellain', 0.8924286), ('sterling infosystems  38 roeser alzingen', 'alvarez 21 raoul follereau strassen', 0.8924286), ('alzingen newton 3 jean steichen', 'vargas 23 wintrange elvange', 0.8924286), ('idia  10 jean steichen alzingen', 'mkdrow 7 maes giqtingen', 0.8924286), ('avontix  5 cimetière alzingen', 'avontix 5 cinefière slxingen', 0.8924286), ('athena bpo  4 syren alzingen', 'athena bpo 4 xgren alzjngsn', 0.8924286), ('dbs bank  8 syren alzingen', 'dbs bank  8 syren alzingen', 0.8924286), ('absolute barbecues  19 syren alzingen', '30 fischbach blaschette', 0.8924286), ('ruiz 29a syren alzingen', 'tuia 29a eyeen alzingen', 0.8924286), ('carroll 38 syren alzingen', 'carroll 38 syren alzingen', 0.8924286), ('george 2 jean wolter alzingen', 'george 2 jean wolter alzingen', 0.8924286), ('flynn 12 jean wolter alzingen', 'flynn 12 jean wolter alzingen', 0.8924286), ('diacritech  8 josy haendel alzingen', 'artson engineering  13 bellevue mamer', 0.8924286), ('shara hospital  22 josy haedel alzingen', 'elcamino software  15 tpierre mansfelud luxemvbourg', 0.8924286), ('livingston 9 jos paquet alzingen', 'livingston 9 jos paquet alzingen', 0.8924286), ('fiexsim technologies 6 brem wee xltwiec', 'schwartz 111 krunn echternach', 0.86052626), ('case 6 filsdorf altwies', 'bhqrag hotels 34 gordon smith ciimar hwrg', 0.86052626), ('west 15 filsdorf altwies', 'e-zest  16 marie thérèse luxembourg', 0.86052626), ('shaffer altwies', 'adyar anhanda bhhavan swezets  17 burgrebierg niederwampach', 0.86052626), ('yupzptv  5 grand rcue', 'hpl riectric & oiwer 32 rochrrd wiltz', 0.86052626), ('christian 15 grand rue altwies', 'chrtian 15 grand rue altwies', 0.86052626), ('continental  9 mondorf altwies', 'phi seeds  20 cimetière esch sur alzette', 0.86052626), ('mills 17 mondorf altwies', 'mills 17 mondorf altwies', 0.86052626), ('crimson interactive  30 mondorf altwies', 'valentine 5 clplp rpdabge', 0.86052626), ('stevens 2 romains altwies', 'stevens 2 romains altwies', 0.86052626), ('suyuba poultry farm 61 romains sitwies', 'minda corporation  7 hesselter godbrange', 0.86052626), ('amway india enterprises  10 luxembourg altwies', 'amwzt khdia enterprises 10 luxembourg altwies', 0.86052626), ('h-one india  18 luxembourg altwies', 'h-one india  18 luxembourg altwies', 0.86052626), ('mayo 30 luxembourg altwies', 'mayo 30 luxembourg altwies', 0.86052626), ('enova facilities management llc  1a sources altwies', 'enova facilities magagehent llc 1a skurcew altwked', 0.86052626), ('american oncology institute  12 sources altwies', 'american oncology institute  12 sources altwies', 0.86052626), ('hull 1 julien berger altwies', 'hull 1 julien berger altwies', 0.86052626), ('advanced technology consulting service  19 julien berger altwies', 'advanced technology consulting servucs 19 huoien berger alfwjes', 0.86052626), ('unique pharmaceutical laboratories  31 duerfstrooss alscheid', 'unique pharmaceutical labgoratories g 3s1 duerfstroosts alscheid', 0.86052626), ('vedanta resources  5 victor hugo altwies', 'vedanta xotwies resiirces 5 victor hugo', 0.86052626), ('radisson hotels  3 jean pierre koppes altwies', 'rdisson hotes  3 jean pierre koppes altwies', 0.86052626), ('jeena sikho lifecare  13a jean pierre koppes altwies', 'doyle 275 val croix luxembourg', 0.86052626), ('henson 2 jean pierre molitor altwies', 'tensoh 2 jean pieerw molitor altwies', 0.86052626), ('great white global  2 nic greef altwies', 'russo 14a fer kleinbettingen', 0.86052626), ('alscheid ych logistics  2 konerhaff', 'mullins 7 hannelaanst weiswampach', 0.86052626), ('morales 7 bëdhfl alsshrid', 'ivl dhunseri petrochem industries  30 principale neuhaeusgen', 0.86052626), ('kider india  6 bläiminnestrooss allerborn', 'torres 66 cegnier sol luxemhougg', 0.86052626), ('auraine botanicals  95 bläiminnestrooss allerborn', 'slhimx wotldbia 13 marguerites strassen', 0.86052626), ('dharampal premchand  20 féitsch allerborn', 'premchand  20 féitsch dharapal allerorn', 0.86052626), ('presidium school  11 vin ahn', 'presidium school  11 vin ahn', 0.86052626), ('iplaceusa  10 duerefstrooss allerborn', 'iplqcehsa 10c duerefstrooss sylledborn', 0.86052626), ('gozocabs  2 leudelange abweiler', 'mirafra technologies  25 maison hoesdorf', 0.86052626), ('verifacts services  7 village abweiler', 'verifacts services  7 village abweiler', 0.86052626), ('nash 20a village abweiler', 'gamble 13 grève strassen', 0.86052626), ('apl apollo tubes   29a village abweiler', 'lambert 17 fontaine canach', 0.86052626), ('amoda group of industrlfs 36 viklane abdsiler', 'wheeler 119 soleuvre', 0.86052626), ('vishay precision transducers  8 palmberg ahn', 'vishay precision transducers  8 palmberg ahn', 0.86052626), ('guzman 58 village abweiler', 'bharatmatrimony.com  19 jérôm busleyden boulaide', 0.86052626), ('peterson 4 résistance ahn', 'peterson 4 résistance ahn', 0.86052626), ('codincity digital technologies  15 résistance ahn', 'eschweiler shepherd 22 kräiz', 0.86052626), ('travelex  8 vignes ahn', 'trsvelsx 8 virned ahn', 0.86052626), ('floating numbers digital solutions  3 reimergaard altrier', 'floating numbers digital solutions  3 reimergaard altrier', 0.86052626), ('ruz 2 aly dkgr ahn', 'itl industries  104 kennedy esch sur alzette', 0.86052626), ('man infraconstruction  5 tumulus altrier', 'man infraconstruction  5 tumulus altrier', 0.86052626), ('bolton 16 tumulus altrier', 'bolton 16 tumulus altrier', 0.86052626), ('downs 15 niederdonven ahn', 'downs 15 niederdonven ahn', 0.86052626), ('mfx 34 hicsderidonven ahn', 'bender 5 killeboesch schengen', 0.86052626), ('soda 2 kreizenheicht alfrirr', 'ict sms  13 castel niederkorn', 0.86052626), ('garza 24 kreizenheicht altrier', 'garza 24 kreizenheicht altrier', 0.86052626), ('essar steel  3 héicht altlinster', 'suarez 6 helen buchholtz strassen', 0.86052626), ('krueger 9a schanz altrier', 'trevino 2 tbriddelsknupp bridel', 0.86052626), ('villanueva 19 schanz altrier', 'bender 10 zac klengbousbierg bissen', 0.86052626), ('randolph 32 schanz altrier', 'health total   17 victor ewen esch sur alzette', 0.86052626), ('mas financial services   42 schanz altrier', 'altrier mas financial services   42 schanz', 0.86052626), ('zamora 50 schanz altrier', 'pont 12 eechternacherstrooss wallendorf atkins', 0.86052626), ('goodman 68 schanz altrier', 'goodman 68 schanz altrier', 0.86052626), ('a. menarini india  1a junglinster altlinster', 'costa coffee  25 oetrange schrassig', 0.86052626), ('carlson 6a junglinster altlinster', 'carlson 6a junglinster altlinster', 0.86052626), ('austin 12 junglinster altlinster', 'allianz technology  26 neuve wiltz', 0.86052626), ('williamson 20 jeunesse sacrifiée 1940 1945 alzingen', 'visyer 41 neuve péhahge', 0.86052626), ('owens 40 jeunesse sacrifiée 1940 1945 alzingen', 'origofinance  13 huserknapp heinerscheid', 0.86052626), ('mahendra nextwealth  3 larochette altlinster', 'bp ifrastructure  2b nospelt goeblange', 0.86052626), ('fisher 5 prés altlinster', 'zuti engineering soluhiond 13 ëlwenteestrooxs', 0.86052626), ('branch 4 hondsbreck alzingen', 'brady 81 noertzange', 0.86052626), ('grant 14 hondsbreck alzingen', 'cabrera 5 xrkistice helmswnhe', 0.86052626), ('jlhj cockeeipl 9 rothweit alzingen', 'cisnerld 3 deickwr sandweiler', 0.86052626), ('bangalore international airport  2 abbé edouard garnich alzingen', 'bajgalire international airpoeh 2 abbé edouard garbidh alzingen', 0.86052626), ('ray 12 abbé edouard garnich alzingen', 'ray 12 abné edouard garnich alziggej', 0.86052626), ('lanarsy infra  31 rothweit alzingen', 'broadband services  21 bourschterbach warken', 0.86052626), ('kelly 3 eglse alzingen', 'helloverify  57 duerfstrooss dahl', 0.86052626), ('glenn 12 eglise alzingen', 'idbi intech  55 tony bourg strooss weicherdange', 0.86052626), (\"moody's analytics  431 thionville alzingen\", 'crawford 9 roger schmitz bofferdange', 0.86052626), ('fuentes 477 thionville alzingen', 'fuentes 477 thionville alzingen', 0.86052626), ('kerr 9 hesperange alzingen', 'kerr 9 hesperange alzingen', 0.86052626), ('simplex infrastructures  481 thionville alzingen', 'nelson 18 bannent dudelange', 0.86052626), ('acevedo 494 thionville alzingen', 'acevedo 494 thionville alzingen', 0.86052626), ('cantrell 508 thionville alzingen', 'burk 32 mondor altwies', 0.86052626), ('30 hesperange alzingen', 'army ordnance corps  12 paul eyschen bettembourg', 0.86052626), ('otctid hotfk 520 thionville alzingen', 'ia motor works  38 hôpital echternach', 0.86052626), ('hutchinson 1 albert bousser alzingen', '5 jean jaurès dudelange proctor', 0.86052626), ('fibcom india  10 albert bousser alzingen', 'fibcom india  10 albert bousser alzingen', 0.86052626), ('morrison 11 roeser alzingen', 'mindtree solutions  51 bettembourg fentange', 0.86052626), ('olson 21 roeser alzingen', 'oksom 21 roeser xlzijgen', 0.86052626), ('the claridges hotel  33 roeser alzingen', 'the claridges hotel  33 roeser alzingen', 0.86052626), ('drake 44 roeser alzingen', 'daniels 44 etang dudelange', 0.86052626), ('ht media  9a jean steichen alzingen', 'srf  11 jean fischbach leudelange', 0.86052626), ('maynard 1 cimetière alzingen', 'maynard 1 cjmetiège alzinbdn', 0.86052626), ('jaipur vidyut vitran nigam  23 cimetière alzingen', 'yaopur bifyut vitdaj nigam 23 cimetière alzingen', 0.86052626), ('shelton 6b syren alzingen', 'shelton 6b sjreb alzibgsn', 0.86052626), ('kusif broadcast 15 syren alzinhfn', 'medibuddy 34 comjfrce jxmer', 0.86052626), ('dalmia bharat group  24 syren alzingen', 'dalmia bharat group  24 syren alzingen', 0.86052626), ('sawyer 34 syren alzingen', 'banla 3 kiemel mlndfrcange', 0.86052626), ('arkad enguneerihg and comsttuction co. 44 syren apzingsn', 'roth 108 paerchen schifflange', 0.86052626), ('odisha power gfheration corpieation 1 josy haendel slzingdn', 'qatar airways  10 rinnheck schandel', 0.86052626), ('energy efficiency services  16 josy haendel alzingen', 'energy efficiency services  16 josy haendel alzingen', 0.86052626), ('raymind 1 jos paqirt alzingen', 'galax e solutions  6 père conrad howald', 0.86052626), ('prince 19 jean wolter alzingen', 'cobday 2a schmitz kopdtal', 0.86052626), ('ritu kumar  38 duerefstrooss allerborn', 'montoya 1 pommiers lorentzweiler', 0.8605262), ('imimobile  5a luxembourg altlinster', 'technosoft global services  22 paul binsfeld bridel', 0.8605262), ('palmer 8 jean wolter alzingen', 'jltchens 55 den jenken regalo péganre', 0.8605262), ('savage 11 huelgaass altwies', 'savage 11 huelgaass altwies', 0.81639403), ('astkma group 9 brem wee sotwies', 'simpson 198v pierre fanaen niederkorn', 0.81639403), ('andrews 9a filsdorf altwies', 'vijaya diagnostic centre  173 kayl dudelange', 0.81639403), ('salazar 18a filsdorf altwies', 'gujarat gas  9 poste grevenmacher', 0.81639403), ('innovative  5 eglise altwies', 'sawyer 4 pierre braun hagen', 0.81639403), ('pearson 8 grand rue altwies', 'bfakn 70 kockelscheuer bigangf', 0.81639403), ('galgotias university  4 mondorf altwies', 'l and t chiyoda  4 wald boevange sur attert', 0.81639403), ('inamdar multispeciality hospital  12a mondorf altwies', 'brooks 46 colmar berg mertzig', 0.81639403), ('miraj group  19 grand rue altwies', 'miraj group  19 grand rue altwies', 0.81639403), ('wiggins 36 momdorr', 'canvera  2a source syren', 0.81639403), ('7 romains pitts altwies', 'desein  6 jean pierre urwald grevenmacher', 0.81639403), ('pfide 4 luxembokeg altwies', 'bravura solutions  1 om buren hupperdange', 0.81639403), ('wang 12 luxembourg altwies', 'wang 12 luxembourg altwies', 0.81639403), ('zensar technologies  21 luxembourg altwies', 'zensar tedhnologiea 21 luxrmbourf altwies', 0.81639403), ('sanford 36 luxembourg altwies', 'savhnford 36 luxembourg altwies', 0.81639403), ('syrma technology  4 sources altwies', 'qdigi services  58 fort neipperg luxembourg', 0.81639403), ('ortega 23 eoutces alfwieq', 'angelique international  59 principale lasauvage', 0.81639403), ('bennett 7 julien berger altwies', 'freeman 11 françois baclesse bettembourg', 0.81639403), ('watts 10 duerfstrooss alscheid', 'watts 10 duerfstrooss alscheid', 0.81639403), ('guidehouse  37 duerfstrooss alscheid', 'guidehouse  37 duerfstrooss alscheid', 0.81639403), ('applus velosi  8 victor hugo altwies', 'applus velosi  8 victor hugo altwies', 0.81639403), ('daniels 6 jean lirrre koppes altairs', 'gordon 20 michel junckel kayl', 0.81639403), ('foetez 17 ieaj pierre koppes altwies', 'gujarat guardian ltd.  49a longwy niederkorn', 0.81639403), ('sipl  4b jean pierre molitor altwies', 'sipl  4b jean pierre molitor altwies', 0.81639403), ('development  2 donatus alscheid labcorp', 'cambridge university press  2 prince charles colmar berg', 0.81639403), ('bruce 2 héicht alscheid', 'astral adhesives  8 baerendall mamer', 0.81639403), ('walton 11 bëchel alscheid', 'gis 14 jen cchahs zandweilwr', 0.81639403), ('landmark group  44 bläiminnestrooss allerborn', 'landmark group  44 bläiminnestrooss allerborn', 0.81639403), ('sns college of engineering  6 schoulbierg alscheid', 'eros group  233 romains bertrange', 0.81639403), ('cargill  4 ruisseau ahn', 'cargill  4 ruisseau ahn', 0.81639403), ('cajpoc 29 vin ahn', 'th hershey cmany  6 hoenerwee hellange', 0.81639403), ('letstransport  18 duerefstrooss allerborn', 'letstransport  18 duerefstrooss allerborn', 0.81639403), ('gupta exim  43 duerefstrooss allerborn', 'gupta exim  43 duerefstrooss allerborn', 0.81639403), ('brandt 6 leudelange abweiler', 'randt 6 leudelange abweiler', 0.81639403), ('herman 11 village abweiler', 'uwrman 11 village abseller', 0.81639403), ('21b village abweiler hunter', 'clarke 56 pommiers luxembourg', 0.81639403), ('ylungahin automotive 29d villagr abweiler', 'kotak mahindra prime  55 ditzebierg niederpallen', 0.81639403), ('ajnara india  44 village abweiler', 'ajnara india  44 village abweiler', 0.81639403), ('novak 50d village abweiler', 'novak 50d village abweiler', 0.81639403), ('petronet lng  70 village abweiler', 'petronet lng  70 village abweiler', 0.81639403), ('rimini street  6 résistance ahn', 'rimonu syteet 6 résistance ahn', 0.81639403), ('cbsl  1 vignes ahn', 'surat municipal corporation  55 commerce dudelange', 0.81639403), ('air force school  24 vignes ahn', 'forbes technosys  5a dielchen hassel', 0.81639403), ('cuevas 7 reimergaard altrier', 'cuevas 7 reimergaard altrier', 0.81639403), ('buck 8 aly duhr ahn', 'vartkett 14 sterlenuch kleinbettingen', 0.81639403), ('weaverbird engineering technology  8 tumulus altrier', 'graves 52 fer dudelange', 0.81639403), ('dickson 5 niederdonven ahn', 'bruce 48 principale grevels', 0.81639403), ('gsrtc  19a niederdonven ahn', 'axis dirct  3 hiehl bettange sr mess', 0.81639403), ('nayara energy  1 heeschbregerwee altrier', 'alyroer nayxrq energyg 1 heeschbregeprweue', 0.81639403), ('midland microfin  8 kreizenheicht altrier', 'midland microfin  8 kreizenheicht altrier', 0.81639403), ('vibes healthcare  3 wameschbur altrier', 'mobicu technologies  4 piere conrardy helmsange', 0.81639403), ('lara 10 rausch altrier', 'lara 10 rausch altrier', 0.81639403), ('sifars  11 schanz altrier', 'sifars  11 schanz altrier', 0.81639403), ('walsh 25 schanz altrier', 'vance 7 jean pierre michels esch sur alzette', 0.81639403), ('ayala 36 schanz altrier', 'ayala 36 schanz altrier', 0.81639403), ('\\tcollins aerospace  45 schanz altrier', '\\tcollins aerospace  45 schanz altrier', 0.81639403), ('cajj 54 schanz zltruer', 'greene 25 champs kehlen', 0.81639403), ('aarti drugs  9 bourglinster altlinster', 'aarti drugs  9 bourglinster altlinster', 0.81639403), ('banks 1d junglinster altlinster', 'banks 1d junglinster altlinster', 0.81639403), ('medreich  7a junglinster altlinster', 'medreich  7a junglinster altlinster', 0.81639403), ('altlinster  18 junglinster mpokket', 'norton 4 ienbedy sfeunsel', 0.81639403), ('anz support services  26 jeunesse sacrifiée 1940 1945 alzingen', 'zudio   29 longwy sprinkange', 0.81639403), ('nielsen 2 weiherchen alzingen', 'usha fjrs swfett equipments 1 septembre schoereb', 0.81639403), ('vasavadatta cement  9 larchette altlinster', 'wellness forever medicare 25 kilieboesdh dchengwn', 0.81639403), ('fox 6 luxembourg altlinster', 'braun 11 prunelles schuttrange', 0.81639403), ('cxc infotech  9 prés altlinster', 'cowxj 106 birangr dudelange', 0.81639403), ('green alzijngeun 7 hondsbreck', 'transoafency niederpzlpen', 0.81639403), ('mlekn 2 rofhwejt alzingen', 'dunnungham 156 iixembourg bofferdange', 0.81639403), ('floyd 12 rothweit alzingen', 'instarem   2b dall tandel', 0.81639403), ('pineda 5 abbé edouard garnich alzingen', 'pineda 5 abbé edouard garnich alzingen', 0.81639403), ('pugh 15 abbé edouard garnich alzingen', 'pugh 15 abbé edouard garnich alzingen', 0.81639403), ('freeman 45 rothweit alzingen', 'autohangar  8 im grund roodt sur syre', 0.81639403), ('tenpath  5 eglise alzingen', 'interglobe air transport 74 pakc cudelanbe', 0.81639403), ('russo 17 eglise alzingen', 'russo 17 eglise alzingen', 0.81639403), ('nihilent  437 thionville alzingen', 'clark 19 champs dsfh suryi ualxstte', 0.81639403), ('wrigiej 2 hesperangge alzinhfn', 'haynes 2 wandbierg osweiler', 0.81639403), ('kelley 12 hesperange alzingen', 'kelley 12 hesperange alzingen', 0.81639403), ('jana small finance bank  483 thionville alzingen', 'jana small finance bank  483 thionville alzingen', 0.81639403), ('roberts 496 thionville alzingen', 'roberts 496 thionviklr alzjngsn', 0.81639403), ('indianmoney.com  514 thionville alzingen', 'navarro 8 neuve perlé', 0.81639403), ('m g contractors  38 hesperange alzingen', 'rigrr dngineeting 17 lucien wercollier dudelange', 0.81639403), ('chan 535 thionville alzingen', 'chan 535 thionville alzingen', 0.81639403), ('mcdaniel 3 albert bousser alzingen', 'mcxankel 3 albert fouzser alzingen', 0.81639403), ('qspiders  14 albert bousser alzingen', 'qspiddds 14 albert bousser apzibgen', 0.81639403), ('mmahle behzr india  14 roeser alqzingen', 'flrtihs tecbmologies 22 franciscaines luxembourg', 0.81639403), ('malone 27 rpezer', 'hhamg 7 fdoles pétange', 0.81639403), ('stein 38a roeser alzingen', 'stein 38a roeser alzingen', 0.81639403), ('levine 2 jean steichen alzingen', 'levine 2 jean steichen alzingen', 0.81639403), ('visteon  10b jean steichen alzingen', 'phonepe  484 longwy luxembourg', 0.81639403), ('holder 4 cimetière alzingen', 'holder 4 cimetière', 0.81639403), ('covereugn pharma 2 syren qlaingen', 'the rajci cemejgs 29 eschdorf esxb sur sûre', 0.81639403), ('blue mount  7 syren alzingen', 'blue mount  7 syren alzingen', 0.81639403), ('mercer 18 syren alzingen', 'mercer 18 syren alzingen', 0.81639403), ('comvision  28 syren alzingen', 'sigma infosolutions  54 luxembourg contern', 0.81639403), ('sa powerinfra  37 syren alzingen', 'varroc grjoup  6 knupp bettel', 0.81639403), ('hensley 1 jean wolter alzingen', 'hensley 1 jean wolter alzingen', 0.81639403), ('dainik alzingen', 'dynacons systems & solutions  1 misärshaff arsdorf', 0.81639403), ('enkei wheels india  6 josy haendel alzingen', 'singleton 10 schuttrange canach', 0.81639403), ('michael alzingen', 'kellogg  5 briëll doennange', 0.81639403), ('dodsal engineering & construction  7 jos paquet alzingen', 'expedia  16 principale sandweiler', 0.81639403), ('marvel realtors  1 huelgaass altwies', 'bilt  5 bois steinsel', 0.7667823), ('faces cosmetics  8 brem wee altwies', 'aces altwies cosmetics  8 brem kleinbettingen', 0.7667823), ('reed 8 filsdorf altwies', 'sruight 61b noermtrange qiktz', 0.7667823), ('sexton 17 filsdorf altwies', 'purnartha investment advisors  6 michel rodange dudelange', 0.7667823), ('eid parry (india)  3 eglise altwies', 'tstbook.om  42 mondercange ehlerangoe', 0.7667823), ('hanna 7 grand rue altwies', 'diagno lxhs 7 berelerwee bsvibne', 0.7667823), ('yoder 2 mondorf altwies', 'tate 2 fail niederfeulen', 0.7667823), ('salas 10 mohforf alhaies', 'ifb agro industries  13 wurth paquet luxembourg', 0.7667823), ('aditya birla fashion and retail  17 grand rue altwies', 'aditya birla fashion and retail  17 grand rue ettelbruck', 0.7667823), ('sgstfms 34 konvorf altwies aspire', 'banks 47 charlotte differdange', 0.7667823), ('dunn 5 romains altwies', 'dunn 5 romains stegen', 0.7667823), ('blair 3 luxembourg altwies', 'dlsrion tfchnilogies 11 munsterbusch senningerberg', 0.7667823), ('hartman 12a luxembourg altwies', 'hartman 12a luxembourg frisange', 0.7667823), ('wilcox 20 luxembourg altwies', 'classic cashiom aopxrel industry ltd co 4 vilgnes grevenmacher', 0.7667823), ('kyb motorcycle suspension  34 luxembourg altwies', 'altwies motorcycle suspension  34 luxembourg schifflange', 0.7667823), ('trevino 2 sources altwies', 'pontokx aerotech 47 jardins cqnacj', 0.7667823), ('future generali india life insurance  14 sources altwies', 'aibir indutries  43 ster fentange', 0.7667823), ('apc by schneider electric  5 julien berger altwies', 'apc by schneider electric  5 julien berger luxembourg', 0.7667823), ('via.com  5 duerfstrooss alscheid', 'via.com  5 duerfstrooss burmerange', 0.7667823), ('daniel 35 duerfstrooss alscheid', 'cochran 5 principale sandweiler', 0.7667823), ('globalhunt   9 victor hugo altwies', 'stephenson 64 marie adélaide luxembourg', 0.7667823), ('roth 5 jean pierre koppes altwies', 'hancock 22 carrefours bridel', 0.7667823), ('emmbi industries  15 jean pierre koppes altwies', 'emmbi industries 15 nfan pierre kipoes tétange', 0.7667823), ('presidency school  4a jean pierre molitor altwies', 'presidency school  4a jean pierre molitor strassen', 0.7667823), ('spice money  11 nic greef altwies', 'philips  4 raedelsbesch bergem', 0.7667823), ('archer 1 héicht alscheid', 'agcner 1 héicht schrondweiler', 0.7667823), ('fernandez 10 bëchel alscheid', 'neugene international  11 neiduerf esch sur alzette', 0.7667823), ('& jony  42 bläiminnestrooss gini allerborn', 'jimes 1 pkerge dupong soleuvre', 0.7667823), ('stephens 4 schoulbierg alscheid', 'f1 info solutions services  45 village brouch', 0.7667823), ('mccann 2 ruisseau ahn', 'waters 53 kockelscheuer bivange', 0.7667823), ('carney 42 duerefstrooss allerborn', '42 duerefstrooss carney kehlen', 0.7667823), ('mcintyre 4 leudelange abweiler', 'mcintyre 4 leudelange nobressart', 0.7667823), ('shyam metalics and energy  10 village abweiler', 'ehuam metalics and snerfy 10 viliage grevenmacher', 0.7667823), ('haley 21a village abweiler', 'haley 21a vilpagf luxembourg', 0.7667823), ('carillion alawi llc  29c village abweiler', 'gutierrez 12 echternach wasserbillig', 0.7667823), ('jabil circuiat india  40 villagen abweiler', 'name 7 schmattegaass erpeldange', 0.7667823), ('foster 50c village abweiler', 'foster 50c village dudelange', 0.7667823), ('thornton 68 village abweiler', 'phillips carbon black  13 frédéric joliot curie esch sur alzette', 0.7667823), ('rosales 5 résistance ahn', 'templeton investments 1 rehicg ersannr', 0.7667823), ('rockwell industries  35 résistance ahn', 'burnett 50 gendarmerie rodange', 0.7667823), ('townsend 22 vignes ahn', 'infra.market  2g wantergaass medernach', 0.7667823), ('godrej group  5 reimergaard altrier', 'meadows 66a hollerich luxembourg', 0.7667823), ('weber 6 aly duhr ahn', 'ahn weber 6 aly bereldange', 0.7667823), ('modern altrier', 'garrett 30 château eepeldwnge sur sûer', 0.7667823), ('callahan 4 niederdonven ahn', 'weaver luxembourg', 0.7667823), ('avendata gmbh  18 niederdonven ahn', 'mega rubber technologies  185a cessange luxembourg', 0.7667823), ('cmc limited, a tata enterprise  46 niederdonven ahn', 'cmc limited, a tata enterprise  46 niederdonven septfontaines', 0.7667823), ('short 6 kreizenheicht altrier', 'aristocrat technologies  10 mersch angelsberg', 0.7667823), ('metro global business services  1 wameschbur altrier', 'metro gkkbal busjjess services 1 wameschbur luxembourg', 0.7667823), ('richmond 8 rausch altrier', 'richmond 8 rausch sandweiler', 0.7667823), ('clements 10 schanz altrier', 'clements 10 schanz soleuvre', 0.7667823), ('ig petrochemicals  21 schanz altrier', 'terminal technologies (i)  3 bockelsgründchen dellen', 0.7667823), ('hombale constructions and estates  34 schanz altrier', 'hombale goeblange', 0.7667823), ('dusters total aolutuons serficds 44 schanz slttier', 'weaver 10 waasserkierten aspelt', 0.7667823), ('huron consulting group  53 schanz altrier', 'huron consulting group  53 schanz fentange', 0.7667823), ('petersen 7 bourglinster altlinster', 'dr lal pathlabs  28 mersch', 0.7667823), ('colorbar cosmetics  1c junglinster altlinster', 'gpma multinational solutions 2 montagne crxuthdm', 0.7667823), ('bellfast management  6 junglinster altlinster', 'oneill 12 dante luxembourg', 0.7667823), ('hancock 16 junglinster altlinster', 'hancock 16 junglinster luxembourg', 0.7667823), ('shree maruti courier service  22 jeunesse sacrifiée 1940 1945 alzingen', 'shree maruti courier service  22 jeunesse sacrifiée 1940 1945 martelange', 0.7667823), ('orr 5 luxembourg altlinster', 'orr 5 luxembourg bridel', 0.7667823), ('truetech solutions  8 prés altlinster', 'classcanyon  18 kettenbach sandweiler', 0.7667823), ('gentry 6 hondsbreck alzingen', 'teleindia networks  guillaume kroll luxembourg', 0.7667823), ('ascendum kps 1 rothwriy akzinnen', 'brouch kennedy 2 maandelbaach', 0.7667823), ('viraaj ventures  11 rothweit alzingen', 'calhoun 160 mondercange esch sur alzette', 0.7667823), ('aguirre 4 abbé edouard garnich alzingen', 'aguirre 4 abbé edouard garnich leudelange', 0.7667823), ('kiran udyog auto industries\\t  14 abbé edouard garnich alzingen', 'alzingen kiran udyog auto industries\\t  14 abbé edouard luxembourg', 0.7667823), ('wise 43 rothweit alzingen', 'rede 23 bettembourg bibwnge', 0.7667823), ('itsource technologies  5a eglise alzingen', 'ktsourcd technologies 5a fnlise wilwerwiltz', 0.7667823), ('abbott 15 eglise alzingen', 'abbott 15 eglise luxembourg', 0.7667823), ('davila 435 thionville alzingen', 'davila 435 thionville findel', 0.7667823), ('hansa research group  1 hesperange alzingen', 'hansa research group  1 hesperange mensdorf', 0.7667823), ('ruparel realty  11 hesperange alzingen', 'laeblanc 13 ketty thultl moutfort', 0.7667823), ('petus technlogies  82 thionville alzingen', 'raymond 27a nord bissen', 0.7667823), ('valenzuela 496b thopnville alzigten', 'vgxn technologies 21 mamer bettrajge', 0.7667823), ('ima-pg  512 thionville alzingen', 'ima-pg  512 thionville hovelange', 0.7667823), ('good 36 hesperange alzingen', 'good 36 hespegqnge differdange', 0.7667823), ('wilo mather and platt pumps  533 thionville alzingen', 'wilo mather and platt pumps  533 thionville kautenbach', 0.7667823), ('roasb 2 albert bouqwer alzingen', 'indiabulls pharmaceuticals  8 genêt wiltz', 0.7667823), ('pace 12 albert bousser alzingen', 'phac 12 aflbert bouser fentange', 0.7667823), ('schaefer 13 roeser alzingen', 'schaefer 13 roeser bertrange', 0.7667823), ('doyle 25 roeser alzingen', 'doyle 25 roeser kehlen', 0.7667823), ('abp group  37 roeser alzingen', 'kraft heinz company  w2a elick bettendorf', 0.7667823), ('gallegos 47 roeser alzingen', 'gallegos 47 roeser luxembourg', 0.7667823), ('vrc constructions india  10a jean steichen alzingen', 'vrc constructions india  10a jean steichen ettelbruck', 0.7667823), ('dlf home developers  3 cimetière alzingen', 'home developers  3 cimetière sprinkange', 0.7667823), ('mswipe technologies  25 cimetière alzingen', 'shyam indus power solutions  26 maison givenich', 0.7667823), ('ellis 6 syren alzingen', 'fabindia  52 luxembourg wasserbillig', 0.7667823), ('mahesh tutorials  17 syren alzingen', 'underwood 38 dalscheidt oberkorn', 0.7667823), ('shah 27 strwn alxingeg', 'mazars  47 champs belvaux', 0.7667823), ('u k paints  10 jean wolter alzingen', 'blanchard 38 pkrincle jeran pétange', 0.7667823), ('volkswagen  4 josy haendel alzingen', ' 4 josy haendel soleuvre', 0.7667823), ('sterlite industries  18 josy haendel alzingen', 'sterlite industries  18 josy haendel rodange', 0.7667823), ('sankara nethralaya  5 jos paquet alzingen', 'sankara nethralaya  5 jos paquet bissen', 0.7667823), ('fuller 27 vin ahn', 'fuller 27 vin bergem', 0.76678216), ('taylor 16 duerefstrooss allerborn', 'taylort 16 ruenrefstrooss differdange', 0.76678216), ('boysf 1 weibercyen alzingen', 'pristyn care  1 mines rumelange', 0.76678216), ('cunningham 7 larochette altlinster', 'cunningham 7 larochette dudelange', 0.76678216), ('stone 36 syren alzingen', 'stone 36 syren bertrange', 0.76678216), ('todd 100 syren alzingen', 'todd 100 syren bascharage', 0.76678216), ('techolution  7 brem wee altwies', 'tils 7a gramd rue eischen', 0.7056765), ('elite powertech  7 filsdorf altwies', 'elite powertech  7 filsdorf altwies', 0.7056765), ('blue tokai coffee roasters  16 filsdorf altwies', 'blue tokai coffee roasters  16 filsdorf altwies', 0.7056765), ('central coalfields  2 eglise altwies', 'centracl coalfields  2 eglwise altwies', 0.7056765), ('gouzl & co. 6 grahf rue altwueq', 'fryan 4 eglise flschbwch', 0.7056765), ('roy 16 grand rue altwies', 'roy 16 grand rue altwies', 0.7056765), ('carrillo 10a mondorf altwies', 'joyce 211 luxembourg bertrange', 0.7056765), ('bdo 18 mondlrd zltwiew', 'roman 1b belle vue', 0.7056765), ('burk 32 mondor altwies', 'case 3 den gehren lamadelaine', 0.7056765), ('harper 3 romains altwies', 'efs facilities services  17 reisdorf beaufort', 0.7056765), ('nixon 1 luxembourg altwies', 'presidium school  98 europe pontpierre', 0.7056765), ('mcgee 11 luxembourg altwies', 'phoypn interactive 8 xobe artisanapr et commerciale ettelbruck', 0.7056765), ('avila 19 luxembourg altwies', 'avila 19 lusehbourg alteids', 0.7056765), ('li 32 luxembourg altwies', 'li 32 luxembourg altwies', 0.7056765), ('dr. ram manohar lohia hospital  1 sources altwies', 'uti mutual fund  11 ëlwenterstrooss binsfeld', 0.7056765), ('yusen logistics  13 sources altwies', 'yusen logistics  13 sources altwies', 0.7056765), ('i-exceed technology solutions  3 julien berger altwies', 'ali 10 chapelle wiltz', 0.7056765), ('jas 21 juien berger altwies', 'maharashtra state electricity transmission company  23 noertzange', 0.7056765), ('james 33 duerfstrooss alscheid', 'james 33 duerfstrooss alscheid', 0.7056765), ('schwartz 6 victor hugo altwies', 'metric stream infotech  5 sëllerstrooss kapweiler', 0.7056765), ('kurag fkrekgn trade 4 jean pjetre koppes altwies', 'ars traffic and translott technology 21 huwl sandwekleg', 0.7056765), ('osp labs  13 jean pierre koppes altwies', 'osp labs  13 jean pierre koppes', 0.7056765), ('jl morison india  3 jean pierre molitor altwies', 'mcclain 10 ligures luxembourg', 0.7056765), ('diaz 3 nic greef altwies', 'tata international  28 françois julien vannérus diekirch', 0.7056765), ('brennan 3 konerhaff alscheid', 'brennan 3 konerhaff alscheid', 0.7056765), ('costa 9 bëchel alscheid', 'costa 9 bëchel alscheid', 0.7056765), ('eclp rapiscan 14 bläimingestroosw allerborn', 'i process services  198 principale munsbach', 0.7056765), ('planetcast  2 schoulbierg alscheid', 'gobpe 7 eugène mousset sscn sur alzdttr', 0.7056765), ('drivulis irrigation  22 féitsch allesrborn', 'ecops globale international gkrps sfbool 13b eck heiderscheid', 0.7056765), ('donaldson 25 vin ahn', 'donaldson 25 vin ahn', 0.7056765), ('tata tinplate  14 duerefstrooss allerborn', 'tinplate 14 duerefstrooss ratz zllerblrn', 0.7056765), ('pnc infratech  2 leudelange abweiler', 'pnc infratech  2 leudelange abweiler', 0.7056765), ('lowery 10 village abweiler', 'lowery 10 village abweiler', 0.7056765), ('luxottica india eyewear  20 village abweiler', 'luxottica india eyewear  20 village abweiler', 0.7056765), ('63 moons technologies  29b village abweiler', '63 moons technologies  29b village abweiler', 0.7056765), ('a.o. smith  38 village abweiler', 'adani enterprises  14 bechel bettange sur mess', 0.7056765), ('desein  10 palmberg ahn', 'desein  10 palmberg ahn', 0.7056765), ('voltech  62 village abweiler', ' 62 villge abweiler', 0.7056765), ('yum!  5 résistance ahn', 'yum!  5 résistance ahn', 0.7056765), ('gain credit  35 résistance ahn', 'gain cfrdit 35 gésistancf ahn', 0.7056765), ('mendoza 10 vignes ahn', 'hansen 8 beyren mensdorf', 0.7056765), ('clarivate analytics  4 reimergaard altrier', 'clarivate analytics  4 reimergaard altrier', 0.7056765), ('time technoplast  4 aly duhr ahn', 'bradshaw 27 cimetière sandweiler', 0.7056765), ('hbl power systems  6 tumulus altrier', 'hbl power systems  6 tumulus altrier', 0.7056765), ('morton 2 niederdonven ahn', 'willis 2a cimetière weiler la tour', 0.7056765), ('maddox 17 niederdonven ahn', 'kiwitech  12 vallée beaufort', 0.7056765), ('pennington 45 niederdonven ahn', 'ornnington 45 nifderronven ahn', 0.7056765), ('conley 4 kreizenheicht altrier', 'melendez 95 charles simonis luxembourg', 0.7056765), ('alvarez 28 kreizenheicht altrier', 'gonzalez 9 léopold richard wiltz', 0.7056765), ('hendricks 6 rausch altrier', 'hendricks 6 rausch altrier', 0.7056765), ('harding 9 schanz altrier', 'bharat it services  52 aubépines luxembourg', 0.7056765), ('volansys technologies  20 schanz altrier', 'volwnsyd technologies 20 sshana altrier', 0.7056765), ('oxford university press  32 schanz altrier', 'oxford university press  32 schanz altrier', 0.7056765), ('snyder 43 schanz altrier', 'sbyee 43 schanz alfker', 0.7056765), ('patrick 52 schanz altrier', 'patrofk 52 scjajz altrier', 0.7056765), ('5 bourglinster altlinster', 'bgitht 78 dommepdajge walferdange', 0.7056765), ('andrade 1b junglinster altlinster', 'andrade 1b junglinster altlinster', 0.7056765), ('reid 6b yunhlinster altljnstfr', 'pin click  12 sangliers steinsel', 0.7056765), ('anraoali vdoup 14 junglinster altlinster', 'armstrong 10 indépendance steinsel', 0.7056765), ('frye 22a jeunesse sacrifiée 1940 1945 alzingen', 'armed forces tribunal  5 moselle grevenmacher', 0.7056765), ('harmon 42 jeunesse sacrifiée 1940 1945 alzingen', 'harmon 42 jeunesse sacrifiée 1940 1945 alzingen', 0.7056765), ('wu 5 larochette altlinster', 'brlps  94 belvaux', 0.7056765), ('davis 7 prés altlinster', 'davi 7 prés altlinster', 0.7056765), ('moyer 5 hondsbreck alzingen', 'pan seeds  2a ell redange sur attert', 0.7056765), ('twtfield zlxingen', 'bettendorf ritz-carlton  15 château', 0.7056765), ('satyam venture engineering services  10 rothweit alzingen', 'satyam venture enginesfing services 10 eothweut alzujgen', 0.7056765), ('simon 3 abbé edouard garnich alzingen', 'sandoval 25 sept arpents luxembourg', 0.7056765), ('brown 13 abbé edouard garnich alzingen', 'brown 13 qbné edouard garbifh alzingen', 0.7056765), ('sunbeam auto  33 rothweit alzingen', 'rt network solutions  fort wedell luxembourg', 0.7056765), ('korea plant service and engineering  4 eglise alzingen', 'korea lkant deevice and engineering 4 eglise apzingfn', 0.7056765), ('nicholson 13 eglise alzingen', 'nicholson 13 fgiise qlzinven', 0.7056765), ('bowman 433 thionville alzingen', 'satyam auto components  46 esch sanem', 0.7056765), ('manipal healthmap  479 thionville alzingen', 'manipal healthmap  479 thionville alzingen', 0.7056765), ('consuktandy services 10 heeperanfe alzingen', 'vqssuez 36 charretiers aiptz', 0.7056765), ('getronics  482a thionville alzingen', 'getruonicis  482a thionville ajlzingen', 0.7056765), ('garcia 496a thionville alzingen', 'garcia 496a thionville alzingen', 0.7056765), ('smc power generation  510 thionville alzingen', 'wade 3 gaulois wasserbillig', 0.7056765), ('curry 34 hesperange alzingen', 'curry 34 hesperange alzingen', 0.7056765), ('jennings 531 thionville alzingen', 'rsb transmissions  1 oberkorn belvaux', 0.7056765), ('monroe 2a algerf bousser alxingfn', 'reed 59 prinzenberg pétange', 0.7056765), ('holmes 11 albert bousser alzingen', 'global hospital pune india  70a jean baptiste gillardin pétange', 0.7056765), ('uniproducts  12 roeser alzingen', 'fisher 9 ditzebierg kobenbour', 0.7056765), ('joseph 23 roeser alzingen', 'josph 23 oeser alzingen', 0.7056765), ('india power corporation  35 roeser alzingen', 'poded corporation 35 roeser alzingen', 0.7056765), ('suguna foods  45 roeser alzingen', 'suguna foods  45 roeser alzingen', 0.7056765), ('bullock 9 jean stdichem slzinten', 'mckinney 43 fontaine casnach', 0.7056765), ('mcafee  2 cimetière alzingen', 'mcafee  2 cimetière alzingen', 0.7056765), ('psp projects 24 xihetière xlzinven', 'haier appliances india  25 templiers steinsel', 0.7056765), ('crosby 6c syren alzingen', 'frosfy 6c syren alxinben', 0.7056765), ('faulkner 16 syren alzingen', 'gaulkneg 16 syren wlzingrn', 0.7056765), ('cohen 25 syren alzingen', 'cohen 25 syren alzingen', 0.7056765), ('born group  35 syren alzingen', 'bpfn group 35 syren alxiggen', 0.7056765), ('butler 100 syren alzingen', 'butler 100 syren alzingen', 0.7056765), ('burch 2 josy haendel alzingen', 'burch 2 josy haendel alzingen', 0.7056765), ('mts 17 jlzy haendel akzongen', 'sage metals  8a durenthal keispelt', 0.7056765), ('alfanar  3 jos paquet alzingen', 'the millennium school  2 klahtzbexr eschdorf', 0.7056765), ('schmidt 20 jean wolter alzingen', 'schmkdy 20 jean qopter alzingen', 0.7056765), ('mbl infrastructures  40 duerefstrooss allerborn', 'stokes 38 merschgrund hobscheid', 0.7056763), ('valgenesis  5 luxembourg altlinster', 'valgenesis  5 luxembourg altlinster', 0.7056763), ('fields 9 jean wolter alzingen', 'fields 9 jean wolter alzingen', 0.7056763)]\n"
          ]
        }
      ],
      "source": [
        "from operator import itemgetter\n",
        "from keras.models import load_model\n",
        "\n",
        "model = load_model(best_model_path)\n",
        "\n",
        "\n",
        "# Generate each evaluation pairs\n",
        "\n",
        "\n",
        "eval_addresses_pair = [(x1, x2) for x1, x2 in zip(evaladd1, evaladd2)]\n",
        "\n",
        "test_data_x1, test_data_x2 = create_test_data(tokenizer, eval_addresses_pair,  siamese_config['MAX_SEQUENCE_LENGTH'])\n",
        "\n",
        "preds = list(model.predict([test_data_x1, test_data_x2], verbose=1).ravel())\n",
        "results = [(x, y, z) for (x, y), z in zip(eval_addresses_pair, preds)]\n",
        "results.sort(key=itemgetter(2), reverse=True)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "UWLouJF37NmJ",
        "outputId": "13cd1067-ea1b-48d0-fd5e-1319e422fdf5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-4b5e350058b2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" /// \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" /// \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" /// \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Found a pair contente ----- \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"<---->\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
          ]
        }
      ],
      "source": [
        "for item in results:\n",
        "  print(str(item[0]) + \" /// \"+ str(item[1]) + \" /// \"+ str(item[2]) + \" /// \")\n",
        "  if(str(item[0]) != str(item[1])):\n",
        "    print(\"Found a pair contente ----- \" + str(item[0]) + \"<---->\" + str(item[1]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OT73EifHFTvy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNGVNH6d3ROu"
      },
      "source": [
        "## Evaluating the model :\n",
        "\n",
        "build a confusion matrix\n",
        "\n",
        "- Recall\n",
        "- Precision\n",
        "- Accuracy\n",
        "- f1 score\n",
        "- Roc_curve\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "7HabNwH63o7d",
        "outputId": "836c6d30-0262-4cc1-94eb-712b49bcfb6c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from operator import itemgetter\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "#def do_everything():\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Build variable for evaluation latter\n",
        "def build_evaluation_list(prediction, confidence_threshold):\n",
        "  model_result = []\n",
        "  for p in prediction:\n",
        "    if p > confidence_threshold:\n",
        "      p = 1\n",
        "    else:\n",
        "      p = 0\n",
        "    model_result.append(p)\n",
        "\n",
        "  return model_result\n",
        "\n",
        "\n",
        "\n",
        "# Run the model on one data set return it's prediction on the data\n",
        "def model_run(model, evaluation_set, tokenizer):\n",
        "  evalAdd1, evalAdd2, true_pred = create_addresses_pairs(evaluation_set)\n",
        "\n",
        "  eval_addresses_pair = eval_addresses_pair = [(x1, x2) for x1, x2 in zip(evalAdd1, evalAdd2)]\n",
        "\n",
        "  test_data_x1, test_data_x2 = create_test_data(tokenizer, eval_addresses_pair,  siamese_config['MAX_SEQUENCE_LENGTH'])\n",
        "\n",
        "  preds = list(model.predict([test_data_x1, test_data_x2], verbose=1).ravel())\n",
        "\n",
        "  results = [(x, y, z) for (x, y), z in zip(eval_addresses_pair, preds)]\n",
        "\n",
        "  results.sort(key=itemgetter(2), reverse=True)\n",
        "\n",
        "  return preds, true_pred\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Combine evaluation data sets\n",
        "def combine_eval_data_sets(evalAdd, evalAddNegative, evalAddTypo1, evalAddTypo2, evalAddTypo3, evalAddToken1, evalAddToken2, evalAddToken3):\n",
        "    base = evalAddNegative + evalAdd\n",
        "\n",
        "    typo1 = evalAddNegative + evalAddTypo1\n",
        "\n",
        "    typo2 = evalAddNegative + evalAddTypo2\n",
        "\n",
        "    typo3 = evalAddNegative + evalAddTypo3\n",
        "\n",
        "    token1 = evalAddNegative + evalAddToken1\n",
        "\n",
        "    token2 = evalAddNegative + evalAddToken2\n",
        "\n",
        "    token3 = evalAddNegative + evalAddToken3\n",
        "\n",
        "    return base, typo1, typo2, typo3, token1, token2, token3\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(true_positives, true_negatives, false_positives, false_negatives):\n",
        "    # Create the confusion matrix\n",
        "    confusion_matrix = np.array([[true_negatives, false_positives],\n",
        "                                 [false_negatives, true_positives]])\n",
        "\n",
        "    # Set up the plot\n",
        "    plt.imshow(confusion_matrix, cmap='Blues')\n",
        "    plt.colorbar()\n",
        "\n",
        "    # Add labels and ticks\n",
        "    plt.xticks(np.arange(2), ['Negative', 'Positive'])\n",
        "    plt.yticks(np.arange(2), ['Negative', 'Positive'])\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "\n",
        "    # Add text annotations\n",
        "    thresh = confusion_matrix.max() / 2\n",
        "    for i in range(2):\n",
        "        for j in range(2):\n",
        "            plt.text(j, i, str(confusion_matrix[i, j]), ha='center', va='center',\n",
        "                     color='white' if confusion_matrix[i, j] > thresh else 'black')\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Compute evaluation metrics and return them according to the model prediction\n",
        "def compute_metrics(expected_result, normalized_model_result):\n",
        "    true_positive = []\n",
        "    false_positive = []\n",
        "    true_negative = []\n",
        "    false_negative = []\n",
        "\n",
        "    for i in range(len(expected_result)):\n",
        "        if expected_result[i] == 1 and normalized_model_result[i] == 1:\n",
        "            true_positive.append(i)\n",
        "        elif expected_result[i] == 0 and normalized_model_result[i] == 1:\n",
        "            false_positive.append(i)\n",
        "        elif expected_result[i] == 0 and normalized_model_result[i] == 0:\n",
        "            true_negative.append(i)\n",
        "        elif expected_result[i] == 1 and normalized_model_result[i] == 0:\n",
        "            false_negative.append(i)\n",
        "\n",
        "    # Precision\n",
        "    if len(true_positive) + len(false_positive) > 0:\n",
        "        precision = len(true_positive) / (len(true_positive) + len(false_positive))\n",
        "    else:\n",
        "        precision = 0.0\n",
        "\n",
        "    # Recall = TP / TP + FN\n",
        "    if len(true_positive) > 0:\n",
        "        recall = len(true_positive) / (len(true_positive) + len(false_negative))\n",
        "    else:\n",
        "        recall = 0.0\n",
        "\n",
        "    # F1 Score\n",
        "    if precision + recall > 0:\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "    else:\n",
        "        f1_score = 0.0\n",
        "\n",
        "    # Accuracy\n",
        "    if len(expected_result) > 0:\n",
        "        accuracy = (len(true_positive) + len(true_negative)) / len(expected_result)\n",
        "    else:\n",
        "        accuracy = 0.0\n",
        "\n",
        "    return (\n",
        "        precision,\n",
        "        recall,\n",
        "        accuracy,\n",
        "        f1_score,\n",
        "        true_positive,\n",
        "        true_negative,\n",
        "        false_positive,\n",
        "        false_negative,\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_with_thresholds(model_pred, true_pred, model_name, embedding_type, embedding_dim):\n",
        "    thresholds = [i / 1000 for i in range(1001)]\n",
        "    best_f1_score = 0.0\n",
        "    best_threshold = 0.0\n",
        "    best_accuracy = 0.0\n",
        "    best_recall = 0.0\n",
        "    best_precision = 0.0\n",
        "    f1_scores = []\n",
        "\n",
        "    for threshold in thresholds:\n",
        "        model_pred_thresh = build_evaluation_list(model_pred, threshold)\n",
        "        precision, recall, f1_score, accuracy, _, _, _, _ = compute_metrics(true_pred, model_pred_thresh)\n",
        "\n",
        "        if f1_score > best_f1_score:\n",
        "            best_f1_score = f1_score\n",
        "            best_threshold = threshold\n",
        "            best_accuracy = accuracy\n",
        "            best_recall = recall\n",
        "            best_precision = precision\n",
        "\n",
        "        f1_scores.append(f1_score)\n",
        "\n",
        "    # Print the evaluation results corresponding to the best F1-score (best threshold)\n",
        "    print(f\"Best threshold for {model_name} ({embedding_type} {embedding_dim}): {best_threshold}\")\n",
        "    print(f\"Best F1 Score for {model_name} ({embedding_type} {embedding_dim}): {best_f1_score}\")\n",
        "    print(f\"Accuracy corresponding to the best F1 Score: {best_accuracy}\")\n",
        "    print(f\"Recall corresponding to the best F1 Score: {best_recall}\")\n",
        "    print(f\"Precision corresponding to the best F1 Score: {best_precision}\")\n",
        "\n",
        "    evaluation_results = {\n",
        "        \"thresholds\": thresholds,\n",
        "        \"precision\": best_precision,\n",
        "        \"recall\": best_recall,\n",
        "        \"accuracy\": best_accuracy,\n",
        "        \"f1_scores\": f1_scores,\n",
        "        \"best_threshold\": best_threshold,\n",
        "        \"max_f1_score\": best_f1_score\n",
        "    }\n",
        "\n",
        "    return evaluation_results\n",
        "\n",
        "\n",
        "\n",
        "def printDetails(true_positive, true_negative, false_positive, false_negative, expected_label, predicted_label):\n",
        "\n",
        "  for tp in true_positive:\n",
        "    print(\"True positive record: \" + \" addresse1: \" + str(evaladd1[tp[2]]) + \" addresse2: \" + str(evaladd2[tp[2]]) +\n",
        "          \" Expected label: \" + str(expected_label[tp[2]]) +\n",
        "          \" Predicted label: \" + str(predicted_label[tp[2]]))\n",
        "\n",
        "  print(\"-----------------------------------------------------------------------------------------------\")\n",
        "\n",
        "  for tn in true_negative:\n",
        "    print(\"True negative record: \" + \" addresse1: \" + str(evaladd1[tn[2]]) + \" addresse2: \" + str(evaladd2[tn[2]]) +\n",
        "          \" Expected label: \" + str(expected_label[tn[2]]) +\n",
        "          \" Predicted label: \" + str(predicted_label[tn[2]]))\n",
        "\n",
        "  print(\"-----------------------------------------------------------------------------------------------\")\n",
        "\n",
        "  for fp in false_positive:\n",
        "    print(\"False positive record: \" + \" addresse1: \" + str(evaladd1[fp[2]]) + \" addresse2: \" + str(evaladd2[fp[2]]) +\n",
        "          \" Expected label: \" + str(expected_label[fp[2]]) +\n",
        "          \" Predicted label: \" + str(predicted_label[fp[2]]))\n",
        "\n",
        "  print(\"-----------------------------------------------------------------------------------------------\")\n",
        "\n",
        "  for fn in false_negative:\n",
        "    print(\"False negative record: \" + \" addresse1: \" + str(evaladd1[fn[2]]) + \" addresse2: \" + str(evaladd2[fn[2]]) +\n",
        "          \"Expected label: \" + str(expected_label[fn[2]]) +\n",
        "          \"Predicted label: \" + str(predicted_label[fn[2]]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plot_f1_scores(base_eval, typo1_eval, typo2_eval, typo3_eval, token1_eval, token2_eval, token3_eval):\n",
        "    thresholds = base_eval[\"thresholds\"]  # Use the thresholds from evaluation results\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    marker_size = 2  # Adjust the marker size as needed\n",
        "\n",
        "    plt.plot(thresholds, base_eval[\"f1_scores\"], marker='o', markersize=marker_size, label='Base')\n",
        "    plt.plot(thresholds, typo1_eval[\"f1_scores\"], marker='o', markersize=marker_size, label='Typo1')\n",
        "    plt.plot(thresholds, typo2_eval[\"f1_scores\"], marker='o', markersize=marker_size, label='Typo2')\n",
        "    plt.plot(thresholds, typo3_eval[\"f1_scores\"], marker='o', markersize=marker_size, label='Typo3')\n",
        "    plt.plot(thresholds, token1_eval[\"f1_scores\"], marker='o', markersize=marker_size, label='Token1')\n",
        "    plt.plot(thresholds, token2_eval[\"f1_scores\"], marker='o', markersize=marker_size, label='Token2')\n",
        "    plt.plot(thresholds, token3_eval[\"f1_scores\"], marker='o', markersize=marker_size, label='Token3')\n",
        "\n",
        "    plt.xlabel('Threshold')\n",
        "    plt.ylabel('F1-Score')\n",
        "    plt.title('F1-Score vs. Threshold for Different Datasets')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F60rz4ZWpRj"
      },
      "source": [
        "# Sbert transformer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8O9u2ty4LAa",
        "outputId": "b3cab4bc-10d0-4667-e626-204ee368d0ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.16.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nng6_-TQDJhb",
        "outputId": "edc968f6-3cfb-418f-9544-c49fe76f1e06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wRSw9HQWpRk",
        "outputId": "c6b88a3a-2f27-44d1-bce4-2651bf59b5f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "78 zone industrielle In den Allern industrielle 78 zone In Allern den 0.99998426\n",
            "3 Om Schachkrutchen Troine-Route 3 Om Schachkrutchen Troine Route 0.9990445\n",
            "3 Om Schachkrutchen Troine-Route 3 Om Troine Route 0.9990445\n",
            "Om 3 Schackrutchn Troine route 3 om Schackrtuche Troine-route 0.99899614\n",
            "2 route de Filsborg, Altwies 2 route de Filsborg, Altwies 0.9987336\n",
            "3 london street, Brooklyn 3 london street  Brooklyn 0.9795068\n",
            "1 rue de la résistance, Ahn 1 rue de la résistance, Bascharagage 0.4277068\n",
            "1  résistance Ahn 1  résistance Bascharagage 0.019620746\n",
            "317 route de longwy Luxembourg 317 longwy Luxembourg 0.008418649\n",
            "92A rue Adoplhe Fischer Luxembourg 92A Adoplhe Fissher Lux 0.00025853515\n",
            "eflfo 2 ruddh  2 rue def rudh 0.00021753134\n",
            "3 london street, Brooklyn 22 route de filsborg Atwiles 8.556247e-05\n",
            "1 rue de la resistance, Ahn 1 rue de la résistance, Ahn 3.287196e-05\n",
            "rue de ma résissrtance, ahn 103 ahn rue de la rsistance, 103 2.0682812e-05\n",
            "22 routes de filsborg, Atwiles 23 route de filsborg, Atwiles 9.506941e-06\n",
            "103 résistance, Ahn 1 filsborg, Auduin 6.3180923e-06\n",
            "1 résistance Altwies 2 résistance Altwies 4.053116e-06\n",
            "50C rue du village, Abweiler  50C rue du villzge, Abxeiler  7.4505806e-07\n",
            "103 rue de la résistance, Ahn 1 rue de filsborg, Auduin 5.9604645e-08\n"
          ]
        }
      ],
      "source": [
        "for item in results:\n",
        "    print(item[0], item[1], item[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEan4pFDWpRk"
      },
      "source": [
        "## Quickstart and embedding (using already trained model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faaBuXDdWpRk",
        "outputId": "ac5f61a2-72dc-4e9b-b6a3-2c99f08fc8af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: This framework generates embeddings for each input sentence\n",
            "Embedding: [-1.37173552e-02 -4.28515449e-02 -1.56286024e-02  1.40537303e-02\n",
            "  3.95537727e-02  1.21796280e-01  2.94334106e-02 -3.17524187e-02\n",
            "  3.54959629e-02 -7.93139935e-02  1.75878741e-02 -4.04369719e-02\n",
            "  4.97259349e-02  2.54912246e-02 -7.18700588e-02  8.14968869e-02\n",
            "  1.47069141e-03  4.79626991e-02 -4.50336412e-02 -9.92174670e-02\n",
            " -2.81769745e-02  6.45046085e-02  4.44670543e-02 -4.76217009e-02\n",
            " -3.52952331e-02  4.38671783e-02 -5.28566055e-02  4.33063833e-04\n",
            "  1.01921506e-01  1.64072234e-02  3.26996595e-02 -3.45986746e-02\n",
            "  1.21339476e-02  7.94870779e-02  4.58345609e-03  1.57777797e-02\n",
            " -9.68206208e-03  2.87625659e-02 -5.05805984e-02 -1.55793717e-02\n",
            " -2.87906546e-02 -9.62280575e-03  3.15556750e-02  2.27349028e-02\n",
            "  8.71449187e-02 -3.85027491e-02 -8.84718448e-02 -8.75498448e-03\n",
            " -2.12343335e-02  2.08923239e-02 -9.02077407e-02 -5.25732562e-02\n",
            " -1.05638904e-02  2.88310610e-02 -1.61455162e-02  6.17837207e-03\n",
            " -1.23234643e-02 -1.07336966e-02  2.83353925e-02 -5.28567582e-02\n",
            " -3.58618125e-02 -5.97989187e-02 -1.09055368e-02  2.91566327e-02\n",
            "  7.97979087e-02 -3.27869435e-04  6.83502248e-03  1.32718356e-02\n",
            " -4.24619913e-02  1.87657047e-02 -9.89234224e-02  2.09049918e-02\n",
            " -8.69606137e-02 -1.50152408e-02 -4.86201532e-02  8.04414600e-02\n",
            " -3.67698912e-03 -6.65044263e-02  1.14556760e-01 -3.04229166e-02\n",
            "  2.96631586e-02 -2.80695464e-02  4.64989729e-02 -2.25513950e-02\n",
            "  8.54222998e-02  3.15446518e-02  7.34541640e-02 -2.21861880e-02\n",
            " -5.29678538e-02  1.27130132e-02 -5.27339838e-02 -1.06188729e-01\n",
            "  7.04731345e-02  2.76736692e-02 -8.05531815e-02  2.39649620e-02\n",
            " -2.65125576e-02 -2.17330772e-02  4.35275882e-02  4.84712161e-02\n",
            " -2.37067696e-02  2.85768248e-02  1.11846186e-01 -6.34935871e-02\n",
            " -1.58318467e-02 -2.26169508e-02 -1.31027615e-02 -1.62068917e-03\n",
            " -3.60929258e-02 -9.78296921e-02 -4.67729159e-02  1.76271517e-02\n",
            " -3.97492237e-02 -1.76393864e-04  3.39627750e-02 -2.09633410e-02\n",
            "  6.33660844e-03 -2.59411316e-02  8.10410008e-02  6.14393242e-02\n",
            " -5.44593297e-03  6.48276433e-02 -1.16844043e-01  2.36861184e-02\n",
            " -1.32058682e-02 -1.12476468e-01  1.90049242e-02 -1.74661551e-34\n",
            "  5.58950081e-02  1.94244590e-02  4.65438887e-02  5.18645905e-02\n",
            "  3.89390998e-02  3.40541117e-02 -4.32114154e-02  7.90637210e-02\n",
            " -9.79530066e-02 -1.27440887e-02 -2.91870926e-02  1.02052419e-02\n",
            "  1.88115947e-02  1.08942553e-01  6.63465187e-02 -5.35295084e-02\n",
            " -3.29228453e-02  4.69826907e-02  2.28882916e-02  2.74114832e-02\n",
            " -2.91982852e-02  3.12706791e-02 -2.22850591e-02 -1.02282234e-01\n",
            " -2.79116593e-02  1.13792978e-02  9.06308740e-02 -4.75414321e-02\n",
            " -1.00718945e-01 -1.23231942e-02 -7.96928704e-02 -1.44636380e-02\n",
            " -7.76400641e-02 -7.66918249e-03  9.73955356e-03  2.24204753e-02\n",
            "  7.77268335e-02 -3.17155244e-03  2.11537741e-02 -3.30393985e-02\n",
            "  9.55249462e-03 -3.73011678e-02  2.61360426e-02 -9.79086477e-03\n",
            " -6.31505325e-02  5.77434059e-03 -3.80031057e-02  1.29684890e-02\n",
            " -1.82499364e-02 -1.56283174e-02 -1.23363407e-03  5.55579141e-02\n",
            "  1.13080234e-04 -5.61256669e-02  7.40165338e-02  1.84451882e-02\n",
            " -2.66368501e-02  1.31951803e-02  7.50086829e-02 -2.46796831e-02\n",
            " -3.24006341e-02 -1.57675110e-02 -8.03517550e-03 -5.61321666e-03\n",
            "  1.05688134e-02  3.26165115e-03 -3.91990021e-02 -9.38677043e-02\n",
            "  1.14227191e-01  6.57304525e-02 -4.72634174e-02  1.45087857e-02\n",
            " -3.54490280e-02 -3.37761603e-02 -5.15505672e-02 -3.81006836e-03\n",
            " -5.15036322e-02 -5.93429171e-02 -1.69412652e-03  7.42107928e-02\n",
            " -4.20091338e-02 -7.19975084e-02  3.17250155e-02 -1.66303422e-02\n",
            "  3.96981463e-03 -6.52750954e-02  2.77391020e-02 -7.51649216e-02\n",
            "  2.27455776e-02 -3.91367897e-02  1.54315913e-02 -5.54908440e-02\n",
            "  1.23318722e-02 -2.59520821e-02  6.66423663e-02 -6.91259463e-34\n",
            "  3.31628956e-02  8.47929046e-02 -6.65583760e-02  3.33541296e-02\n",
            "  4.71610203e-03  1.35361915e-02 -5.38694337e-02  9.20694172e-02\n",
            " -2.96876598e-02  3.16219553e-02 -2.37497576e-02  1.98770966e-02\n",
            "  1.03446178e-01 -9.06947479e-02  6.30625384e-03  1.42886052e-02\n",
            "  1.19293667e-02  6.43724762e-03  4.20104750e-02  1.25344768e-02\n",
            "  3.93019058e-02  5.35691865e-02 -4.30749804e-02  6.10432252e-02\n",
            " -5.39732027e-05  6.91682473e-02  1.05520226e-02  1.22111840e-02\n",
            " -7.23185092e-02  2.50469856e-02 -5.18371277e-02 -4.36562337e-02\n",
            " -6.71818480e-02  1.34828528e-02 -7.25888908e-02  7.04165967e-03\n",
            "  6.58939630e-02  1.08994860e-02 -2.60006706e-03  5.49968705e-02\n",
            "  5.06966449e-02  3.27948816e-02 -6.68833181e-02  6.45557567e-02\n",
            " -2.52075940e-02 -2.92572118e-02 -1.16696693e-01  3.24064232e-02\n",
            "  5.85858189e-02 -3.51756513e-02 -7.15240240e-02  2.24936083e-02\n",
            " -1.00786723e-01 -4.74544913e-02 -7.61962831e-02 -5.87166660e-02\n",
            "  4.21138331e-02 -7.47213885e-02  1.98467914e-02 -3.36499629e-03\n",
            " -5.29736802e-02  2.74729691e-02  3.45736817e-02 -6.11846857e-02\n",
            "  1.06364794e-01 -9.64119881e-02 -4.55945097e-02  1.51489647e-02\n",
            " -5.13524842e-03 -6.64447471e-02  4.31721173e-02 -1.10406131e-02\n",
            " -9.80253331e-03  7.53783062e-02 -1.49570936e-02 -4.80208471e-02\n",
            "  5.80726638e-02 -2.43896376e-02 -2.23137625e-02 -4.36992273e-02\n",
            "  5.12054190e-02 -3.28626074e-02  1.08763300e-01  6.08926825e-02\n",
            "  3.30793299e-03  5.53820021e-02  8.43200982e-02  1.27087235e-02\n",
            "  3.84465940e-02  6.52325600e-02 -2.94683855e-02  5.08005321e-02\n",
            " -2.09347773e-02  1.46135703e-01  2.25561298e-02 -1.77227761e-08\n",
            " -5.02672605e-02 -2.79184926e-04 -1.00328632e-01  2.42811553e-02\n",
            " -7.54043534e-02 -3.79139744e-02  3.96049619e-02  3.10079474e-02\n",
            " -9.05704591e-03 -6.50411472e-02  4.05453220e-02  4.83390242e-02\n",
            " -4.56962325e-02  4.76008514e-03  2.64359498e-03  9.35614184e-02\n",
            " -4.02599797e-02  3.27402055e-02  1.18298111e-02  5.54344766e-02\n",
            "  1.48052216e-01  7.21189231e-02  2.77007668e-04  1.68651100e-02\n",
            "  8.34879838e-03 -8.76156799e-03 -1.33649446e-02  6.14237301e-02\n",
            "  1.57167744e-02  6.94961101e-02  1.08621838e-02  6.08018339e-02\n",
            " -5.33421785e-02 -3.47924158e-02 -3.36272381e-02  6.93906471e-02\n",
            "  1.22987507e-02 -1.45237386e-01 -2.06968887e-03 -4.61132675e-02\n",
            "  3.72748147e-03 -5.59353922e-03 -1.00659862e-01 -4.45953384e-02\n",
            "  5.40921614e-02  4.98890178e-03  1.49534633e-02 -8.26059431e-02\n",
            "  6.26630932e-02 -5.01904078e-03 -4.81857508e-02 -3.53990979e-02\n",
            "  9.03386902e-03 -2.42338013e-02  5.66267371e-02  2.51529105e-02\n",
            " -1.70708802e-02 -1.24780377e-02  3.19518223e-02  1.38420640e-02\n",
            " -1.55814970e-02  1.00178212e-01  1.23657197e-01 -4.22966890e-02]\n",
            "\n",
            "Sentence: Sentences are passed as a list of string.\n",
            "Embedding: [ 5.64524941e-02  5.50024211e-02  3.13795917e-02  3.39485407e-02\n",
            " -3.54247391e-02  8.34667981e-02  9.88800824e-02  7.27545982e-03\n",
            " -6.68657012e-03 -7.65808206e-03  7.93738365e-02  7.39684154e-04\n",
            "  1.49292350e-02 -1.51047092e-02  3.67674008e-02  4.78743352e-02\n",
            " -4.81969304e-02 -3.76052111e-02 -4.60278280e-02 -8.89816359e-02\n",
            "  1.20228112e-01  1.30663246e-01 -3.73935848e-02  2.47854833e-03\n",
            "  2.55826209e-03  7.25814849e-02 -6.80436715e-02 -5.24696223e-02\n",
            "  4.90233898e-02  2.99563054e-02 -5.84429689e-02 -2.02263203e-02\n",
            "  2.08822340e-02  9.76691991e-02  3.52390669e-02  3.91140729e-02\n",
            "  1.05667617e-02  1.56232726e-03 -1.30822659e-02  8.52903258e-03\n",
            " -4.84096026e-03 -2.03766860e-02 -2.71800663e-02  2.83307508e-02\n",
            "  3.66017781e-02  2.51276083e-02 -9.90862027e-02  1.15626482e-02\n",
            " -3.60380262e-02 -7.23783970e-02 -1.12670071e-01  1.12942038e-02\n",
            " -3.86397392e-02  4.67386134e-02 -2.88460571e-02  2.26703882e-02\n",
            " -8.52405839e-03  3.32815014e-02 -1.06584094e-03 -7.09745362e-02\n",
            " -6.31169975e-02 -5.72186820e-02 -6.16026632e-02  5.47146276e-02\n",
            "  1.18318023e-02 -4.66261581e-02  2.56959703e-02 -7.07413303e-03\n",
            " -5.73843122e-02  4.12839428e-02 -5.91503195e-02  5.89022078e-02\n",
            " -4.41697463e-02  4.65081632e-02 -3.15814689e-02  5.58312647e-02\n",
            "  5.54578453e-02 -5.96533641e-02  4.06407639e-02  4.83763497e-03\n",
            " -4.96768206e-02 -1.00944348e-01  3.40078175e-02  4.13273042e-03\n",
            " -2.93524098e-03  2.11837385e-02 -3.73962112e-02 -2.79066842e-02\n",
            " -4.61767912e-02  5.26138283e-02 -2.79735085e-02 -1.62379265e-01\n",
            "  6.61042631e-02  1.72274131e-02 -5.45113301e-03  4.74473909e-02\n",
            " -3.82237434e-02 -3.96896824e-02  1.34544885e-02  4.49653640e-02\n",
            "  4.53671440e-03  2.82978769e-02  8.36633146e-02 -1.00858258e-02\n",
            " -1.19354017e-01 -3.84624638e-02  4.82858941e-02 -9.46083590e-02\n",
            "  1.91854089e-02 -9.96518359e-02 -6.30596504e-02  3.02695855e-02\n",
            "  1.17402757e-02 -4.78372648e-02 -6.20267028e-03 -3.32850814e-02\n",
            " -4.04391997e-03  1.28307138e-02  4.05254364e-02  7.56476894e-02\n",
            "  2.92434860e-02  2.84270123e-02 -2.78939065e-02  1.66857876e-02\n",
            " -2.47961897e-02 -6.83651268e-02  2.89968867e-02 -5.39867748e-33\n",
            " -2.69017392e-03 -2.65069138e-02 -6.47939451e-04 -8.46198201e-03\n",
            " -7.35154524e-02  4.94082551e-03 -5.97842373e-02  1.03438003e-02\n",
            "  2.12902576e-03 -2.88217678e-03 -3.17076556e-02 -9.42364112e-02\n",
            "  3.03020030e-02  7.00226650e-02  4.50685546e-02  3.69439200e-02\n",
            "  1.13593517e-02  3.53027135e-02  5.50445775e-03  1.34416134e-03\n",
            "  3.46117374e-03  7.75047615e-02  5.45112677e-02 -7.92055652e-02\n",
            " -9.31696519e-02 -4.03398536e-02  3.10668629e-02 -3.83081995e-02\n",
            " -5.89442924e-02  1.93331800e-02 -2.67159678e-02 -7.91938081e-02\n",
            "  1.04181760e-04  7.70621151e-02  4.16603871e-02  8.90932456e-02\n",
            "  3.56843360e-02 -1.09152840e-02  3.71498279e-02 -2.07070261e-02\n",
            " -2.46100929e-02 -2.05025375e-02  2.62201745e-02  3.43590602e-02\n",
            "  4.39251140e-02 -8.20518564e-03 -8.40710104e-02  4.24171016e-02\n",
            "  4.87498865e-02  5.95384911e-02  2.87747905e-02  3.37638296e-02\n",
            " -4.07442711e-02 -1.66372617e-03  7.91927502e-02  3.41088325e-02\n",
            " -5.72796213e-04  1.87749565e-02 -1.36963902e-02  7.38333240e-02\n",
            "  5.74505248e-04  8.33505392e-02  5.60811087e-02 -1.13711338e-02\n",
            "  4.42611501e-02  2.69581564e-02 -4.80536073e-02 -3.15087289e-02\n",
            "  7.75226057e-02  1.81773454e-02 -8.83005336e-02 -7.85518158e-03\n",
            " -6.22242838e-02  7.19372928e-02 -2.33475156e-02  6.52480731e-03\n",
            " -9.49525367e-03 -9.88313407e-02  4.01306264e-02  3.07396930e-02\n",
            " -2.21607257e-02 -9.45911780e-02  1.02368146e-02  1.02187760e-01\n",
            " -4.12960425e-02 -3.15777957e-02  4.74752188e-02 -1.10209800e-01\n",
            "  1.69614796e-02 -3.71708833e-02 -1.03261927e-02 -4.72538471e-02\n",
            " -1.20213805e-02 -1.93255395e-02  5.79292290e-02  4.23867054e-34\n",
            "  3.92013304e-02  8.41361731e-02 -1.02946721e-01  6.92259818e-02\n",
            "  1.68821719e-02 -3.26760560e-02  9.65962000e-03  1.80899873e-02\n",
            "  2.17939876e-02  1.63189471e-02 -9.69291925e-02  3.74850631e-03\n",
            " -2.38456801e-02 -3.44055966e-02  7.11962655e-02  9.21923784e-04\n",
            " -6.23855367e-03  3.23754437e-02 -8.90376861e-04  5.01907477e-03\n",
            " -4.24537770e-02  9.89083797e-02 -4.60321046e-02  4.69704941e-02\n",
            " -1.75284278e-02 -7.02514965e-03  1.32743660e-02 -5.30152097e-02\n",
            "  2.66401120e-03  1.45819187e-02  7.43344938e-03 -3.07131782e-02\n",
            " -2.09416319e-02  8.24110284e-02 -5.15894033e-02 -2.71178186e-02\n",
            "  1.17582992e-01  7.72499340e-03 -1.89523119e-02  3.94559130e-02\n",
            "  7.17360377e-02  2.59116869e-02  2.75191851e-02  9.50546656e-03\n",
            " -3.02354973e-02 -4.07944806e-02 -1.04028493e-01 -7.97423068e-03\n",
            " -3.64457630e-03  3.29716653e-02 -2.35954598e-02 -7.50513189e-03\n",
            " -5.82234301e-02 -3.17905806e-02 -4.18049060e-02  2.17453819e-02\n",
            " -6.67292103e-02 -4.89104502e-02  4.58515342e-03 -2.66046394e-02\n",
            " -1.12597041e-01  5.11167534e-02  5.48534282e-02 -6.69857189e-02\n",
            "  1.26766339e-01 -8.59487429e-02 -5.94231412e-02 -2.92183971e-03\n",
            " -1.14876069e-02 -1.26025811e-01 -3.48278251e-03 -9.12001878e-02\n",
            " -1.22933067e-01  1.33777000e-02 -4.75775152e-02 -6.57933205e-02\n",
            " -3.39409970e-02 -3.07107288e-02 -5.22034243e-02 -2.35463940e-02\n",
            "  5.90035059e-02 -3.85757908e-02  3.19701284e-02  4.05118391e-02\n",
            "  1.67077798e-02 -3.58281061e-02  1.45687927e-02  3.20137478e-02\n",
            " -1.34843504e-02  6.07819892e-02 -8.31400603e-03 -1.08106127e-02\n",
            "  4.69410904e-02  7.66133741e-02 -4.23400216e-02 -2.11963318e-08\n",
            " -7.25292638e-02 -4.20228131e-02 -6.12374544e-02  5.24666682e-02\n",
            " -1.42363459e-02  1.18487058e-02 -1.40789226e-02 -3.67530212e-02\n",
            " -4.44977544e-02 -1.15140351e-02  5.23317121e-02  2.96651684e-02\n",
            " -4.62780520e-02 -3.70892808e-02  1.89129580e-02  2.04307083e-02\n",
            " -2.24005859e-02 -1.48562677e-02 -1.79504286e-02  4.20007631e-02\n",
            "  1.40942782e-02 -2.83492263e-02 -1.16863042e-01  1.48956897e-02\n",
            " -7.30592874e-04  5.66028468e-02 -2.68740449e-02  1.09106638e-01\n",
            "  2.94562988e-03  1.19267881e-01  1.14212438e-01  8.92973915e-02\n",
            " -1.70255471e-02 -4.99054119e-02 -2.11931095e-02  3.18421237e-02\n",
            "  7.03436434e-02 -1.02929421e-01  8.23816955e-02  2.81968340e-02\n",
            "  3.21146511e-02  3.79107855e-02 -1.09553121e-01  8.19620714e-02\n",
            "  8.73216838e-02 -5.73563650e-02 -2.01709159e-02 -5.69444522e-02\n",
            " -1.30338352e-02 -5.55684417e-02 -1.32966004e-02  8.64009652e-03\n",
            "  5.30012585e-02 -4.06847447e-02  2.71709003e-02 -2.55948980e-03\n",
            "  3.05775888e-02 -4.61865328e-02  4.68033552e-03 -3.64947096e-02\n",
            "  6.80802837e-02  6.65087476e-02  8.49152058e-02 -3.32849026e-02]\n",
            "\n",
            "Sentence: The quick brown fox jumps over the lazy dog.\n",
            "Embedding: [ 4.39335555e-02  5.89344129e-02  4.81783748e-02  7.75481239e-02\n",
            "  2.67444383e-02 -3.76295261e-02 -2.60506151e-03 -5.99430315e-02\n",
            " -2.49603437e-03  2.20728088e-02  4.80258875e-02  5.57553098e-02\n",
            " -3.89454588e-02 -2.66167559e-02  7.69342296e-03 -2.62376610e-02\n",
            " -3.64161022e-02 -3.78161110e-02  7.40781352e-02 -4.95050699e-02\n",
            " -5.85216992e-02 -6.36196882e-02  3.24349925e-02  2.20085643e-02\n",
            " -7.10637346e-02 -3.31577696e-02 -6.94104284e-02 -5.00373691e-02\n",
            "  7.46268108e-02 -1.11133859e-01 -1.23063009e-02  3.77456471e-02\n",
            " -2.80313157e-02  1.45353554e-02 -3.15585881e-02 -8.05836096e-02\n",
            "  5.83525226e-02  2.59000063e-03  3.92801911e-02  2.57695504e-02\n",
            "  4.98505682e-02 -1.75624248e-03 -4.55298051e-02  2.92607844e-02\n",
            " -1.02017261e-01  5.22287898e-02 -7.90899321e-02 -1.02857249e-02\n",
            "  9.20247007e-03  1.30732376e-02 -4.04777899e-02 -2.77924985e-02\n",
            "  1.24667529e-02  6.72833249e-02  6.81247935e-02 -7.57112540e-03\n",
            " -6.09937869e-03 -4.23777029e-02  5.17815910e-02 -1.56707745e-02\n",
            "  9.56362206e-03  4.12390605e-02  2.14959085e-02  1.04293721e-02\n",
            "  2.73349807e-02  1.87062249e-02 -2.69607455e-02 -7.00542405e-02\n",
            " -1.04700483e-01 -1.89875439e-03  1.77016687e-02 -5.74725606e-02\n",
            " -1.44223329e-02  4.70484723e-04  2.33230717e-03 -2.51920056e-02\n",
            "  4.93004471e-02 -5.09609766e-02  6.31983206e-02  1.49165187e-02\n",
            " -2.70766858e-02 -4.52875681e-02 -4.90594469e-02  3.74940373e-02\n",
            "  3.84580195e-02  1.56905258e-03  3.09922323e-02  2.01630872e-02\n",
            " -1.24363611e-02 -3.06719802e-02 -2.78819073e-02 -6.89182431e-02\n",
            " -5.13677225e-02  2.14795843e-02  1.15747219e-02  1.25412364e-03\n",
            "  1.88765284e-02 -4.42318916e-02 -4.49817516e-02 -3.41871497e-03\n",
            "  1.31130917e-02  2.00099200e-02  1.21099800e-01  2.31075417e-02\n",
            " -2.20159609e-02 -3.28847133e-02 -3.15512135e-03  1.17839249e-04\n",
            "  9.91498753e-02  1.65239088e-02 -4.69671423e-03 -1.45366285e-02\n",
            " -3.71076888e-03  9.65136364e-02  2.85908096e-02  2.13481914e-02\n",
            " -7.17645139e-02 -2.41142400e-02 -4.40940596e-02 -1.07346840e-01\n",
            "  6.79946020e-02  1.30466774e-01 -7.97029734e-02  6.79511251e-03\n",
            " -2.37512290e-02 -4.61636484e-02 -2.99650952e-02 -3.69409936e-33\n",
            "  7.30969533e-02 -2.20171753e-02 -8.61464739e-02 -7.14379624e-02\n",
            " -6.36742190e-02 -7.21863061e-02 -5.93048334e-03 -2.33641602e-02\n",
            " -2.83658206e-02  4.77434918e-02 -8.06176290e-02 -1.56474754e-03\n",
            "  1.38443988e-02 -2.86235958e-02 -3.35386507e-02 -1.13777511e-01\n",
            " -9.17632319e-03 -1.08101163e-02  3.23195755e-02  5.88380806e-02\n",
            "  3.34208868e-02  1.07987955e-01 -3.72713730e-02 -2.96770465e-02\n",
            "  5.17190285e-02 -2.25338805e-02 -6.96090609e-02 -2.14475170e-02\n",
            " -2.33410578e-02  4.82199304e-02 -3.58766578e-02 -4.68990915e-02\n",
            " -3.97873856e-02  1.10813238e-01 -1.43006677e-02 -1.18464537e-01\n",
            "  5.82915321e-02 -6.25889003e-02 -2.94040944e-02  6.03238270e-02\n",
            " -2.44417787e-03  1.60116013e-02  2.67233662e-02  2.49530282e-02\n",
            " -6.49318844e-02 -1.06802024e-02  2.81464960e-02  1.03563694e-02\n",
            " -6.63608313e-04  1.98186059e-02 -3.04288547e-02  6.28419919e-03\n",
            "  5.15268072e-02 -4.75375168e-02 -6.44421279e-02  9.55031663e-02\n",
            "  7.55858272e-02 -2.81574521e-02 -3.49965878e-02  1.01816341e-01\n",
            "  1.98732577e-02 -3.68037149e-02  2.93523981e-03 -5.00745252e-02\n",
            "  1.50932118e-01 -6.16079718e-02 -8.58812556e-02  7.13986019e-03\n",
            " -1.33065563e-02  7.80404806e-02  1.75250713e-02  4.21279781e-02\n",
            "  3.57939787e-02 -1.32950455e-01  3.56970355e-02 -2.03117151e-02\n",
            "  1.24909710e-02 -3.80355865e-02  4.91543114e-02 -1.56540796e-02\n",
            "  1.21418215e-01 -8.08644444e-02 -4.68781702e-02  4.10843194e-02\n",
            " -1.84318144e-02  6.69690520e-02  4.33593756e-03  2.27315165e-02\n",
            " -1.36428624e-02 -4.53238562e-02 -3.92829292e-02 -6.29889080e-03\n",
            "  5.29610217e-02 -3.69064398e-02  7.11677000e-02  2.33343233e-33\n",
            "  1.05231352e-01 -4.81874347e-02  6.95919096e-02  6.56976029e-02\n",
            " -4.65148874e-02  5.14492728e-02 -1.24475248e-02  3.20872180e-02\n",
            " -9.23356712e-02  5.00932895e-02 -3.28876227e-02  1.39138624e-02\n",
            " -8.70228861e-04 -4.90906788e-03  1.03946380e-01  3.21603293e-04\n",
            "  5.28110452e-02 -1.17990654e-02  2.31565312e-02  1.31768482e-02\n",
            " -5.25962599e-02  3.26702558e-02  3.08671908e-04  6.41129389e-02\n",
            "  3.88501137e-02  5.88008501e-02  8.29793364e-02 -1.88149344e-02\n",
            " -2.26377528e-02 -1.00473702e-01 -3.83752882e-02 -5.88081442e-02\n",
            "  1.82419259e-03 -4.26994897e-02  2.50195395e-02  6.40059486e-02\n",
            " -3.77482623e-02 -6.83901273e-03 -2.54606782e-03 -9.76042971e-02\n",
            "  1.88475884e-02 -8.83146189e-04  1.73611902e-02  7.10790828e-02\n",
            "  3.30393165e-02  6.93424651e-03 -5.60523234e-02  5.14635108e-02\n",
            " -4.29542027e-02  4.60077226e-02 -8.78832769e-03  3.17289121e-02\n",
            "  4.93965223e-02  2.95190047e-02 -5.05192950e-02 -5.43187223e-02\n",
            "  1.50013962e-04 -2.76614781e-02  3.46878543e-02 -2.10890248e-02\n",
            "  1.38059994e-02  2.99886987e-02  1.39744114e-02 -4.26469743e-03\n",
            " -1.50337098e-02 -8.76095295e-02 -6.85054064e-02 -4.28141393e-02\n",
            "  7.76944980e-02 -7.10285455e-02 -7.37688178e-03  2.13726871e-02\n",
            "  1.35562262e-02 -7.90464804e-02  5.47668338e-03  8.30663145e-02\n",
            "  1.14148036e-01  1.80759444e-03  8.75491351e-02 -4.16045487e-02\n",
            "  1.55416708e-02 -1.01206200e-02 -7.32439663e-03  1.07966159e-02\n",
            " -6.62816912e-02  3.98413613e-02 -1.16711557e-01  6.42993897e-02\n",
            "  4.02919874e-02 -6.54741600e-02  1.95052642e-02  8.09995532e-02\n",
            "  5.36463633e-02  7.67969638e-02 -1.34852175e-02 -1.76919031e-08\n",
            " -4.43935357e-02  9.20643285e-03 -8.79590586e-02  4.26921360e-02\n",
            "  7.31364712e-02  1.68427080e-02 -4.03262749e-02  1.85131934e-02\n",
            "  8.44173059e-02 -3.74476649e-02  3.02996188e-02  2.90641878e-02\n",
            "  6.36879429e-02  2.89750695e-02 -1.47270011e-02  1.77543126e-02\n",
            " -3.36895883e-02  1.73160788e-02  3.37875262e-02  1.76826045e-01\n",
            " -1.75533127e-02 -6.03078157e-02 -1.43395010e-02 -2.38536168e-02\n",
            " -4.45531234e-02 -2.89850421e-02 -8.96776468e-02 -1.75938557e-03\n",
            " -2.61486005e-02  5.94002241e-03 -5.18355593e-02  8.57279748e-02\n",
            " -8.18398669e-02  8.35440960e-03  4.00789641e-02  4.17764783e-02\n",
            "  1.04573593e-01 -2.86560366e-03  1.96691193e-02  5.81049593e-03\n",
            "  1.33253178e-02  4.51001152e-02 -2.17588153e-02 -1.39493216e-02\n",
            " -6.86992779e-02 -2.94119469e-03 -3.10765337e-02 -1.05854452e-01\n",
            "  6.91624358e-02 -4.24115174e-02 -4.67681959e-02 -3.64750847e-02\n",
            "  4.50399965e-02  6.09816648e-02 -6.56561404e-02 -5.45641175e-03\n",
            " -1.86226703e-02 -6.31484687e-02 -3.87436599e-02  3.46733518e-02\n",
            "  5.55458739e-02  5.21627665e-02  5.61065041e-02  1.02063909e-01]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Quick install\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "#Our sentences we like to encode\n",
        "sentences = ['This framework generates embeddings for each input sentence',\n",
        "    'Sentences are passed as a list of string.',\n",
        "    'The quick brown fox jumps over the lazy dog.']\n",
        "\n",
        "#Sentences are encoded by calling model.encode()\n",
        "sentence_embeddings = model.encode(sentences)\n",
        "\n",
        "#Print the embeddings\n",
        "for sentence, embedding in zip(sentences, sentence_embeddings):\n",
        "    print(\"Sentence:\", sentence)\n",
        "    print(\"Embedding:\", embedding)\n",
        "    print(\"\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzV-qJEtWpRl"
      },
      "source": [
        "## text similarity using cosine distance (pre-trained model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKRG8i1HWpRl",
        "outputId": "1398c550-4399-41e6-e13c-6fbd44d26a1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22 routes de filsborg, Atwiles \t\t 23 route de filsborg, Atwiles \t\t Score: 0.9329\n",
            "2 route de Filsborg, Altwies \t\t 2 route de Filsborg, Altwies \t\t Score: 1.0000\n",
            "50C rue du village, Abweiler \t\t 50C rue du villzge, Abxeiler  \t\t Score: 0.6411\n",
            "1 rue de la résistance, Ahn \t\t 1 rue de la résistance, Bascharagage \t\t Score: 0.8458\n",
            "1  résistance Ahn \t\t 1  résistance Bascharagage \t\t Score: 0.6088\n",
            "1 rue de la resistance, Ahn \t\t 1 rue de la résistance, Ahn \t\t Score: 1.0000\n",
            "103 résistance, Ahn \t\t 1 filsborg, Auduin \t\t Score: 0.1648\n",
            "103 rue de la résistance, Ahn \t\t 1 rue de filsborg, Auduin \t\t Score: 0.5644\n",
            "rue de ma résissrtance, ahn 103 \t\t ahn rue de la rsistance, 103 \t\t Score: 0.7694\n",
            "1 résistance Altwies \t\t 2 résistance Altwies \t\t Score: 0.9541\n",
            "317 route de longwy Luxembourg \t\t 317 longwy Luxembourg \t\t Score: 0.8591\n",
            "92A rue Adoplhe Fischer Luxembourg \t\t 92A Adoplhe Fissher Lux \t\t Score: 0.5758\n",
            "3 Om Schachkrutchen Troine-Route \t\t 3 Om Schachkrutchen Troine Route \t\t Score: 0.9900\n",
            "Om 3 Schackrutchn Troine route78 zone industrielle In den Allern \t\t 3 om Schackrtuche Troine-route \t\t Score: 0.5343\n",
            "3 london street, Brooklyn \t\t industrielle 78 zone In Allern den \t\t Score: 0.1064\n",
            "3 london street, Brooklyn \t\t 22 route de filsborg Atwiles \t\t Score: 0.1912\n",
            "eflfo 2 ruddh \t\t 3 london street  Brooklyn \t\t Score: 0.1527\n",
            "3 Om Schachkrutchen Troine-Route \t\t 2 rue def rudh \t\t Score: 0.3702\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Two lists of sentences\n",
        "\n",
        "sentencest1 = ['22 routes de filsborg, Atwiles',\n",
        "              '2 route de Filsborg, Altwies',\n",
        "              '50C rue du village, Abweiler',\n",
        "              '1 rue de la résistance, Ahn',\n",
        "              '1  résistance Ahn',\n",
        "              '1 rue de la resistance, Ahn',\n",
        "              '103 résistance, Ahn',\n",
        "              '103 rue de la résistance, Ahn',\n",
        "              'rue de ma résissrtance, ahn 103',\n",
        "              \"1 résistance Altwies\",\n",
        "              \"317 route de longwy Luxembourg\",\n",
        "              \"92A rue Adoplhe Fischer Luxembourg\",\n",
        "              \"3 Om Schachkrutchen Troine-Route\",\n",
        "              \"Om 3 Schackrutchn Troine route\"\n",
        "              \"78 zone industrielle In den Allern\",\n",
        "              \"3 london street, Brooklyn\",\n",
        "              \"3 london street, Brooklyn\",\n",
        "              \"eflfo 2 ruddh\",\n",
        "              '3 Om Schachkrutchen Troine-Route']\n",
        "\n",
        "sentencest2 =  ['23 route de filsborg, Atwiles',\n",
        "               '2 route de Filsborg, Altwies',\n",
        "               '50C rue du villzge, Abxeiler ',\n",
        "               '1 rue de la résistance, Bascharagage',\n",
        "               '1  résistance Bascharagage',\n",
        "               '1 rue de la résistance, Ahn',\n",
        "               '1 filsborg, Auduin',\n",
        "               '1 rue de filsborg, Auduin',\n",
        "               'ahn rue de la rsistance, 103',\n",
        "               \"2 résistance Altwies\",\n",
        "               \"317 longwy Luxembourg\",\n",
        "               \"92A Adoplhe Fissher Lux\",\n",
        "               \"3 Om Schachkrutchen Troine Route\",\n",
        "               \"3 om Schackrtuche Troine-route\",\n",
        "               \"industrielle 78 zone In Allern den\",\n",
        "               \"22 route de filsborg Atwiles\",\n",
        "               \"3 london street  Brooklyn\",\n",
        "               \"2 rue def rudh\",\n",
        "               \"3 Om Troine Route\"]\n",
        "\n",
        "\n",
        "#Compute embedding for both lists\n",
        "embeddings1 = model.encode(sentencest1, convert_to_tensor=True)\n",
        "embeddings2 = model.encode(sentencest2, convert_to_tensor=True)\n",
        "\n",
        "#Compute cosine-similarities\n",
        "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
        "\n",
        "#Output the pairs with their score\n",
        "for i in range(len(sentences1)):\n",
        "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentencest1[i], sentencest2[i], cosine_scores[i][i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EJcCENgWpRl"
      },
      "source": [
        "## Training embedding with our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "4c6557720d7943f4b7f4dd3a5cd0738b",
            "44d133c1227f4c6c9d79b7746123be43",
            "8e6935caaf39469ca10424ddfa815e41",
            "e984c9ef79604b6e9f9ef710e1765680",
            "bd64271d1c2a46f9bdbc379b751479d2",
            "969e3656a3be45dca5f26c0a463f65cf",
            "4deb31d2506549dab926217761d65d9b",
            "608c79d3f7e64fad8c0acd38d44dcb00",
            "e541fbe972f9490ba4549f94a36b397d",
            "52f23a8889d643598787e2ddb076cb7b",
            "03a80a4dbf3d4997b5e28a10167b7a79",
            "f72172ca27cb4200ac19224ea851bf44",
            "6f8c2f2a0e294c87a3becbfb375e2e71",
            "01020e596eeb4b2abab39365c5b17bc4",
            "4f3d2869472c4dd19472bdc7f2da1ddb",
            "81f2efeaacea49abaa4106f4632e711e",
            "5f2c65a8c9ec42cbb53b3184359df62b",
            "f446f4dfdfd14db5a09440661b8b1636",
            "f05b8152e14a49a58b935ec973b7564d",
            "bda05d2c3b5544c5b5909f7e6487e7a9",
            "175edf876a8a4cf0beadafda78227bbd",
            "19422c5ec53847b68b54c9d35f971fd9",
            "5a31ca9af1d946eab2bec831313d94cf"
          ]
        },
        "id": "vMJGpGCTWpRm",
        "outputId": "dfdd25cc-db6c-49d1-afb3-a8b743a42ca2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c6557720d7943f4b7f4dd3a5cd0738b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f72172ca27cb4200ac19224ea851bf44",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Iteration:   0%|          | 0/235 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a31ca9af1d946eab2bec831313d94cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Iteration:   0%|          | 0/235 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
        "import torch\n",
        "\n",
        "\n",
        "# Define the model. Either from scratch or by loading a pre-trained model\n",
        "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
        "\n",
        "# Define your train examples\n",
        "train_examples = []\n",
        "for i in range(len(sentences1)):\n",
        "    train_examples.append(InputExample(texts=[sentences1[i], sentences2[i]], label=float(is_similar[i])))\n",
        "\n",
        "# Define your train dataset, the dataloader, and the train loss\n",
        "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=64)\n",
        "train_loss = losses.CosineSimilarityLoss(model)\n",
        "\n",
        "# Tune the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "train_loss.to(device)\n",
        "model.fit(train_objectives=[(train_dataloader, train_loss)],save_best_model=True, checkpoint_path = './' ,checkpoint_save_steps=100,  epochs=100, warmup_steps=100)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01020e596eeb4b2abab39365c5b17bc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f05b8152e14a49a58b935ec973b7564d",
            "max": 235,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bda05d2c3b5544c5b5909f7e6487e7a9",
            "value": 0
          }
        },
        "03a80a4dbf3d4997b5e28a10167b7a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "175edf876a8a4cf0beadafda78227bbd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19422c5ec53847b68b54c9d35f971fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44d133c1227f4c6c9d79b7746123be43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_969e3656a3be45dca5f26c0a463f65cf",
            "placeholder": "​",
            "style": "IPY_MODEL_4deb31d2506549dab926217761d65d9b",
            "value": "Epoch:   0%"
          }
        },
        "4c6557720d7943f4b7f4dd3a5cd0738b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44d133c1227f4c6c9d79b7746123be43",
              "IPY_MODEL_8e6935caaf39469ca10424ddfa815e41",
              "IPY_MODEL_e984c9ef79604b6e9f9ef710e1765680"
            ],
            "layout": "IPY_MODEL_bd64271d1c2a46f9bdbc379b751479d2"
          }
        },
        "4deb31d2506549dab926217761d65d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f3d2869472c4dd19472bdc7f2da1ddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_175edf876a8a4cf0beadafda78227bbd",
            "placeholder": "​",
            "style": "IPY_MODEL_19422c5ec53847b68b54c9d35f971fd9",
            "value": " 0/235 [00:00&lt;?, ?it/s]"
          }
        },
        "52f23a8889d643598787e2ddb076cb7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f2c65a8c9ec42cbb53b3184359df62b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "608c79d3f7e64fad8c0acd38d44dcb00": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f8c2f2a0e294c87a3becbfb375e2e71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f2c65a8c9ec42cbb53b3184359df62b",
            "placeholder": "​",
            "style": "IPY_MODEL_f446f4dfdfd14db5a09440661b8b1636",
            "value": "Iteration:   0%"
          }
        },
        "81f2efeaacea49abaa4106f4632e711e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e6935caaf39469ca10424ddfa815e41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_608c79d3f7e64fad8c0acd38d44dcb00",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e541fbe972f9490ba4549f94a36b397d",
            "value": 0
          }
        },
        "969e3656a3be45dca5f26c0a463f65cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd64271d1c2a46f9bdbc379b751479d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bda05d2c3b5544c5b5909f7e6487e7a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e541fbe972f9490ba4549f94a36b397d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e984c9ef79604b6e9f9ef710e1765680": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52f23a8889d643598787e2ddb076cb7b",
            "placeholder": "​",
            "style": "IPY_MODEL_03a80a4dbf3d4997b5e28a10167b7a79",
            "value": " 0/100 [00:00&lt;?, ?it/s]"
          }
        },
        "f05b8152e14a49a58b935ec973b7564d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f446f4dfdfd14db5a09440661b8b1636": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f72172ca27cb4200ac19224ea851bf44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f8c2f2a0e294c87a3becbfb375e2e71",
              "IPY_MODEL_01020e596eeb4b2abab39365c5b17bc4",
              "IPY_MODEL_4f3d2869472c4dd19472bdc7f2da1ddb"
            ],
            "layout": "IPY_MODEL_81f2efeaacea49abaa4106f4632e711e"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}